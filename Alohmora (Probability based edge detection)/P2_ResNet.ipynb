{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoAmRych4zjz"
   },
   "source": [
    "# RBE/CS549 Fall 2022: Computer Vision\n",
    "## Homework 0: Alohomora\n",
    "\n",
    "Author(s): \n",
    "Prof. Nitin J. Sanket (nsanket@wpi.edu), Lening Li (lli4@wpi.edu), Gejji, Vaishnavi Vivek (vgejji@wpi.edu)\n",
    "\n",
    "Robotics Engineering Department,\n",
    "\n",
    "Worcester Polytechnic Institute\n",
    "\n",
    "Code adapted from CMSC733 at the University of Maryland, College Park."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2aeH7uq8qR7"
   },
   "source": [
    "## Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4iWkcHsItB0"
   },
   "source": [
    "### Neural Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jGCHa0pfIss-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def loss_fn(out, labels):\n",
    "    ###############################################\n",
    "    # Fill your loss function of choice here!\n",
    "    ###############################################\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    loss = loss(out, labels)\n",
    "    return loss\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = loss_fn(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = loss_fn(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'loss': loss.detach(), 'acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'loss': epoch_loss.item(), 'acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], loss: {:.4f}, acc: {:.4f}\".format(epoch, result['loss'], result['acc']))\n",
    "\n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True)\n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Linear(512, num_classes))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    \n",
    "'''\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "#         self.shortcut = nn.Sequential()\n",
    "#         if stride != 1 or in_planes != self.expansion*planes:\n",
    "#             self.shortcut = nn.Sequential(\n",
    "#                 nn.Conv2d(in_planes, self.expansion*planes,\n",
    "#                           kernel_size=1, stride=stride, bias=False),\n",
    "#                 nn.BatchNorm2d(self.expansion*planes)\n",
    "#             )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        # out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        # out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(ImageClassificationBase):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        # out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "       \n",
    "        \n",
    "'''            \n",
    "        \n",
    "'''\n",
    "# 3x3 convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "# ResNet\n",
    "class ResNet(ImageClassificationBase):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 32\n",
    "        self.conv = conv3x3(3, 32)\n",
    "        self.bn = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 32, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 64, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 128, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "'''\n",
    "# class CIFAR10Model(ImageClassificationBase):\n",
    "#     def __init__(self, InputSize, OutputSize):\n",
    "#         \"\"\"\n",
    "#         Inputs: \n",
    "#         InputSize - Size of the Input\n",
    "#         OutputSize - Size of the Output\n",
    "#         \"\"\"\n",
    "#         #############################\n",
    "#         # Fill your network initialization of choice here!\n",
    "#         #############################\n",
    "#         super().__init__()\n",
    "#         self.network = nn.Sequential(\n",
    "#             nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "#             nn.BatchNorm2d(64),\n",
    "\n",
    "#             nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "#             nn.BatchNorm2d(128),\n",
    "\n",
    "#             nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "#             nn.BatchNorm2d(256),\n",
    "\n",
    "#             nn.Flatten(), \n",
    "#             nn.Linear(256*4*4, 1024),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(1024, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, 10))\n",
    "        \n",
    "#     def forward(self, xb):\n",
    "#         \"\"\"\n",
    "#         Input:\n",
    "#         xb is a MiniBatch of the current image\n",
    "#         Outputs:\n",
    "#         out - output of the network\n",
    "#         \"\"\"\n",
    "#         #############################\n",
    "#         # Fill your network structure of choice here!\n",
    "#         #############################\n",
    "#         return self.network(xb)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2SPck2oRdL5j"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def tic():\n",
    "    \"\"\"\n",
    "    Function to start timer\n",
    "    Tries to mimic tic() toc() in MATLAB\n",
    "    \"\"\"\n",
    "    StartTime = time.time()\n",
    "    return StartTime\n",
    "\n",
    "def toc(StartTime):\n",
    "    \"\"\"\n",
    "    Function to stop timer\n",
    "    Tries to mimic tic() toc() in MATLAB\n",
    "    \"\"\"\n",
    "    return time.time() - StartTime\n",
    "\n",
    "def FindLatestModel(CheckPointPath):\n",
    "    \"\"\"\n",
    "    Finds Latest Model in CheckPointPath\n",
    "    Inputs:\n",
    "    CheckPointPath - Path where you have stored checkpoints\n",
    "    Outputs:\n",
    "    LatestFile - File Name of the latest checkpoint\n",
    "    \"\"\"\n",
    "    FileList = glob.glob(CheckPointPath + '*.ckpt.index') # * means all if need specific format then *.csv\n",
    "    LatestFile = max(FileList, key=os.path.getctime)\n",
    "    # Strip everything else except needed information\n",
    "    LatestFile = LatestFile.replace(CheckPointPath, '')\n",
    "    LatestFile = LatestFile.replace('.ckpt.index', '')\n",
    "    return LatestFile\n",
    "\n",
    "\n",
    "def convertToOneHot(vector, NumClasses):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    vector - vector of argmax indexes\n",
    "    NumClasses - Number of classes\n",
    "    \"\"\"\n",
    "    return np.equal.outer(vector, np.arange(NumClasses)).astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A04kYJ_rJxEP"
   },
   "source": [
    "### Train your neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculating 3 channel mean and std for image dataset\n",
    "# import tqdm\n",
    "# import random\n",
    "\n",
    "# means = np.array([0, 0, 0], dtype=np.float32)\n",
    "# stds = np.array([0, 0, 0], dtype=np.float32)\n",
    "# total_images = 0\n",
    "# randomly_sample = 5000\n",
    "# for f in tqdm.tqdm(random.sample(glob.glob(\"dataset_path/**.jpg\", recursive = True), randomly_sample)):\n",
    "#     img = cv2.imread(f)\n",
    "#     means += img.mean(axis=(0,1))\n",
    "#     stds += img.std(axis=(0,1))\n",
    "#     total_images += 1\n",
    "# means = means / (total_images * 255.)\n",
    "# stds = stds / (total_images * 255.)\n",
    "# print(\"Total images: \", total_images)\n",
    "# print(\"Means: \", means)\n",
    "# print(\"Stds: \", stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hcGOFRE2JueB",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Number of Epochs Training will run for 10\n",
      "Factor of reduction in training data is 1.0\n",
      "Mini Batch Size 64\n",
      "Number of Training Images 50000\n",
      "New model initialized....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676f453b0a824a4d9b6d632cb024d6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f5038b9d5b4a809b2015c3f878a96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checkpoints/0a0model.ckpt Model Saved...\n",
      "Epoch [0], loss: 1.8051, acc: 0.4375\n",
      "Epoch [1], loss: 1.3404, acc: 0.6719\n",
      "Epoch [2], loss: 1.2008, acc: 0.5938\n",
      "Epoch [3], loss: 1.9191, acc: 0.4688\n",
      "Epoch [4], loss: 1.7822, acc: 0.5156\n",
      "Epoch [5], loss: 1.7919, acc: 0.4531\n",
      "Epoch [6], loss: 1.7300, acc: 0.3438\n",
      "Epoch [7], loss: 1.6959, acc: 0.4062\n",
      "Epoch [8], loss: 2.1003, acc: 0.3594\n",
      "Epoch [9], loss: 2.0355, acc: 0.3594\n",
      "Epoch [10], loss: 1.8463, acc: 0.4062\n",
      "Epoch [11], loss: 1.7302, acc: 0.3594\n",
      "Epoch [12], loss: 1.7461, acc: 0.3906\n",
      "Epoch [13], loss: 1.7564, acc: 0.3594\n",
      "Epoch [14], loss: 1.8419, acc: 0.3906\n",
      "Epoch [15], loss: 2.0685, acc: 0.3281\n",
      "Epoch [16], loss: 1.7053, acc: 0.4062\n",
      "Epoch [17], loss: 1.7823, acc: 0.3125\n",
      "Epoch [18], loss: 1.5026, acc: 0.4531\n",
      "Epoch [19], loss: 1.6025, acc: 0.4219\n",
      "Epoch [20], loss: 1.7425, acc: 0.3594\n",
      "Epoch [21], loss: 1.6498, acc: 0.4062\n",
      "Epoch [22], loss: 1.6949, acc: 0.4219\n",
      "Epoch [23], loss: 1.5950, acc: 0.4062\n",
      "Epoch [24], loss: 1.5303, acc: 0.3438\n",
      "Epoch [25], loss: 1.5621, acc: 0.4062\n",
      "Epoch [26], loss: 1.5561, acc: 0.3906\n",
      "Epoch [27], loss: 1.4976, acc: 0.4219\n",
      "Epoch [28], loss: 1.4830, acc: 0.5312\n",
      "Epoch [29], loss: 1.6158, acc: 0.3750\n",
      "Epoch [30], loss: 1.5432, acc: 0.4219\n",
      "Epoch [31], loss: 1.4626, acc: 0.3750\n",
      "Epoch [32], loss: 1.4647, acc: 0.5469\n",
      "Epoch [33], loss: 1.4885, acc: 0.4844\n",
      "Epoch [34], loss: 1.4195, acc: 0.4688\n",
      "Epoch [35], loss: 1.5668, acc: 0.3438\n",
      "Epoch [36], loss: 1.3778, acc: 0.5156\n",
      "Epoch [37], loss: 1.5171, acc: 0.4844\n",
      "Epoch [38], loss: 1.2941, acc: 0.5312\n",
      "Epoch [39], loss: 1.5368, acc: 0.4375\n",
      "Epoch [40], loss: 1.7033, acc: 0.3750\n",
      "Epoch [41], loss: 1.3987, acc: 0.4219\n",
      "Epoch [42], loss: 1.6446, acc: 0.3906\n",
      "Epoch [43], loss: 1.4928, acc: 0.4531\n",
      "Epoch [44], loss: 1.4601, acc: 0.4219\n",
      "Epoch [45], loss: 1.4559, acc: 0.4375\n",
      "Epoch [46], loss: 1.3921, acc: 0.5312\n",
      "Epoch [47], loss: 1.2615, acc: 0.5625\n",
      "Epoch [48], loss: 1.4966, acc: 0.4531\n",
      "Epoch [49], loss: 1.5295, acc: 0.4375\n",
      "Epoch [50], loss: 1.4211, acc: 0.4219\n",
      "Epoch [51], loss: 1.3951, acc: 0.5000\n",
      "Epoch [52], loss: 1.4167, acc: 0.5000\n",
      "Epoch [53], loss: 1.3147, acc: 0.4688\n",
      "Epoch [54], loss: 1.5416, acc: 0.4375\n",
      "Epoch [55], loss: 1.3887, acc: 0.5156\n",
      "Epoch [56], loss: 1.5180, acc: 0.4688\n",
      "Epoch [57], loss: 1.3522, acc: 0.5156\n",
      "Epoch [58], loss: 1.3359, acc: 0.5156\n",
      "Epoch [59], loss: 1.4540, acc: 0.4531\n",
      "Epoch [60], loss: 1.1895, acc: 0.5938\n",
      "Epoch [61], loss: 1.5722, acc: 0.4062\n",
      "Epoch [62], loss: 1.3937, acc: 0.5312\n",
      "Epoch [63], loss: 1.3125, acc: 0.5312\n",
      "Epoch [64], loss: 1.3032, acc: 0.5938\n",
      "Epoch [65], loss: 1.4907, acc: 0.3906\n",
      "Epoch [66], loss: 1.2860, acc: 0.6406\n",
      "Epoch [67], loss: 1.4528, acc: 0.5469\n",
      "Epoch [68], loss: 1.4391, acc: 0.5625\n",
      "Epoch [69], loss: 1.3378, acc: 0.4688\n",
      "Epoch [70], loss: 1.5408, acc: 0.4844\n",
      "Epoch [71], loss: 1.1855, acc: 0.6562\n",
      "Epoch [72], loss: 1.6245, acc: 0.5156\n",
      "Epoch [73], loss: 1.2447, acc: 0.5938\n",
      "Epoch [74], loss: 1.3265, acc: 0.4375\n",
      "Epoch [75], loss: 1.2876, acc: 0.5156\n",
      "Epoch [76], loss: 1.3402, acc: 0.5000\n",
      "Epoch [77], loss: 1.2293, acc: 0.5625\n",
      "Epoch [78], loss: 1.2716, acc: 0.5781\n",
      "Epoch [79], loss: 1.4463, acc: 0.5312\n",
      "Epoch [80], loss: 1.1461, acc: 0.6406\n",
      "Epoch [81], loss: 1.4094, acc: 0.4844\n",
      "Epoch [82], loss: 1.3812, acc: 0.4375\n",
      "Epoch [83], loss: 1.2544, acc: 0.5938\n",
      "Epoch [84], loss: 1.0722, acc: 0.6406\n",
      "Epoch [85], loss: 1.3121, acc: 0.5781\n",
      "Epoch [86], loss: 1.2416, acc: 0.4688\n",
      "Epoch [87], loss: 1.2695, acc: 0.5156\n",
      "Epoch [88], loss: 1.1800, acc: 0.6094\n",
      "Epoch [89], loss: 1.2353, acc: 0.5469\n",
      "Epoch [90], loss: 1.2079, acc: 0.6250\n",
      "Epoch [91], loss: 1.3490, acc: 0.5312\n",
      "Epoch [92], loss: 1.1268, acc: 0.6250\n",
      "Epoch [93], loss: 1.2874, acc: 0.5156\n",
      "Epoch [94], loss: 1.1683, acc: 0.6406\n",
      "Epoch [95], loss: 1.1613, acc: 0.5781\n",
      "Epoch [96], loss: 1.1433, acc: 0.6875\n",
      "Epoch [97], loss: 1.2137, acc: 0.5469\n",
      "Epoch [98], loss: 1.1803, acc: 0.5938\n",
      "Epoch [99], loss: 1.1872, acc: 0.5000\n",
      "\n",
      "Checkpoints/0a100model.ckpt Model Saved...\n",
      "Epoch [100], loss: 1.1169, acc: 0.5625\n",
      "Epoch [101], loss: 1.1672, acc: 0.5938\n",
      "Epoch [102], loss: 1.2548, acc: 0.5938\n",
      "Epoch [103], loss: 1.1484, acc: 0.6250\n",
      "Epoch [104], loss: 1.1358, acc: 0.5781\n",
      "Epoch [105], loss: 0.9146, acc: 0.7344\n",
      "Epoch [106], loss: 1.1394, acc: 0.6094\n",
      "Epoch [107], loss: 1.2793, acc: 0.5781\n",
      "Epoch [108], loss: 1.0831, acc: 0.5938\n",
      "Epoch [109], loss: 1.1095, acc: 0.5938\n",
      "Epoch [110], loss: 1.1441, acc: 0.6094\n",
      "Epoch [111], loss: 1.2324, acc: 0.5156\n",
      "Epoch [112], loss: 1.2504, acc: 0.5312\n",
      "Epoch [113], loss: 1.2573, acc: 0.5781\n",
      "Epoch [114], loss: 1.2381, acc: 0.5312\n",
      "Epoch [115], loss: 1.2584, acc: 0.5781\n",
      "Epoch [116], loss: 1.2228, acc: 0.5625\n",
      "Epoch [117], loss: 1.0582, acc: 0.5469\n",
      "Epoch [118], loss: 1.2959, acc: 0.5312\n",
      "Epoch [119], loss: 0.9982, acc: 0.6875\n",
      "Epoch [120], loss: 1.2127, acc: 0.5781\n",
      "Epoch [121], loss: 1.2360, acc: 0.5469\n",
      "Epoch [122], loss: 1.1413, acc: 0.5469\n",
      "Epoch [123], loss: 1.3093, acc: 0.5312\n",
      "Epoch [124], loss: 1.0596, acc: 0.6562\n",
      "Epoch [125], loss: 1.0792, acc: 0.5938\n",
      "Epoch [126], loss: 1.4268, acc: 0.5000\n",
      "Epoch [127], loss: 1.3926, acc: 0.4375\n",
      "Epoch [128], loss: 1.0014, acc: 0.5469\n",
      "Epoch [129], loss: 1.0271, acc: 0.6094\n",
      "Epoch [130], loss: 1.1871, acc: 0.6406\n",
      "Epoch [131], loss: 1.1015, acc: 0.5938\n",
      "Epoch [132], loss: 1.2294, acc: 0.6250\n",
      "Epoch [133], loss: 1.1889, acc: 0.5938\n",
      "Epoch [134], loss: 1.2409, acc: 0.5938\n",
      "Epoch [135], loss: 0.9852, acc: 0.6719\n",
      "Epoch [136], loss: 1.1331, acc: 0.6250\n",
      "Epoch [137], loss: 1.0762, acc: 0.6250\n",
      "Epoch [138], loss: 1.3134, acc: 0.5312\n",
      "Epoch [139], loss: 1.2046, acc: 0.5938\n",
      "Epoch [140], loss: 1.1880, acc: 0.5781\n",
      "Epoch [141], loss: 1.1446, acc: 0.6875\n",
      "Epoch [142], loss: 1.2324, acc: 0.6406\n",
      "Epoch [143], loss: 1.1950, acc: 0.5469\n",
      "Epoch [144], loss: 1.0863, acc: 0.5781\n",
      "Epoch [145], loss: 1.3249, acc: 0.5938\n",
      "Epoch [146], loss: 1.1052, acc: 0.6719\n",
      "Epoch [147], loss: 1.1211, acc: 0.5000\n",
      "Epoch [148], loss: 1.1522, acc: 0.5625\n",
      "Epoch [149], loss: 1.1527, acc: 0.5312\n",
      "Epoch [150], loss: 1.0087, acc: 0.6250\n",
      "Epoch [151], loss: 1.2990, acc: 0.5469\n",
      "Epoch [152], loss: 1.2238, acc: 0.5625\n",
      "Epoch [153], loss: 1.0371, acc: 0.6094\n",
      "Epoch [154], loss: 1.1382, acc: 0.6094\n",
      "Epoch [155], loss: 1.1162, acc: 0.5781\n",
      "Epoch [156], loss: 0.9857, acc: 0.5938\n",
      "Epoch [157], loss: 1.0324, acc: 0.6406\n",
      "Epoch [158], loss: 0.9348, acc: 0.6250\n",
      "Epoch [159], loss: 1.1781, acc: 0.6094\n",
      "Epoch [160], loss: 1.1294, acc: 0.6250\n",
      "Epoch [161], loss: 1.0752, acc: 0.6406\n",
      "Epoch [162], loss: 1.1575, acc: 0.6094\n",
      "Epoch [163], loss: 1.1247, acc: 0.5938\n",
      "Epoch [164], loss: 1.1804, acc: 0.5781\n",
      "Epoch [165], loss: 0.9687, acc: 0.6250\n",
      "Epoch [166], loss: 1.0833, acc: 0.7031\n",
      "Epoch [167], loss: 1.0653, acc: 0.6406\n",
      "Epoch [168], loss: 0.9612, acc: 0.6719\n",
      "Epoch [169], loss: 0.9874, acc: 0.7188\n",
      "Epoch [170], loss: 1.2016, acc: 0.6250\n",
      "Epoch [171], loss: 0.8376, acc: 0.7656\n",
      "Epoch [172], loss: 1.1204, acc: 0.6094\n",
      "Epoch [173], loss: 1.0650, acc: 0.6250\n",
      "Epoch [174], loss: 0.8601, acc: 0.7188\n",
      "Epoch [175], loss: 1.0572, acc: 0.6094\n",
      "Epoch [176], loss: 1.0363, acc: 0.6094\n",
      "Epoch [177], loss: 1.0632, acc: 0.6562\n",
      "Epoch [178], loss: 1.0897, acc: 0.6094\n",
      "Epoch [179], loss: 0.8813, acc: 0.7188\n",
      "Epoch [180], loss: 0.9083, acc: 0.6875\n",
      "Epoch [181], loss: 1.0014, acc: 0.7031\n",
      "Epoch [182], loss: 1.0594, acc: 0.5781\n",
      "Epoch [183], loss: 0.9061, acc: 0.7031\n",
      "Epoch [184], loss: 0.7637, acc: 0.7656\n",
      "Epoch [185], loss: 0.9261, acc: 0.6250\n",
      "Epoch [186], loss: 0.9637, acc: 0.6562\n",
      "Epoch [187], loss: 0.9929, acc: 0.6250\n",
      "Epoch [188], loss: 0.9612, acc: 0.6406\n",
      "Epoch [189], loss: 1.0524, acc: 0.6250\n",
      "Epoch [190], loss: 1.1337, acc: 0.6094\n",
      "Epoch [191], loss: 1.1607, acc: 0.5781\n",
      "Epoch [192], loss: 0.9629, acc: 0.6250\n",
      "Epoch [193], loss: 0.7610, acc: 0.7656\n",
      "Epoch [194], loss: 1.0344, acc: 0.6406\n",
      "Epoch [195], loss: 0.8769, acc: 0.7188\n",
      "Epoch [196], loss: 0.9228, acc: 0.7188\n",
      "Epoch [197], loss: 0.9160, acc: 0.6875\n",
      "Epoch [198], loss: 0.8863, acc: 0.7188\n",
      "Epoch [199], loss: 1.0576, acc: 0.6562\n",
      "\n",
      "Checkpoints/0a200model.ckpt Model Saved...\n",
      "Epoch [200], loss: 0.9338, acc: 0.6875\n",
      "Epoch [201], loss: 1.1172, acc: 0.6406\n",
      "Epoch [202], loss: 0.9252, acc: 0.7031\n",
      "Epoch [203], loss: 1.0325, acc: 0.6406\n",
      "Epoch [204], loss: 1.0970, acc: 0.5781\n",
      "Epoch [205], loss: 0.9687, acc: 0.6719\n",
      "Epoch [206], loss: 0.9816, acc: 0.5938\n",
      "Epoch [207], loss: 0.8407, acc: 0.7188\n",
      "Epoch [208], loss: 0.6690, acc: 0.8125\n",
      "Epoch [209], loss: 1.2777, acc: 0.5000\n",
      "Epoch [210], loss: 0.9314, acc: 0.7031\n",
      "Epoch [211], loss: 0.7634, acc: 0.7344\n",
      "Epoch [212], loss: 1.1628, acc: 0.6719\n",
      "Epoch [213], loss: 1.0405, acc: 0.6094\n",
      "Epoch [214], loss: 1.1555, acc: 0.5469\n",
      "Epoch [215], loss: 1.3099, acc: 0.5625\n",
      "Epoch [216], loss: 1.0928, acc: 0.5000\n",
      "Epoch [217], loss: 0.9776, acc: 0.6406\n",
      "Epoch [218], loss: 1.0286, acc: 0.6094\n",
      "Epoch [219], loss: 1.0942, acc: 0.6562\n",
      "Epoch [220], loss: 1.0785, acc: 0.5625\n",
      "Epoch [221], loss: 0.9874, acc: 0.6250\n",
      "Epoch [222], loss: 0.9531, acc: 0.7031\n",
      "Epoch [223], loss: 0.9595, acc: 0.6406\n",
      "Epoch [224], loss: 1.1743, acc: 0.6562\n",
      "Epoch [225], loss: 0.8424, acc: 0.7500\n",
      "Epoch [226], loss: 0.8995, acc: 0.7031\n",
      "Epoch [227], loss: 0.9054, acc: 0.6719\n",
      "Epoch [228], loss: 1.0399, acc: 0.6875\n",
      "Epoch [229], loss: 0.8115, acc: 0.7656\n",
      "Epoch [230], loss: 1.1673, acc: 0.5469\n",
      "Epoch [231], loss: 0.9760, acc: 0.6875\n",
      "Epoch [232], loss: 0.8171, acc: 0.7188\n",
      "Epoch [233], loss: 0.8795, acc: 0.7188\n",
      "Epoch [234], loss: 0.7242, acc: 0.7188\n",
      "Epoch [235], loss: 0.8470, acc: 0.7188\n",
      "Epoch [236], loss: 1.0621, acc: 0.6250\n",
      "Epoch [237], loss: 1.0651, acc: 0.6406\n",
      "Epoch [238], loss: 0.8871, acc: 0.7656\n",
      "Epoch [239], loss: 0.9171, acc: 0.7031\n",
      "Epoch [240], loss: 0.9019, acc: 0.6406\n",
      "Epoch [241], loss: 0.8810, acc: 0.6562\n",
      "Epoch [242], loss: 1.1298, acc: 0.5781\n",
      "Epoch [243], loss: 0.7664, acc: 0.7344\n",
      "Epoch [244], loss: 1.0806, acc: 0.6094\n",
      "Epoch [245], loss: 0.8573, acc: 0.7188\n",
      "Epoch [246], loss: 1.0539, acc: 0.6406\n",
      "Epoch [247], loss: 0.7990, acc: 0.7500\n",
      "Epoch [248], loss: 0.7623, acc: 0.7656\n",
      "Epoch [249], loss: 0.8431, acc: 0.7188\n",
      "Epoch [250], loss: 0.9038, acc: 0.6719\n",
      "Epoch [251], loss: 0.7710, acc: 0.7656\n",
      "Epoch [252], loss: 0.8121, acc: 0.6875\n",
      "Epoch [253], loss: 0.9568, acc: 0.6562\n",
      "Epoch [254], loss: 0.9897, acc: 0.6094\n",
      "Epoch [255], loss: 0.9468, acc: 0.6562\n",
      "Epoch [256], loss: 0.5891, acc: 0.8125\n",
      "Epoch [257], loss: 0.6890, acc: 0.7344\n",
      "Epoch [258], loss: 1.0078, acc: 0.6875\n",
      "Epoch [259], loss: 0.7741, acc: 0.7188\n",
      "Epoch [260], loss: 1.0519, acc: 0.6719\n",
      "Epoch [261], loss: 0.9338, acc: 0.6094\n",
      "Epoch [262], loss: 0.8552, acc: 0.7188\n",
      "Epoch [263], loss: 0.9222, acc: 0.6875\n",
      "Epoch [264], loss: 0.6684, acc: 0.7969\n",
      "Epoch [265], loss: 0.9837, acc: 0.6406\n",
      "Epoch [266], loss: 0.8040, acc: 0.7031\n",
      "Epoch [267], loss: 0.9215, acc: 0.7344\n",
      "Epoch [268], loss: 0.9582, acc: 0.6562\n",
      "Epoch [269], loss: 0.7171, acc: 0.7656\n",
      "Epoch [270], loss: 0.7487, acc: 0.7812\n",
      "Epoch [271], loss: 1.0714, acc: 0.6406\n",
      "Epoch [272], loss: 1.1337, acc: 0.6406\n",
      "Epoch [273], loss: 0.8000, acc: 0.7500\n",
      "Epoch [274], loss: 0.8941, acc: 0.6719\n",
      "Epoch [275], loss: 1.0084, acc: 0.7344\n",
      "Epoch [276], loss: 0.7985, acc: 0.6719\n",
      "Epoch [277], loss: 0.9581, acc: 0.6875\n",
      "Epoch [278], loss: 0.9021, acc: 0.7031\n",
      "Epoch [279], loss: 0.8428, acc: 0.7188\n",
      "Epoch [280], loss: 0.7419, acc: 0.7812\n",
      "Epoch [281], loss: 1.1506, acc: 0.5000\n",
      "Epoch [282], loss: 0.7076, acc: 0.7500\n",
      "Epoch [283], loss: 0.9156, acc: 0.7188\n",
      "Epoch [284], loss: 0.8323, acc: 0.7969\n",
      "Epoch [285], loss: 0.9740, acc: 0.6250\n",
      "Epoch [286], loss: 0.6926, acc: 0.7656\n",
      "Epoch [287], loss: 0.8108, acc: 0.7656\n",
      "Epoch [288], loss: 0.9033, acc: 0.7031\n",
      "Epoch [289], loss: 0.8162, acc: 0.7500\n",
      "Epoch [290], loss: 0.8712, acc: 0.6562\n",
      "Epoch [291], loss: 0.7415, acc: 0.7812\n",
      "Epoch [292], loss: 0.8809, acc: 0.7344\n",
      "Epoch [293], loss: 0.6570, acc: 0.7656\n",
      "Epoch [294], loss: 0.5791, acc: 0.7812\n",
      "Epoch [295], loss: 0.6995, acc: 0.7188\n",
      "Epoch [296], loss: 0.8901, acc: 0.7031\n",
      "Epoch [297], loss: 0.7449, acc: 0.7500\n",
      "Epoch [298], loss: 0.8524, acc: 0.7344\n",
      "Epoch [299], loss: 0.8842, acc: 0.6562\n",
      "\n",
      "Checkpoints/0a300model.ckpt Model Saved...\n",
      "Epoch [300], loss: 0.7433, acc: 0.8125\n",
      "Epoch [301], loss: 0.7386, acc: 0.7656\n",
      "Epoch [302], loss: 0.9065, acc: 0.7812\n",
      "Epoch [303], loss: 0.7560, acc: 0.7188\n",
      "Epoch [304], loss: 0.9365, acc: 0.7031\n",
      "Epoch [305], loss: 0.7018, acc: 0.7812\n",
      "Epoch [306], loss: 0.9181, acc: 0.7031\n",
      "Epoch [307], loss: 0.7272, acc: 0.7656\n",
      "Epoch [308], loss: 0.8321, acc: 0.7344\n",
      "Epoch [309], loss: 0.8401, acc: 0.7500\n",
      "Epoch [310], loss: 0.5450, acc: 0.8750\n",
      "Epoch [311], loss: 0.9762, acc: 0.6250\n",
      "Epoch [312], loss: 0.8830, acc: 0.6250\n",
      "Epoch [313], loss: 0.8331, acc: 0.7500\n",
      "Epoch [314], loss: 0.8235, acc: 0.7188\n",
      "Epoch [315], loss: 0.7257, acc: 0.7344\n",
      "Epoch [316], loss: 0.8368, acc: 0.7500\n",
      "Epoch [317], loss: 0.8003, acc: 0.7656\n",
      "Epoch [318], loss: 0.5981, acc: 0.8125\n",
      "Epoch [319], loss: 0.9529, acc: 0.6406\n",
      "Epoch [320], loss: 0.8364, acc: 0.7500\n",
      "Epoch [321], loss: 1.0156, acc: 0.6875\n",
      "Epoch [322], loss: 0.7341, acc: 0.7500\n",
      "Epoch [323], loss: 0.7415, acc: 0.7656\n",
      "Epoch [324], loss: 0.9861, acc: 0.6719\n",
      "Epoch [325], loss: 0.8457, acc: 0.7188\n",
      "Epoch [326], loss: 0.7198, acc: 0.7188\n",
      "Epoch [327], loss: 0.9890, acc: 0.7188\n",
      "Epoch [328], loss: 0.9628, acc: 0.6875\n",
      "Epoch [329], loss: 0.9806, acc: 0.6562\n",
      "Epoch [330], loss: 0.8193, acc: 0.6875\n",
      "Epoch [331], loss: 0.7656, acc: 0.7344\n",
      "Epoch [332], loss: 0.7654, acc: 0.7500\n",
      "Epoch [333], loss: 1.0681, acc: 0.6406\n",
      "Epoch [334], loss: 0.9189, acc: 0.7188\n",
      "Epoch [335], loss: 1.0510, acc: 0.6094\n",
      "Epoch [336], loss: 0.8319, acc: 0.7500\n",
      "Epoch [337], loss: 0.7833, acc: 0.7344\n",
      "Epoch [338], loss: 0.7595, acc: 0.7812\n",
      "Epoch [339], loss: 0.6598, acc: 0.7500\n",
      "Epoch [340], loss: 0.5533, acc: 0.8906\n",
      "Epoch [341], loss: 0.9453, acc: 0.7031\n",
      "Epoch [342], loss: 0.7336, acc: 0.7812\n",
      "Epoch [343], loss: 0.9918, acc: 0.6875\n",
      "Epoch [344], loss: 0.5716, acc: 0.7656\n",
      "Epoch [345], loss: 0.7382, acc: 0.7500\n",
      "Epoch [346], loss: 0.7337, acc: 0.7031\n",
      "Epoch [347], loss: 0.8090, acc: 0.7500\n",
      "Epoch [348], loss: 0.9314, acc: 0.6562\n",
      "Epoch [349], loss: 0.6360, acc: 0.8125\n",
      "Epoch [350], loss: 0.7031, acc: 0.7344\n",
      "Epoch [351], loss: 0.9138, acc: 0.7500\n",
      "Epoch [352], loss: 0.8805, acc: 0.7188\n",
      "Epoch [353], loss: 0.6175, acc: 0.8125\n",
      "Epoch [354], loss: 0.7228, acc: 0.7969\n",
      "Epoch [355], loss: 0.7459, acc: 0.8281\n",
      "Epoch [356], loss: 0.8581, acc: 0.7188\n",
      "Epoch [357], loss: 0.7132, acc: 0.7500\n",
      "Epoch [358], loss: 0.7277, acc: 0.7656\n",
      "Epoch [359], loss: 0.6813, acc: 0.7344\n",
      "Epoch [360], loss: 0.5736, acc: 0.7969\n",
      "Epoch [361], loss: 1.0818, acc: 0.6875\n",
      "Epoch [362], loss: 0.8040, acc: 0.6875\n",
      "Epoch [363], loss: 1.0010, acc: 0.6250\n",
      "Epoch [364], loss: 0.6571, acc: 0.7812\n",
      "Epoch [365], loss: 0.8041, acc: 0.7656\n",
      "Epoch [366], loss: 1.0157, acc: 0.6094\n",
      "Epoch [367], loss: 0.9380, acc: 0.7344\n",
      "Epoch [368], loss: 0.6242, acc: 0.7969\n",
      "Epoch [369], loss: 0.6367, acc: 0.7969\n",
      "Epoch [370], loss: 0.5945, acc: 0.8281\n",
      "Epoch [371], loss: 0.7510, acc: 0.6094\n",
      "Epoch [372], loss: 0.5569, acc: 0.7969\n",
      "Epoch [373], loss: 1.0004, acc: 0.6719\n",
      "Epoch [374], loss: 0.8972, acc: 0.7031\n",
      "Epoch [375], loss: 0.6597, acc: 0.7500\n",
      "Epoch [376], loss: 0.6118, acc: 0.8125\n",
      "Epoch [377], loss: 0.7708, acc: 0.6719\n",
      "Epoch [378], loss: 0.7935, acc: 0.7188\n",
      "Epoch [379], loss: 0.8583, acc: 0.7344\n",
      "Epoch [380], loss: 0.7619, acc: 0.6719\n",
      "Epoch [381], loss: 0.6600, acc: 0.8125\n",
      "Epoch [382], loss: 0.7225, acc: 0.7188\n",
      "Epoch [383], loss: 0.7600, acc: 0.7344\n",
      "Epoch [384], loss: 0.5842, acc: 0.8438\n",
      "Epoch [385], loss: 0.6734, acc: 0.7656\n",
      "Epoch [386], loss: 0.5902, acc: 0.7969\n",
      "Epoch [387], loss: 0.8435, acc: 0.7188\n",
      "Epoch [388], loss: 0.7317, acc: 0.7812\n",
      "Epoch [389], loss: 0.5801, acc: 0.7656\n",
      "Epoch [390], loss: 0.5974, acc: 0.7969\n",
      "Epoch [391], loss: 0.7629, acc: 0.7500\n",
      "Epoch [392], loss: 0.7070, acc: 0.7344\n",
      "Epoch [393], loss: 0.5908, acc: 0.8125\n",
      "Epoch [394], loss: 0.5527, acc: 0.8125\n",
      "Epoch [395], loss: 0.7307, acc: 0.7344\n",
      "Epoch [396], loss: 0.8162, acc: 0.7031\n",
      "Epoch [397], loss: 0.7022, acc: 0.7344\n",
      "Epoch [398], loss: 0.6946, acc: 0.7344\n",
      "Epoch [399], loss: 0.9953, acc: 0.6562\n",
      "\n",
      "Checkpoints/0a400model.ckpt Model Saved...\n",
      "Epoch [400], loss: 0.6825, acc: 0.7344\n",
      "Epoch [401], loss: 0.7820, acc: 0.7500\n",
      "Epoch [402], loss: 0.8152, acc: 0.7656\n",
      "Epoch [403], loss: 0.6078, acc: 0.7969\n",
      "Epoch [404], loss: 0.6027, acc: 0.8125\n",
      "Epoch [405], loss: 1.0337, acc: 0.6406\n",
      "Epoch [406], loss: 0.7557, acc: 0.7188\n",
      "Epoch [407], loss: 0.6147, acc: 0.7969\n",
      "Epoch [408], loss: 0.7968, acc: 0.7031\n",
      "Epoch [409], loss: 0.8632, acc: 0.7344\n",
      "Epoch [410], loss: 0.7288, acc: 0.7344\n",
      "Epoch [411], loss: 0.6168, acc: 0.7969\n",
      "Epoch [412], loss: 0.8985, acc: 0.7188\n",
      "Epoch [413], loss: 0.9608, acc: 0.6719\n",
      "Epoch [414], loss: 0.8163, acc: 0.7344\n",
      "Epoch [415], loss: 0.7613, acc: 0.7188\n",
      "Epoch [416], loss: 0.5914, acc: 0.7812\n",
      "Epoch [417], loss: 0.5974, acc: 0.8125\n",
      "Epoch [418], loss: 0.6113, acc: 0.8125\n",
      "Epoch [419], loss: 0.8017, acc: 0.7500\n",
      "Epoch [420], loss: 0.8062, acc: 0.7344\n",
      "Epoch [421], loss: 0.8237, acc: 0.7188\n",
      "Epoch [422], loss: 0.5672, acc: 0.8125\n",
      "Epoch [423], loss: 0.7168, acc: 0.7031\n",
      "Epoch [424], loss: 0.7903, acc: 0.7812\n",
      "Epoch [425], loss: 0.6019, acc: 0.7812\n",
      "Epoch [426], loss: 0.7884, acc: 0.7500\n",
      "Epoch [427], loss: 0.7624, acc: 0.7188\n",
      "Epoch [428], loss: 0.4970, acc: 0.8906\n",
      "Epoch [429], loss: 0.7342, acc: 0.7344\n",
      "Epoch [430], loss: 0.7683, acc: 0.7188\n",
      "Epoch [431], loss: 0.6679, acc: 0.8281\n",
      "Epoch [432], loss: 0.8258, acc: 0.7188\n",
      "Epoch [433], loss: 0.8050, acc: 0.7188\n",
      "Epoch [434], loss: 0.6287, acc: 0.7812\n",
      "Epoch [435], loss: 0.7023, acc: 0.7656\n",
      "Epoch [436], loss: 0.5504, acc: 0.8281\n",
      "Epoch [437], loss: 0.5934, acc: 0.8125\n",
      "Epoch [438], loss: 0.5746, acc: 0.7969\n",
      "Epoch [439], loss: 0.9129, acc: 0.7031\n",
      "Epoch [440], loss: 0.7162, acc: 0.7500\n",
      "Epoch [441], loss: 0.6236, acc: 0.7969\n",
      "Epoch [442], loss: 0.6017, acc: 0.7812\n",
      "Epoch [443], loss: 0.6693, acc: 0.7500\n",
      "Epoch [444], loss: 0.6224, acc: 0.7812\n",
      "Epoch [445], loss: 0.6037, acc: 0.7656\n",
      "Epoch [446], loss: 0.6432, acc: 0.7812\n",
      "Epoch [447], loss: 0.6978, acc: 0.7500\n",
      "Epoch [448], loss: 0.6128, acc: 0.8594\n",
      "Epoch [449], loss: 0.7015, acc: 0.7656\n",
      "Epoch [450], loss: 0.6921, acc: 0.8125\n",
      "Epoch [451], loss: 0.7093, acc: 0.7812\n",
      "Epoch [452], loss: 0.6942, acc: 0.7188\n",
      "Epoch [453], loss: 0.6241, acc: 0.8125\n",
      "Epoch [454], loss: 0.6366, acc: 0.7500\n",
      "Epoch [455], loss: 0.8574, acc: 0.7188\n",
      "Epoch [456], loss: 0.6323, acc: 0.8125\n",
      "Epoch [457], loss: 0.7602, acc: 0.7344\n",
      "Epoch [458], loss: 0.8544, acc: 0.7656\n",
      "Epoch [459], loss: 0.4942, acc: 0.8750\n",
      "Epoch [460], loss: 0.5263, acc: 0.7969\n",
      "Epoch [461], loss: 0.6959, acc: 0.7656\n",
      "Epoch [462], loss: 0.6136, acc: 0.8125\n",
      "Epoch [463], loss: 0.6041, acc: 0.8125\n",
      "Epoch [464], loss: 0.7304, acc: 0.7031\n",
      "Epoch [465], loss: 0.4860, acc: 0.8281\n",
      "Epoch [466], loss: 0.7868, acc: 0.7656\n",
      "Epoch [467], loss: 0.5750, acc: 0.9062\n",
      "Epoch [468], loss: 0.5685, acc: 0.8594\n",
      "Epoch [469], loss: 0.6052, acc: 0.7969\n",
      "Epoch [470], loss: 0.6313, acc: 0.7812\n",
      "Epoch [471], loss: 0.5537, acc: 0.7969\n",
      "Epoch [472], loss: 0.6769, acc: 0.7812\n",
      "Epoch [473], loss: 0.8414, acc: 0.6719\n",
      "Epoch [474], loss: 0.7193, acc: 0.7344\n",
      "Epoch [475], loss: 0.7424, acc: 0.7812\n",
      "Epoch [476], loss: 0.6188, acc: 0.7969\n",
      "Epoch [477], loss: 0.5939, acc: 0.8125\n",
      "Epoch [478], loss: 0.6682, acc: 0.7344\n",
      "Epoch [479], loss: 0.7429, acc: 0.7344\n",
      "Epoch [480], loss: 0.8051, acc: 0.7188\n",
      "Epoch [481], loss: 0.6400, acc: 0.7656\n",
      "Epoch [482], loss: 0.5990, acc: 0.8125\n",
      "Epoch [483], loss: 0.8795, acc: 0.7188\n",
      "Epoch [484], loss: 0.5630, acc: 0.7969\n",
      "Epoch [485], loss: 0.5909, acc: 0.7969\n",
      "Epoch [486], loss: 0.5681, acc: 0.8438\n",
      "Epoch [487], loss: 0.6374, acc: 0.8281\n",
      "Epoch [488], loss: 1.0057, acc: 0.7031\n",
      "Epoch [489], loss: 0.7156, acc: 0.8438\n",
      "Epoch [490], loss: 0.6576, acc: 0.7969\n",
      "Epoch [491], loss: 0.7546, acc: 0.6719\n",
      "Epoch [492], loss: 0.7110, acc: 0.7656\n",
      "Epoch [493], loss: 0.5966, acc: 0.8594\n",
      "Epoch [494], loss: 0.7476, acc: 0.7500\n",
      "Epoch [495], loss: 0.6748, acc: 0.8125\n",
      "Epoch [496], loss: 0.6333, acc: 0.8438\n",
      "Epoch [497], loss: 0.7400, acc: 0.7344\n",
      "Epoch [498], loss: 0.6212, acc: 0.8281\n",
      "Epoch [499], loss: 0.6085, acc: 0.7969\n",
      "\n",
      "Checkpoints/0a500model.ckpt Model Saved...\n",
      "Epoch [500], loss: 0.7787, acc: 0.7188\n",
      "Epoch [501], loss: 0.6508, acc: 0.8281\n",
      "Epoch [502], loss: 0.6242, acc: 0.7969\n",
      "Epoch [503], loss: 0.5563, acc: 0.8125\n",
      "Epoch [504], loss: 0.8555, acc: 0.6719\n",
      "Epoch [505], loss: 0.5275, acc: 0.8438\n",
      "Epoch [506], loss: 0.6893, acc: 0.6875\n",
      "Epoch [507], loss: 0.6581, acc: 0.7812\n",
      "Epoch [508], loss: 0.9107, acc: 0.6719\n",
      "Epoch [509], loss: 0.5109, acc: 0.8906\n",
      "Epoch [510], loss: 0.6144, acc: 0.7812\n",
      "Epoch [511], loss: 0.6793, acc: 0.7500\n",
      "Epoch [512], loss: 0.6514, acc: 0.7812\n",
      "Epoch [513], loss: 0.5897, acc: 0.7656\n",
      "Epoch [514], loss: 0.5373, acc: 0.8125\n",
      "Epoch [515], loss: 0.6310, acc: 0.8281\n",
      "Epoch [516], loss: 0.8060, acc: 0.7031\n",
      "Epoch [517], loss: 0.6575, acc: 0.7656\n",
      "Epoch [518], loss: 0.6808, acc: 0.7344\n",
      "Epoch [519], loss: 0.6072, acc: 0.8125\n",
      "Epoch [520], loss: 0.5839, acc: 0.8125\n",
      "Epoch [521], loss: 0.6466, acc: 0.7969\n",
      "Epoch [522], loss: 0.8633, acc: 0.7500\n",
      "Epoch [523], loss: 0.5996, acc: 0.8594\n",
      "Epoch [524], loss: 0.5150, acc: 0.9062\n",
      "Epoch [525], loss: 0.5455, acc: 0.7969\n",
      "Epoch [526], loss: 0.7557, acc: 0.7188\n",
      "Epoch [527], loss: 0.6529, acc: 0.7500\n",
      "Epoch [528], loss: 0.5433, acc: 0.8594\n",
      "Epoch [529], loss: 0.7310, acc: 0.7500\n",
      "Epoch [530], loss: 0.8210, acc: 0.7031\n",
      "Epoch [531], loss: 0.6674, acc: 0.7969\n",
      "Epoch [532], loss: 0.6732, acc: 0.7500\n",
      "Epoch [533], loss: 0.6927, acc: 0.7344\n",
      "Epoch [534], loss: 0.7487, acc: 0.7500\n",
      "Epoch [535], loss: 0.6465, acc: 0.7656\n",
      "Epoch [536], loss: 0.7603, acc: 0.7500\n",
      "Epoch [537], loss: 0.8014, acc: 0.6562\n",
      "Epoch [538], loss: 0.6437, acc: 0.7031\n",
      "Epoch [539], loss: 0.7272, acc: 0.7500\n",
      "Epoch [540], loss: 0.8051, acc: 0.7344\n",
      "Epoch [541], loss: 0.8612, acc: 0.7344\n",
      "Epoch [542], loss: 0.5573, acc: 0.7969\n",
      "Epoch [543], loss: 0.6058, acc: 0.7656\n",
      "Epoch [544], loss: 0.4471, acc: 0.8594\n",
      "Epoch [545], loss: 0.6266, acc: 0.7969\n",
      "Epoch [546], loss: 0.4714, acc: 0.8594\n",
      "Epoch [547], loss: 0.4785, acc: 0.8281\n",
      "Epoch [548], loss: 0.6382, acc: 0.7969\n",
      "Epoch [549], loss: 0.5809, acc: 0.8594\n",
      "Epoch [550], loss: 0.5921, acc: 0.8125\n",
      "Epoch [551], loss: 0.6458, acc: 0.7031\n",
      "Epoch [552], loss: 0.4597, acc: 0.8906\n",
      "Epoch [553], loss: 0.5537, acc: 0.7969\n",
      "Epoch [554], loss: 0.4268, acc: 0.8906\n",
      "Epoch [555], loss: 0.5127, acc: 0.7969\n",
      "Epoch [556], loss: 0.6185, acc: 0.7656\n",
      "Epoch [557], loss: 0.4853, acc: 0.8750\n",
      "Epoch [558], loss: 0.5053, acc: 0.8281\n",
      "Epoch [559], loss: 0.4878, acc: 0.8750\n",
      "Epoch [560], loss: 0.5697, acc: 0.8438\n",
      "Epoch [561], loss: 0.4185, acc: 0.8281\n",
      "Epoch [562], loss: 0.5616, acc: 0.8281\n",
      "Epoch [563], loss: 0.5868, acc: 0.7969\n",
      "Epoch [564], loss: 0.6669, acc: 0.7344\n",
      "Epoch [565], loss: 0.5197, acc: 0.8906\n",
      "Epoch [566], loss: 0.5822, acc: 0.8281\n",
      "Epoch [567], loss: 0.7971, acc: 0.7500\n",
      "Epoch [568], loss: 0.5875, acc: 0.8125\n",
      "Epoch [569], loss: 0.7462, acc: 0.8281\n",
      "Epoch [570], loss: 0.5583, acc: 0.7500\n",
      "Epoch [571], loss: 0.4205, acc: 0.8594\n",
      "Epoch [572], loss: 0.7245, acc: 0.6875\n",
      "Epoch [573], loss: 0.4295, acc: 0.8281\n",
      "Epoch [574], loss: 0.6707, acc: 0.7969\n",
      "Epoch [575], loss: 0.3928, acc: 0.8750\n",
      "Epoch [576], loss: 0.4951, acc: 0.8438\n",
      "Epoch [577], loss: 0.5756, acc: 0.7656\n",
      "Epoch [578], loss: 0.6891, acc: 0.7500\n",
      "Epoch [579], loss: 0.4531, acc: 0.8281\n",
      "Epoch [580], loss: 0.4886, acc: 0.8438\n",
      "Epoch [581], loss: 0.7857, acc: 0.6719\n",
      "Epoch [582], loss: 0.6043, acc: 0.8125\n",
      "Epoch [583], loss: 0.4796, acc: 0.8594\n",
      "Epoch [584], loss: 0.5692, acc: 0.8438\n",
      "Epoch [585], loss: 0.4677, acc: 0.8281\n",
      "Epoch [586], loss: 0.6547, acc: 0.7812\n",
      "Epoch [587], loss: 0.7300, acc: 0.6875\n",
      "Epoch [588], loss: 0.5367, acc: 0.8906\n",
      "Epoch [589], loss: 0.3292, acc: 0.9219\n",
      "Epoch [590], loss: 0.7130, acc: 0.7812\n",
      "Epoch [591], loss: 0.5610, acc: 0.7656\n",
      "Epoch [592], loss: 0.4517, acc: 0.8594\n",
      "Epoch [593], loss: 0.5215, acc: 0.8125\n",
      "Epoch [594], loss: 0.5788, acc: 0.8125\n",
      "Epoch [595], loss: 0.6486, acc: 0.7344\n",
      "Epoch [596], loss: 0.5374, acc: 0.7812\n",
      "Epoch [597], loss: 0.4948, acc: 0.8125\n",
      "Epoch [598], loss: 0.5425, acc: 0.8594\n",
      "Epoch [599], loss: 0.6265, acc: 0.7969\n",
      "\n",
      "Checkpoints/0a600model.ckpt Model Saved...\n",
      "Epoch [600], loss: 0.6697, acc: 0.7656\n",
      "Epoch [601], loss: 0.3634, acc: 0.8906\n",
      "Epoch [602], loss: 0.6855, acc: 0.7500\n",
      "Epoch [603], loss: 0.6136, acc: 0.8438\n",
      "Epoch [604], loss: 0.6896, acc: 0.7344\n",
      "Epoch [605], loss: 0.5909, acc: 0.7500\n",
      "Epoch [606], loss: 0.5049, acc: 0.8281\n",
      "Epoch [607], loss: 0.5553, acc: 0.8125\n",
      "Epoch [608], loss: 0.5951, acc: 0.8125\n",
      "Epoch [609], loss: 0.6884, acc: 0.7500\n",
      "Epoch [610], loss: 0.4812, acc: 0.8750\n",
      "Epoch [611], loss: 0.5839, acc: 0.8281\n",
      "Epoch [612], loss: 0.4875, acc: 0.8438\n",
      "Epoch [613], loss: 0.4278, acc: 0.8750\n",
      "Epoch [614], loss: 0.7805, acc: 0.7500\n",
      "Epoch [615], loss: 0.6074, acc: 0.8281\n",
      "Epoch [616], loss: 0.5071, acc: 0.7812\n",
      "Epoch [617], loss: 0.6816, acc: 0.7500\n",
      "Epoch [618], loss: 0.6481, acc: 0.7656\n",
      "Epoch [619], loss: 0.5280, acc: 0.7969\n",
      "Epoch [620], loss: 0.7257, acc: 0.7812\n",
      "Epoch [621], loss: 0.8316, acc: 0.6719\n",
      "Epoch [622], loss: 0.3639, acc: 0.9375\n",
      "Epoch [623], loss: 0.7010, acc: 0.7656\n",
      "Epoch [624], loss: 0.5717, acc: 0.8750\n",
      "Epoch [625], loss: 0.5851, acc: 0.7812\n",
      "Epoch [626], loss: 0.6188, acc: 0.7344\n",
      "Epoch [627], loss: 0.6782, acc: 0.8125\n",
      "Epoch [628], loss: 0.5683, acc: 0.7656\n",
      "Epoch [629], loss: 0.6700, acc: 0.7500\n",
      "Epoch [630], loss: 0.6626, acc: 0.7031\n",
      "Epoch [631], loss: 0.6336, acc: 0.7500\n",
      "Epoch [632], loss: 0.4922, acc: 0.8594\n",
      "Epoch [633], loss: 0.4196, acc: 0.8594\n",
      "Epoch [634], loss: 0.3832, acc: 0.8594\n",
      "Epoch [635], loss: 0.3929, acc: 0.8438\n",
      "Epoch [636], loss: 0.4792, acc: 0.8281\n",
      "Epoch [637], loss: 0.5542, acc: 0.8438\n",
      "Epoch [638], loss: 0.4783, acc: 0.8906\n",
      "Epoch [639], loss: 0.4577, acc: 0.8281\n",
      "Epoch [640], loss: 0.6296, acc: 0.7500\n",
      "Epoch [641], loss: 0.5736, acc: 0.7969\n",
      "Epoch [642], loss: 0.4999, acc: 0.8125\n",
      "Epoch [643], loss: 0.3867, acc: 0.8594\n",
      "Epoch [644], loss: 0.5802, acc: 0.8281\n",
      "Epoch [645], loss: 0.5735, acc: 0.8750\n",
      "Epoch [646], loss: 0.5635, acc: 0.8594\n",
      "Epoch [647], loss: 0.5774, acc: 0.8281\n",
      "Epoch [648], loss: 0.4396, acc: 0.8750\n",
      "Epoch [649], loss: 0.5184, acc: 0.8594\n",
      "Epoch [650], loss: 0.6011, acc: 0.8281\n",
      "Epoch [651], loss: 0.5874, acc: 0.7812\n",
      "Epoch [652], loss: 0.3284, acc: 0.9062\n",
      "Epoch [653], loss: 0.6453, acc: 0.7969\n",
      "Epoch [654], loss: 0.6647, acc: 0.7812\n",
      "Epoch [655], loss: 0.5400, acc: 0.8438\n",
      "Epoch [656], loss: 0.4725, acc: 0.8125\n",
      "Epoch [657], loss: 0.3639, acc: 0.8906\n",
      "Epoch [658], loss: 0.5332, acc: 0.7812\n",
      "Epoch [659], loss: 0.4648, acc: 0.8125\n",
      "Epoch [660], loss: 0.5142, acc: 0.8281\n",
      "Epoch [661], loss: 0.5689, acc: 0.8125\n",
      "Epoch [662], loss: 0.6102, acc: 0.7500\n",
      "Epoch [663], loss: 0.5950, acc: 0.7969\n",
      "Epoch [664], loss: 0.2828, acc: 0.9062\n",
      "Epoch [665], loss: 0.4647, acc: 0.8594\n",
      "Epoch [666], loss: 0.5331, acc: 0.8750\n",
      "Epoch [667], loss: 0.6407, acc: 0.7969\n",
      "Epoch [668], loss: 0.3983, acc: 0.8906\n",
      "Epoch [669], loss: 0.5181, acc: 0.8594\n",
      "Epoch [670], loss: 0.6070, acc: 0.8281\n",
      "Epoch [671], loss: 0.7833, acc: 0.7500\n",
      "Epoch [672], loss: 0.4814, acc: 0.8594\n",
      "Epoch [673], loss: 0.4214, acc: 0.9062\n",
      "Epoch [674], loss: 0.8867, acc: 0.7188\n",
      "Epoch [675], loss: 0.5007, acc: 0.8438\n",
      "Epoch [676], loss: 0.4267, acc: 0.8594\n",
      "Epoch [677], loss: 0.4931, acc: 0.7969\n",
      "Epoch [678], loss: 0.3711, acc: 0.9062\n",
      "Epoch [679], loss: 0.9453, acc: 0.6562\n",
      "Epoch [680], loss: 0.3075, acc: 0.9062\n",
      "Epoch [681], loss: 0.5776, acc: 0.8438\n",
      "Epoch [682], loss: 0.5921, acc: 0.7812\n",
      "Epoch [683], loss: 0.5356, acc: 0.8125\n",
      "Epoch [684], loss: 0.6083, acc: 0.7812\n",
      "Epoch [685], loss: 0.3510, acc: 0.9062\n",
      "Epoch [686], loss: 0.7154, acc: 0.7812\n",
      "Epoch [687], loss: 0.5252, acc: 0.8281\n",
      "Epoch [688], loss: 0.5848, acc: 0.8750\n",
      "Epoch [689], loss: 0.5054, acc: 0.8281\n",
      "Epoch [690], loss: 0.6356, acc: 0.7969\n",
      "Epoch [691], loss: 0.3847, acc: 0.9062\n",
      "Epoch [692], loss: 0.5262, acc: 0.8438\n",
      "Epoch [693], loss: 0.4903, acc: 0.8281\n",
      "Epoch [694], loss: 0.6770, acc: 0.7656\n",
      "Epoch [695], loss: 0.5067, acc: 0.8125\n",
      "Epoch [696], loss: 0.7208, acc: 0.7344\n",
      "Epoch [697], loss: 0.5533, acc: 0.7969\n",
      "Epoch [698], loss: 0.4993, acc: 0.8281\n",
      "Epoch [699], loss: 0.5718, acc: 0.8125\n",
      "\n",
      "Checkpoints/0a700model.ckpt Model Saved...\n",
      "Epoch [700], loss: 0.5597, acc: 0.8438\n",
      "Epoch [701], loss: 0.4316, acc: 0.8750\n",
      "Epoch [702], loss: 0.4710, acc: 0.8594\n",
      "Epoch [703], loss: 0.2997, acc: 0.9062\n",
      "Epoch [704], loss: 0.6517, acc: 0.8125\n",
      "Epoch [705], loss: 0.5655, acc: 0.8125\n",
      "Epoch [706], loss: 0.5712, acc: 0.7500\n",
      "Epoch [707], loss: 0.7112, acc: 0.7656\n",
      "Epoch [708], loss: 0.6063, acc: 0.7812\n",
      "Epoch [709], loss: 0.4112, acc: 0.8438\n",
      "Epoch [710], loss: 0.4811, acc: 0.8281\n",
      "Epoch [711], loss: 0.4692, acc: 0.8125\n",
      "Epoch [712], loss: 0.4720, acc: 0.8438\n",
      "Epoch [713], loss: 0.3397, acc: 0.9062\n",
      "Epoch [714], loss: 0.5718, acc: 0.8125\n",
      "Epoch [715], loss: 0.5117, acc: 0.8125\n",
      "Epoch [716], loss: 0.6682, acc: 0.7500\n",
      "Epoch [717], loss: 0.4596, acc: 0.8906\n",
      "Epoch [718], loss: 0.4839, acc: 0.8594\n",
      "Epoch [719], loss: 0.5565, acc: 0.7969\n",
      "Epoch [720], loss: 0.3397, acc: 0.8906\n",
      "Epoch [721], loss: 0.4728, acc: 0.8594\n",
      "Epoch [722], loss: 0.5417, acc: 0.8281\n",
      "Epoch [723], loss: 0.5386, acc: 0.8125\n",
      "Epoch [724], loss: 0.3910, acc: 0.8281\n",
      "Epoch [725], loss: 0.4750, acc: 0.8594\n",
      "Epoch [726], loss: 0.6411, acc: 0.7812\n",
      "Epoch [727], loss: 0.5737, acc: 0.8125\n",
      "Epoch [728], loss: 0.3910, acc: 0.9062\n",
      "Epoch [729], loss: 0.4725, acc: 0.8750\n",
      "Epoch [730], loss: 0.4670, acc: 0.8594\n",
      "Epoch [731], loss: 0.5178, acc: 0.8438\n",
      "Epoch [732], loss: 0.5188, acc: 0.8281\n",
      "Epoch [733], loss: 0.5609, acc: 0.8438\n",
      "Epoch [734], loss: 0.3664, acc: 0.8438\n",
      "Epoch [735], loss: 0.4107, acc: 0.9062\n",
      "Epoch [736], loss: 0.7693, acc: 0.7031\n",
      "Epoch [737], loss: 0.6060, acc: 0.7812\n",
      "Epoch [738], loss: 0.4217, acc: 0.8594\n",
      "Epoch [739], loss: 0.5949, acc: 0.8125\n",
      "Epoch [740], loss: 0.4686, acc: 0.8125\n",
      "Epoch [741], loss: 0.3663, acc: 0.9219\n",
      "Epoch [742], loss: 0.5944, acc: 0.8125\n",
      "Epoch [743], loss: 0.3604, acc: 0.8906\n",
      "Epoch [744], loss: 0.3444, acc: 0.8906\n",
      "Epoch [745], loss: 0.5951, acc: 0.7344\n",
      "Epoch [746], loss: 0.4477, acc: 0.8438\n",
      "Epoch [747], loss: 0.4967, acc: 0.7812\n",
      "Epoch [748], loss: 0.5882, acc: 0.7500\n",
      "Epoch [749], loss: 0.2982, acc: 0.9062\n",
      "Epoch [750], loss: 0.5045, acc: 0.8438\n",
      "Epoch [751], loss: 0.3900, acc: 0.9219\n",
      "Epoch [752], loss: 0.5918, acc: 0.8125\n",
      "Epoch [753], loss: 0.3228, acc: 0.9062\n",
      "Epoch [754], loss: 0.6768, acc: 0.8125\n",
      "Epoch [755], loss: 0.5426, acc: 0.8750\n",
      "Epoch [756], loss: 0.5547, acc: 0.8750\n",
      "Epoch [757], loss: 0.4058, acc: 0.8281\n",
      "Epoch [758], loss: 0.6587, acc: 0.7500\n",
      "Epoch [759], loss: 0.4252, acc: 0.8750\n",
      "Epoch [760], loss: 0.5765, acc: 0.7344\n",
      "Epoch [761], loss: 0.2984, acc: 0.8906\n",
      "Epoch [762], loss: 0.4537, acc: 0.8438\n",
      "Epoch [763], loss: 0.4725, acc: 0.8750\n",
      "Epoch [764], loss: 0.4613, acc: 0.8594\n",
      "Epoch [765], loss: 0.5238, acc: 0.7812\n",
      "Epoch [766], loss: 0.6330, acc: 0.7969\n",
      "Epoch [767], loss: 0.5953, acc: 0.8281\n",
      "Epoch [768], loss: 0.4430, acc: 0.8750\n",
      "Epoch [769], loss: 0.4646, acc: 0.8750\n",
      "Epoch [770], loss: 0.5962, acc: 0.7812\n",
      "Epoch [771], loss: 0.8135, acc: 0.7656\n",
      "Epoch [772], loss: 0.4380, acc: 0.9062\n",
      "Epoch [773], loss: 0.3948, acc: 0.8750\n",
      "Epoch [774], loss: 0.5707, acc: 0.8125\n",
      "Epoch [775], loss: 0.4327, acc: 0.8125\n",
      "Epoch [776], loss: 0.4005, acc: 0.8906\n",
      "Epoch [777], loss: 0.6354, acc: 0.7969\n",
      "Epoch [778], loss: 0.5096, acc: 0.8281\n",
      "Epoch [779], loss: 0.6065, acc: 0.7969\n",
      "Epoch [780], loss: 0.4787, acc: 0.8438\n",
      "\n",
      "Checkpoints/0model.ckpt Model Saved...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10eceba2d8a34581a7e0332c8965bfed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checkpoints/1a0model.ckpt Model Saved...\n",
      "Epoch [781], loss: 0.6137, acc: 0.8281\n",
      "Epoch [782], loss: 0.9823, acc: 0.6875\n",
      "Epoch [783], loss: 0.6336, acc: 0.8281\n",
      "Epoch [784], loss: 0.4234, acc: 0.8594\n",
      "Epoch [785], loss: 0.6906, acc: 0.7500\n",
      "Epoch [786], loss: 0.5341, acc: 0.7969\n",
      "Epoch [787], loss: 0.5493, acc: 0.8281\n",
      "Epoch [788], loss: 0.4741, acc: 0.8750\n",
      "Epoch [789], loss: 0.4276, acc: 0.8750\n",
      "Epoch [790], loss: 0.4146, acc: 0.8750\n",
      "Epoch [791], loss: 0.6388, acc: 0.7812\n",
      "Epoch [792], loss: 0.4691, acc: 0.8438\n",
      "Epoch [793], loss: 0.4303, acc: 0.8438\n",
      "Epoch [794], loss: 0.3133, acc: 0.9219\n",
      "Epoch [795], loss: 0.5535, acc: 0.7812\n",
      "Epoch [796], loss: 0.4315, acc: 0.8281\n",
      "Epoch [797], loss: 0.3748, acc: 0.8906\n",
      "Epoch [798], loss: 0.6574, acc: 0.7812\n",
      "Epoch [799], loss: 0.4112, acc: 0.8594\n",
      "Epoch [800], loss: 0.3925, acc: 0.9219\n",
      "Epoch [801], loss: 0.3702, acc: 0.8750\n",
      "Epoch [802], loss: 0.6549, acc: 0.7344\n",
      "Epoch [803], loss: 0.4916, acc: 0.8750\n",
      "Epoch [804], loss: 0.5392, acc: 0.8281\n",
      "Epoch [805], loss: 0.7142, acc: 0.7500\n",
      "Epoch [806], loss: 0.6146, acc: 0.7812\n",
      "Epoch [807], loss: 0.3954, acc: 0.8594\n",
      "Epoch [808], loss: 0.5862, acc: 0.8438\n",
      "Epoch [809], loss: 0.4628, acc: 0.8906\n",
      "Epoch [810], loss: 0.5303, acc: 0.8594\n",
      "Epoch [811], loss: 0.6961, acc: 0.7656\n",
      "Epoch [812], loss: 0.6517, acc: 0.7969\n",
      "Epoch [813], loss: 0.5203, acc: 0.8281\n",
      "Epoch [814], loss: 0.6373, acc: 0.7812\n",
      "Epoch [815], loss: 0.3821, acc: 0.8750\n",
      "Epoch [816], loss: 0.4138, acc: 0.8438\n",
      "Epoch [817], loss: 0.5288, acc: 0.7812\n",
      "Epoch [818], loss: 0.6278, acc: 0.7969\n",
      "Epoch [819], loss: 0.4068, acc: 0.8125\n",
      "Epoch [820], loss: 0.5616, acc: 0.8281\n",
      "Epoch [821], loss: 0.4735, acc: 0.8125\n",
      "Epoch [822], loss: 0.4407, acc: 0.8281\n",
      "Epoch [823], loss: 0.7165, acc: 0.7031\n",
      "Epoch [824], loss: 0.8026, acc: 0.7656\n",
      "Epoch [825], loss: 0.4941, acc: 0.8438\n",
      "Epoch [826], loss: 0.6582, acc: 0.7969\n",
      "Epoch [827], loss: 0.4144, acc: 0.8906\n",
      "Epoch [828], loss: 0.5034, acc: 0.8438\n",
      "Epoch [829], loss: 0.5232, acc: 0.8594\n",
      "Epoch [830], loss: 0.4159, acc: 0.8438\n",
      "Epoch [831], loss: 0.7112, acc: 0.7656\n",
      "Epoch [832], loss: 0.6005, acc: 0.7188\n",
      "Epoch [833], loss: 0.4080, acc: 0.8281\n",
      "Epoch [834], loss: 0.6732, acc: 0.7812\n",
      "Epoch [835], loss: 0.5435, acc: 0.8281\n",
      "Epoch [836], loss: 0.6272, acc: 0.7812\n",
      "Epoch [837], loss: 0.6430, acc: 0.7656\n",
      "Epoch [838], loss: 0.5212, acc: 0.7969\n",
      "Epoch [839], loss: 0.4025, acc: 0.8594\n",
      "Epoch [840], loss: 0.4391, acc: 0.8750\n",
      "Epoch [841], loss: 0.3528, acc: 0.9219\n",
      "Epoch [842], loss: 0.6125, acc: 0.7344\n",
      "Epoch [843], loss: 0.4300, acc: 0.8906\n",
      "Epoch [844], loss: 0.5367, acc: 0.8281\n",
      "Epoch [845], loss: 0.4426, acc: 0.8750\n",
      "Epoch [846], loss: 0.4218, acc: 0.8750\n",
      "Epoch [847], loss: 0.5211, acc: 0.8594\n",
      "Epoch [848], loss: 0.6239, acc: 0.7656\n",
      "Epoch [849], loss: 0.5028, acc: 0.8438\n",
      "Epoch [850], loss: 0.5830, acc: 0.8438\n",
      "Epoch [851], loss: 0.3872, acc: 0.8281\n",
      "Epoch [852], loss: 0.5622, acc: 0.8750\n",
      "Epoch [853], loss: 0.5121, acc: 0.8594\n",
      "Epoch [854], loss: 0.6757, acc: 0.7812\n",
      "Epoch [855], loss: 0.5204, acc: 0.7969\n",
      "Epoch [856], loss: 0.5656, acc: 0.8281\n",
      "Epoch [857], loss: 0.6363, acc: 0.7656\n",
      "Epoch [858], loss: 0.4278, acc: 0.8594\n",
      "Epoch [859], loss: 0.4902, acc: 0.8594\n",
      "Epoch [860], loss: 0.6748, acc: 0.7500\n",
      "Epoch [861], loss: 0.5377, acc: 0.7812\n",
      "Epoch [862], loss: 0.5216, acc: 0.8750\n",
      "Epoch [863], loss: 0.4659, acc: 0.8281\n",
      "Epoch [864], loss: 0.5564, acc: 0.8438\n",
      "Epoch [865], loss: 0.6006, acc: 0.8594\n",
      "Epoch [866], loss: 0.4953, acc: 0.8281\n",
      "Epoch [867], loss: 0.3158, acc: 0.8906\n",
      "Epoch [868], loss: 0.4026, acc: 0.8438\n",
      "Epoch [869], loss: 0.4666, acc: 0.8750\n",
      "Epoch [870], loss: 0.4512, acc: 0.8594\n",
      "Epoch [871], loss: 0.4788, acc: 0.8594\n",
      "Epoch [872], loss: 0.4193, acc: 0.8281\n",
      "Epoch [873], loss: 0.4148, acc: 0.8125\n",
      "Epoch [874], loss: 0.4169, acc: 0.8594\n",
      "Epoch [875], loss: 0.2664, acc: 0.9219\n",
      "Epoch [876], loss: 0.7688, acc: 0.7188\n",
      "Epoch [877], loss: 0.4872, acc: 0.8438\n",
      "Epoch [878], loss: 0.5722, acc: 0.8125\n",
      "Epoch [879], loss: 0.6575, acc: 0.8125\n",
      "Epoch [880], loss: 0.5239, acc: 0.8281\n",
      "\n",
      "Checkpoints/1a100model.ckpt Model Saved...\n",
      "Epoch [881], loss: 0.3914, acc: 0.8750\n",
      "Epoch [882], loss: 0.5486, acc: 0.7969\n",
      "Epoch [883], loss: 0.4013, acc: 0.8750\n",
      "Epoch [884], loss: 0.4768, acc: 0.8594\n",
      "Epoch [885], loss: 0.5091, acc: 0.8281\n",
      "Epoch [886], loss: 0.6817, acc: 0.7656\n",
      "Epoch [887], loss: 0.6500, acc: 0.8438\n",
      "Epoch [888], loss: 0.3011, acc: 0.9219\n",
      "Epoch [889], loss: 0.3807, acc: 0.8750\n",
      "Epoch [890], loss: 0.6582, acc: 0.7969\n",
      "Epoch [891], loss: 0.4846, acc: 0.7969\n",
      "Epoch [892], loss: 0.3896, acc: 0.8750\n",
      "Epoch [893], loss: 0.4514, acc: 0.8125\n",
      "Epoch [894], loss: 0.3704, acc: 0.8438\n",
      "Epoch [895], loss: 0.5420, acc: 0.7969\n",
      "Epoch [896], loss: 0.7433, acc: 0.7344\n",
      "Epoch [897], loss: 0.4666, acc: 0.8438\n",
      "Epoch [898], loss: 0.4603, acc: 0.8750\n",
      "Epoch [899], loss: 0.4928, acc: 0.8750\n",
      "Epoch [900], loss: 0.3998, acc: 0.8594\n",
      "Epoch [901], loss: 0.5165, acc: 0.7969\n",
      "Epoch [902], loss: 0.5494, acc: 0.8438\n",
      "Epoch [903], loss: 0.5140, acc: 0.8594\n",
      "Epoch [904], loss: 0.3802, acc: 0.8750\n",
      "Epoch [905], loss: 0.4515, acc: 0.8906\n",
      "Epoch [906], loss: 0.5442, acc: 0.8281\n",
      "Epoch [907], loss: 0.4287, acc: 0.8750\n",
      "Epoch [908], loss: 0.4075, acc: 0.8594\n",
      "Epoch [909], loss: 0.4824, acc: 0.8906\n",
      "Epoch [910], loss: 0.7408, acc: 0.7344\n",
      "Epoch [911], loss: 0.4809, acc: 0.8281\n",
      "Epoch [912], loss: 0.5066, acc: 0.7969\n",
      "Epoch [913], loss: 0.3742, acc: 0.8750\n",
      "Epoch [914], loss: 0.4035, acc: 0.8594\n",
      "Epoch [915], loss: 0.4694, acc: 0.8750\n",
      "Epoch [916], loss: 0.6196, acc: 0.7812\n",
      "Epoch [917], loss: 0.5633, acc: 0.7969\n",
      "Epoch [918], loss: 0.4282, acc: 0.8906\n",
      "Epoch [919], loss: 0.3894, acc: 0.8906\n",
      "Epoch [920], loss: 0.3160, acc: 0.9531\n",
      "Epoch [921], loss: 0.5514, acc: 0.7812\n",
      "Epoch [922], loss: 0.4388, acc: 0.8594\n",
      "Epoch [923], loss: 0.5665, acc: 0.8281\n",
      "Epoch [924], loss: 0.6486, acc: 0.7500\n",
      "Epoch [925], loss: 0.5241, acc: 0.8281\n",
      "Epoch [926], loss: 0.4516, acc: 0.7969\n",
      "Epoch [927], loss: 0.3601, acc: 0.8750\n",
      "Epoch [928], loss: 0.5148, acc: 0.8281\n",
      "Epoch [929], loss: 0.3332, acc: 0.9375\n",
      "Epoch [930], loss: 0.5552, acc: 0.8281\n",
      "Epoch [931], loss: 0.3572, acc: 0.9531\n",
      "Epoch [932], loss: 0.4976, acc: 0.8125\n",
      "Epoch [933], loss: 0.4010, acc: 0.8906\n",
      "Epoch [934], loss: 0.2986, acc: 0.9375\n",
      "Epoch [935], loss: 0.3684, acc: 0.8906\n",
      "Epoch [936], loss: 0.4119, acc: 0.8906\n",
      "Epoch [937], loss: 0.4413, acc: 0.8750\n",
      "Epoch [938], loss: 0.5290, acc: 0.8125\n",
      "Epoch [939], loss: 0.4916, acc: 0.7969\n",
      "Epoch [940], loss: 0.3159, acc: 0.9531\n",
      "Epoch [941], loss: 0.4114, acc: 0.8906\n",
      "Epoch [942], loss: 0.3709, acc: 0.8750\n",
      "Epoch [943], loss: 0.5747, acc: 0.7812\n",
      "Epoch [944], loss: 0.4107, acc: 0.8906\n",
      "Epoch [945], loss: 0.3647, acc: 0.8750\n",
      "Epoch [946], loss: 0.4415, acc: 0.8594\n",
      "Epoch [947], loss: 0.2888, acc: 0.9062\n",
      "Epoch [948], loss: 0.7251, acc: 0.7344\n",
      "Epoch [949], loss: 0.5710, acc: 0.8281\n",
      "Epoch [950], loss: 0.5100, acc: 0.8125\n",
      "Epoch [951], loss: 0.3422, acc: 0.8750\n",
      "Epoch [952], loss: 0.5171, acc: 0.8438\n",
      "Epoch [953], loss: 0.4549, acc: 0.8594\n",
      "Epoch [954], loss: 0.4092, acc: 0.8594\n",
      "Epoch [955], loss: 0.5426, acc: 0.7969\n",
      "Epoch [956], loss: 0.5010, acc: 0.8438\n",
      "Epoch [957], loss: 0.4123, acc: 0.8750\n",
      "Epoch [958], loss: 0.5839, acc: 0.8438\n",
      "Epoch [959], loss: 0.3376, acc: 0.8750\n",
      "Epoch [960], loss: 0.6743, acc: 0.7656\n",
      "Epoch [961], loss: 0.4013, acc: 0.9375\n",
      "Epoch [962], loss: 0.4333, acc: 0.8438\n",
      "Epoch [963], loss: 0.3606, acc: 0.8906\n",
      "Epoch [964], loss: 0.4813, acc: 0.8594\n",
      "Epoch [965], loss: 0.3013, acc: 0.9062\n",
      "Epoch [966], loss: 0.5593, acc: 0.8125\n",
      "Epoch [967], loss: 0.4715, acc: 0.8906\n",
      "Epoch [968], loss: 0.4001, acc: 0.8594\n",
      "Epoch [969], loss: 0.4700, acc: 0.8438\n",
      "Epoch [970], loss: 0.2781, acc: 0.9219\n",
      "Epoch [971], loss: 0.4583, acc: 0.8594\n",
      "Epoch [972], loss: 0.5626, acc: 0.8281\n",
      "Epoch [973], loss: 0.3723, acc: 0.9219\n",
      "Epoch [974], loss: 0.3525, acc: 0.8594\n",
      "Epoch [975], loss: 0.3463, acc: 0.8750\n",
      "Epoch [976], loss: 0.3931, acc: 0.8750\n",
      "Epoch [977], loss: 0.4149, acc: 0.8750\n",
      "Epoch [978], loss: 0.4376, acc: 0.8281\n",
      "Epoch [979], loss: 0.3902, acc: 0.8750\n",
      "Epoch [980], loss: 0.3828, acc: 0.8594\n",
      "\n",
      "Checkpoints/1a200model.ckpt Model Saved...\n",
      "Epoch [981], loss: 0.5293, acc: 0.8750\n",
      "Epoch [982], loss: 0.3260, acc: 0.9062\n",
      "Epoch [983], loss: 0.8030, acc: 0.7344\n",
      "Epoch [984], loss: 0.5273, acc: 0.7969\n",
      "Epoch [985], loss: 0.5476, acc: 0.7969\n",
      "Epoch [986], loss: 0.3925, acc: 0.8750\n",
      "Epoch [987], loss: 0.4378, acc: 0.8281\n",
      "Epoch [988], loss: 0.4877, acc: 0.7812\n",
      "Epoch [989], loss: 0.4458, acc: 0.8281\n",
      "Epoch [990], loss: 0.3969, acc: 0.8906\n",
      "Epoch [991], loss: 0.4615, acc: 0.8750\n",
      "Epoch [992], loss: 0.3302, acc: 0.8750\n",
      "Epoch [993], loss: 0.5786, acc: 0.8125\n",
      "Epoch [994], loss: 0.5340, acc: 0.8125\n",
      "Epoch [995], loss: 0.5148, acc: 0.7969\n",
      "Epoch [996], loss: 0.4646, acc: 0.8438\n",
      "Epoch [997], loss: 0.4519, acc: 0.8438\n",
      "Epoch [998], loss: 0.3460, acc: 0.8750\n",
      "Epoch [999], loss: 0.3190, acc: 0.9062\n",
      "Epoch [1000], loss: 0.3859, acc: 0.8438\n",
      "Epoch [1001], loss: 0.5028, acc: 0.8281\n",
      "Epoch [1002], loss: 0.3123, acc: 0.9062\n",
      "Epoch [1003], loss: 0.5753, acc: 0.8438\n",
      "Epoch [1004], loss: 0.4866, acc: 0.8281\n",
      "Epoch [1005], loss: 0.4349, acc: 0.8438\n",
      "Epoch [1006], loss: 0.4328, acc: 0.8750\n",
      "Epoch [1007], loss: 0.2886, acc: 0.9219\n",
      "Epoch [1008], loss: 0.4665, acc: 0.8438\n",
      "Epoch [1009], loss: 0.3806, acc: 0.8906\n",
      "Epoch [1010], loss: 0.4073, acc: 0.8594\n",
      "Epoch [1011], loss: 0.5509, acc: 0.7969\n",
      "Epoch [1012], loss: 0.5007, acc: 0.8438\n",
      "Epoch [1013], loss: 0.3762, acc: 0.8750\n",
      "Epoch [1014], loss: 0.5276, acc: 0.7969\n",
      "Epoch [1015], loss: 0.5135, acc: 0.8438\n",
      "Epoch [1016], loss: 0.5047, acc: 0.8750\n",
      "Epoch [1017], loss: 0.4063, acc: 0.8906\n",
      "Epoch [1018], loss: 0.5600, acc: 0.8125\n",
      "Epoch [1019], loss: 0.6785, acc: 0.8125\n",
      "Epoch [1020], loss: 0.7980, acc: 0.7031\n",
      "Epoch [1021], loss: 0.4759, acc: 0.8281\n",
      "Epoch [1022], loss: 0.4431, acc: 0.8281\n",
      "Epoch [1023], loss: 0.5676, acc: 0.8438\n",
      "Epoch [1024], loss: 0.6778, acc: 0.7656\n",
      "Epoch [1025], loss: 0.5811, acc: 0.7969\n",
      "Epoch [1026], loss: 0.3552, acc: 0.8906\n",
      "Epoch [1027], loss: 0.5323, acc: 0.7969\n",
      "Epoch [1028], loss: 0.5726, acc: 0.8125\n",
      "Epoch [1029], loss: 0.3828, acc: 0.8750\n",
      "Epoch [1030], loss: 0.3136, acc: 0.9531\n",
      "Epoch [1031], loss: 0.3811, acc: 0.8438\n",
      "Epoch [1032], loss: 0.5632, acc: 0.8438\n",
      "Epoch [1033], loss: 0.5889, acc: 0.7500\n",
      "Epoch [1034], loss: 0.4666, acc: 0.8906\n",
      "Epoch [1035], loss: 0.3155, acc: 0.9219\n",
      "Epoch [1036], loss: 0.4103, acc: 0.8906\n",
      "Epoch [1037], loss: 0.6474, acc: 0.7812\n",
      "Epoch [1038], loss: 0.3593, acc: 0.8438\n",
      "Epoch [1039], loss: 0.3789, acc: 0.8906\n",
      "Epoch [1040], loss: 0.5010, acc: 0.8281\n",
      "Epoch [1041], loss: 0.3670, acc: 0.8906\n",
      "Epoch [1042], loss: 0.4229, acc: 0.8125\n",
      "Epoch [1043], loss: 0.3396, acc: 0.8750\n",
      "Epoch [1044], loss: 0.4910, acc: 0.8750\n",
      "Epoch [1045], loss: 0.4354, acc: 0.8281\n",
      "Epoch [1046], loss: 0.4876, acc: 0.7969\n",
      "Epoch [1047], loss: 0.3495, acc: 0.8750\n",
      "Epoch [1048], loss: 0.4220, acc: 0.8594\n",
      "Epoch [1049], loss: 0.3439, acc: 0.9375\n",
      "Epoch [1050], loss: 0.4600, acc: 0.8750\n",
      "Epoch [1051], loss: 0.4491, acc: 0.8594\n",
      "Epoch [1052], loss: 0.5367, acc: 0.7812\n",
      "Epoch [1053], loss: 0.4294, acc: 0.8438\n",
      "Epoch [1054], loss: 0.5378, acc: 0.8281\n",
      "Epoch [1055], loss: 0.4435, acc: 0.8750\n",
      "Epoch [1056], loss: 0.4523, acc: 0.8594\n",
      "Epoch [1057], loss: 0.5983, acc: 0.7969\n",
      "Epoch [1058], loss: 0.5249, acc: 0.8125\n",
      "Epoch [1059], loss: 0.4532, acc: 0.8438\n",
      "Epoch [1060], loss: 0.3814, acc: 0.8750\n",
      "Epoch [1061], loss: 0.3255, acc: 0.9219\n",
      "Epoch [1062], loss: 0.3944, acc: 0.8594\n",
      "Epoch [1063], loss: 0.4711, acc: 0.7969\n",
      "Epoch [1064], loss: 0.6978, acc: 0.7500\n",
      "Epoch [1065], loss: 0.4494, acc: 0.8125\n",
      "Epoch [1066], loss: 0.2921, acc: 0.9688\n",
      "Epoch [1067], loss: 0.4811, acc: 0.8750\n",
      "Epoch [1068], loss: 0.4461, acc: 0.8750\n",
      "Epoch [1069], loss: 0.4097, acc: 0.9062\n",
      "Epoch [1070], loss: 0.4311, acc: 0.8594\n",
      "Epoch [1071], loss: 0.4552, acc: 0.8906\n",
      "Epoch [1072], loss: 0.5466, acc: 0.7656\n",
      "Epoch [1073], loss: 0.5589, acc: 0.7969\n",
      "Epoch [1074], loss: 0.3614, acc: 0.9219\n",
      "Epoch [1075], loss: 0.4790, acc: 0.7969\n",
      "Epoch [1076], loss: 0.3603, acc: 0.9375\n",
      "Epoch [1077], loss: 0.3591, acc: 0.8750\n",
      "Epoch [1078], loss: 0.2085, acc: 0.9375\n",
      "Epoch [1079], loss: 0.5074, acc: 0.8281\n",
      "Epoch [1080], loss: 0.5517, acc: 0.8281\n",
      "\n",
      "Checkpoints/1a300model.ckpt Model Saved...\n",
      "Epoch [1081], loss: 0.4353, acc: 0.8594\n",
      "Epoch [1082], loss: 0.5600, acc: 0.8438\n",
      "Epoch [1083], loss: 0.3241, acc: 0.8906\n",
      "Epoch [1084], loss: 0.3083, acc: 0.9062\n",
      "Epoch [1085], loss: 0.3178, acc: 0.9062\n",
      "Epoch [1086], loss: 0.4299, acc: 0.7969\n",
      "Epoch [1087], loss: 0.4156, acc: 0.8281\n",
      "Epoch [1088], loss: 0.4702, acc: 0.8438\n",
      "Epoch [1089], loss: 0.3483, acc: 0.9219\n",
      "Epoch [1090], loss: 0.3108, acc: 0.9219\n",
      "Epoch [1091], loss: 0.3455, acc: 0.9219\n",
      "Epoch [1092], loss: 0.3541, acc: 0.8906\n",
      "Epoch [1093], loss: 0.5174, acc: 0.8594\n",
      "Epoch [1094], loss: 0.4449, acc: 0.8281\n",
      "Epoch [1095], loss: 0.5188, acc: 0.7656\n",
      "Epoch [1096], loss: 0.4866, acc: 0.8594\n",
      "Epoch [1097], loss: 0.3942, acc: 0.9062\n",
      "Epoch [1098], loss: 0.2209, acc: 0.9531\n",
      "Epoch [1099], loss: 0.5206, acc: 0.8438\n",
      "Epoch [1100], loss: 0.5159, acc: 0.8594\n",
      "Epoch [1101], loss: 0.4083, acc: 0.8594\n",
      "Epoch [1102], loss: 0.4861, acc: 0.8906\n",
      "Epoch [1103], loss: 0.4268, acc: 0.8438\n",
      "Epoch [1104], loss: 0.4891, acc: 0.8906\n",
      "Epoch [1105], loss: 0.4703, acc: 0.8281\n",
      "Epoch [1106], loss: 0.3645, acc: 0.8750\n",
      "Epoch [1107], loss: 0.2908, acc: 0.8906\n",
      "Epoch [1108], loss: 0.5484, acc: 0.8125\n",
      "Epoch [1109], loss: 0.3970, acc: 0.8438\n",
      "Epoch [1110], loss: 0.7200, acc: 0.7344\n",
      "Epoch [1111], loss: 0.3863, acc: 0.9062\n",
      "Epoch [1112], loss: 0.5648, acc: 0.7812\n",
      "Epoch [1113], loss: 0.3471, acc: 0.9062\n",
      "Epoch [1114], loss: 0.3289, acc: 0.9062\n",
      "Epoch [1115], loss: 0.5098, acc: 0.8281\n",
      "Epoch [1116], loss: 0.4597, acc: 0.7812\n",
      "Epoch [1117], loss: 0.3742, acc: 0.8906\n",
      "Epoch [1118], loss: 0.4470, acc: 0.8594\n",
      "Epoch [1119], loss: 0.3633, acc: 0.9219\n",
      "Epoch [1120], loss: 0.2995, acc: 0.9531\n",
      "Epoch [1121], loss: 0.5349, acc: 0.8125\n",
      "Epoch [1122], loss: 0.4822, acc: 0.8281\n",
      "Epoch [1123], loss: 0.4787, acc: 0.7969\n",
      "Epoch [1124], loss: 0.4934, acc: 0.8438\n",
      "Epoch [1125], loss: 0.2923, acc: 0.9219\n",
      "Epoch [1126], loss: 0.3166, acc: 0.9219\n",
      "Epoch [1127], loss: 0.5761, acc: 0.8594\n",
      "Epoch [1128], loss: 0.3849, acc: 0.8750\n",
      "Epoch [1129], loss: 0.4072, acc: 0.8438\n",
      "Epoch [1130], loss: 0.4309, acc: 0.8594\n",
      "Epoch [1131], loss: 0.2599, acc: 0.8906\n",
      "Epoch [1132], loss: 0.3473, acc: 0.8750\n",
      "Epoch [1133], loss: 0.4770, acc: 0.8594\n",
      "Epoch [1134], loss: 0.3172, acc: 0.9062\n",
      "Epoch [1135], loss: 0.3873, acc: 0.9219\n",
      "Epoch [1136], loss: 0.3444, acc: 0.9062\n",
      "Epoch [1137], loss: 0.4401, acc: 0.8594\n",
      "Epoch [1138], loss: 0.3728, acc: 0.9062\n",
      "Epoch [1139], loss: 0.4360, acc: 0.8594\n",
      "Epoch [1140], loss: 0.3989, acc: 0.8750\n",
      "Epoch [1141], loss: 0.3933, acc: 0.9062\n",
      "Epoch [1142], loss: 0.5402, acc: 0.8281\n",
      "Epoch [1143], loss: 0.3770, acc: 0.8594\n",
      "Epoch [1144], loss: 0.4590, acc: 0.8438\n",
      "Epoch [1145], loss: 0.4373, acc: 0.8594\n",
      "Epoch [1146], loss: 0.3831, acc: 0.8594\n",
      "Epoch [1147], loss: 0.2706, acc: 0.8906\n",
      "Epoch [1148], loss: 0.3200, acc: 0.9062\n",
      "Epoch [1149], loss: 0.4131, acc: 0.8750\n",
      "Epoch [1150], loss: 0.5464, acc: 0.7969\n",
      "Epoch [1151], loss: 0.3755, acc: 0.9062\n",
      "Epoch [1152], loss: 0.4838, acc: 0.8594\n",
      "Epoch [1153], loss: 0.3147, acc: 0.9062\n",
      "Epoch [1154], loss: 0.4611, acc: 0.8438\n",
      "Epoch [1155], loss: 0.4073, acc: 0.8438\n",
      "Epoch [1156], loss: 0.4078, acc: 0.8594\n",
      "Epoch [1157], loss: 0.4381, acc: 0.8594\n",
      "Epoch [1158], loss: 0.3018, acc: 0.9375\n",
      "Epoch [1159], loss: 0.4818, acc: 0.8281\n",
      "Epoch [1160], loss: 0.2524, acc: 0.9219\n",
      "Epoch [1161], loss: 0.3062, acc: 0.9062\n",
      "Epoch [1162], loss: 0.4209, acc: 0.8750\n",
      "Epoch [1163], loss: 0.4769, acc: 0.8125\n",
      "Epoch [1164], loss: 0.5644, acc: 0.8438\n",
      "Epoch [1165], loss: 0.3408, acc: 0.9375\n",
      "Epoch [1166], loss: 0.3247, acc: 0.9219\n",
      "Epoch [1167], loss: 0.4178, acc: 0.9062\n",
      "Epoch [1168], loss: 0.4255, acc: 0.8594\n",
      "Epoch [1169], loss: 0.5158, acc: 0.8594\n",
      "Epoch [1170], loss: 0.3583, acc: 0.9062\n",
      "Epoch [1171], loss: 0.3712, acc: 0.9219\n",
      "Epoch [1172], loss: 0.5344, acc: 0.8906\n",
      "Epoch [1173], loss: 0.3683, acc: 0.8750\n",
      "Epoch [1174], loss: 0.4669, acc: 0.8438\n",
      "Epoch [1175], loss: 0.4837, acc: 0.8906\n",
      "Epoch [1176], loss: 0.3096, acc: 0.9062\n",
      "Epoch [1177], loss: 0.5790, acc: 0.8125\n",
      "Epoch [1178], loss: 0.3798, acc: 0.8594\n",
      "Epoch [1179], loss: 0.4816, acc: 0.8438\n",
      "Epoch [1180], loss: 0.3635, acc: 0.8750\n",
      "\n",
      "Checkpoints/1a400model.ckpt Model Saved...\n",
      "Epoch [1181], loss: 0.4428, acc: 0.8750\n",
      "Epoch [1182], loss: 0.5157, acc: 0.8281\n",
      "Epoch [1183], loss: 0.4849, acc: 0.8125\n",
      "Epoch [1184], loss: 0.3347, acc: 0.9219\n",
      "Epoch [1185], loss: 0.3169, acc: 0.9219\n",
      "Epoch [1186], loss: 0.4359, acc: 0.8906\n",
      "Epoch [1187], loss: 0.3890, acc: 0.9062\n",
      "Epoch [1188], loss: 0.3156, acc: 0.8906\n",
      "Epoch [1189], loss: 0.4872, acc: 0.8750\n",
      "Epoch [1190], loss: 0.4056, acc: 0.8594\n",
      "Epoch [1191], loss: 0.5598, acc: 0.8125\n",
      "Epoch [1192], loss: 0.3731, acc: 0.9062\n",
      "Epoch [1193], loss: 0.3147, acc: 0.9219\n",
      "Epoch [1194], loss: 0.3528, acc: 0.8906\n",
      "Epoch [1195], loss: 0.1940, acc: 0.9688\n",
      "Epoch [1196], loss: 0.4130, acc: 0.8594\n",
      "Epoch [1197], loss: 0.2920, acc: 0.9062\n",
      "Epoch [1198], loss: 0.4840, acc: 0.8281\n",
      "Epoch [1199], loss: 0.3925, acc: 0.8594\n",
      "Epoch [1200], loss: 0.3659, acc: 0.8906\n",
      "Epoch [1201], loss: 0.3872, acc: 0.8906\n",
      "Epoch [1202], loss: 0.2897, acc: 0.8906\n",
      "Epoch [1203], loss: 0.3983, acc: 0.8438\n",
      "Epoch [1204], loss: 0.3286, acc: 0.9531\n",
      "Epoch [1205], loss: 0.3325, acc: 0.9062\n",
      "Epoch [1206], loss: 0.6370, acc: 0.7812\n",
      "Epoch [1207], loss: 0.2459, acc: 0.9375\n",
      "Epoch [1208], loss: 0.4538, acc: 0.8750\n",
      "Epoch [1209], loss: 0.5214, acc: 0.8281\n",
      "Epoch [1210], loss: 0.4306, acc: 0.8750\n",
      "Epoch [1211], loss: 0.3100, acc: 0.9219\n",
      "Epoch [1212], loss: 0.5134, acc: 0.8125\n",
      "Epoch [1213], loss: 0.4259, acc: 0.8906\n",
      "Epoch [1214], loss: 0.4186, acc: 0.8906\n",
      "Epoch [1215], loss: 0.3614, acc: 0.9219\n",
      "Epoch [1216], loss: 0.4768, acc: 0.8438\n",
      "Epoch [1217], loss: 0.3029, acc: 0.9375\n",
      "Epoch [1218], loss: 0.3956, acc: 0.8594\n",
      "Epoch [1219], loss: 0.2710, acc: 0.8906\n",
      "Epoch [1220], loss: 0.3641, acc: 0.9531\n",
      "Epoch [1221], loss: 0.3892, acc: 0.8906\n",
      "Epoch [1222], loss: 0.2728, acc: 0.9219\n",
      "Epoch [1223], loss: 0.4713, acc: 0.8594\n",
      "Epoch [1224], loss: 0.3090, acc: 0.9375\n",
      "Epoch [1225], loss: 0.3151, acc: 0.8906\n",
      "Epoch [1226], loss: 0.2745, acc: 0.9062\n",
      "Epoch [1227], loss: 0.3146, acc: 0.9062\n",
      "Epoch [1228], loss: 0.4153, acc: 0.8906\n",
      "Epoch [1229], loss: 0.6009, acc: 0.8125\n",
      "Epoch [1230], loss: 0.4334, acc: 0.8594\n",
      "Epoch [1231], loss: 0.2199, acc: 0.9844\n",
      "Epoch [1232], loss: 0.3862, acc: 0.8438\n",
      "Epoch [1233], loss: 0.5110, acc: 0.7969\n",
      "Epoch [1234], loss: 0.3941, acc: 0.8750\n",
      "Epoch [1235], loss: 0.6286, acc: 0.8125\n",
      "Epoch [1236], loss: 0.3991, acc: 0.8594\n",
      "Epoch [1237], loss: 0.4552, acc: 0.8594\n",
      "Epoch [1238], loss: 0.5657, acc: 0.7969\n",
      "Epoch [1239], loss: 0.6214, acc: 0.8125\n",
      "Epoch [1240], loss: 0.2647, acc: 0.9375\n",
      "Epoch [1241], loss: 0.4557, acc: 0.8438\n",
      "Epoch [1242], loss: 0.6669, acc: 0.7656\n",
      "Epoch [1243], loss: 0.5745, acc: 0.8281\n",
      "Epoch [1244], loss: 0.4506, acc: 0.8125\n",
      "Epoch [1245], loss: 0.3005, acc: 0.8594\n",
      "Epoch [1246], loss: 0.5407, acc: 0.7969\n",
      "Epoch [1247], loss: 0.3472, acc: 0.8750\n",
      "Epoch [1248], loss: 0.3178, acc: 0.9062\n",
      "Epoch [1249], loss: 0.4995, acc: 0.8438\n",
      "Epoch [1250], loss: 0.4343, acc: 0.8906\n",
      "Epoch [1251], loss: 0.3619, acc: 0.9062\n",
      "Epoch [1252], loss: 0.4329, acc: 0.8438\n",
      "Epoch [1253], loss: 0.3553, acc: 0.8750\n",
      "Epoch [1254], loss: 0.3687, acc: 0.9375\n",
      "Epoch [1255], loss: 0.5192, acc: 0.8438\n",
      "Epoch [1256], loss: 0.3730, acc: 0.9062\n",
      "Epoch [1257], loss: 0.4367, acc: 0.8906\n",
      "Epoch [1258], loss: 0.3510, acc: 0.9062\n",
      "Epoch [1259], loss: 0.4407, acc: 0.8438\n",
      "Epoch [1260], loss: 0.4645, acc: 0.8438\n",
      "Epoch [1261], loss: 0.5112, acc: 0.8438\n",
      "Epoch [1262], loss: 0.3830, acc: 0.8750\n",
      "Epoch [1263], loss: 0.4274, acc: 0.8750\n",
      "Epoch [1264], loss: 0.5964, acc: 0.7812\n",
      "Epoch [1265], loss: 0.4309, acc: 0.8438\n",
      "Epoch [1266], loss: 0.3177, acc: 0.8906\n",
      "Epoch [1267], loss: 0.3229, acc: 0.9062\n",
      "Epoch [1268], loss: 0.3834, acc: 0.8750\n",
      "Epoch [1269], loss: 0.4353, acc: 0.8594\n",
      "Epoch [1270], loss: 0.3173, acc: 0.8750\n",
      "Epoch [1271], loss: 0.4418, acc: 0.8594\n",
      "Epoch [1272], loss: 0.3670, acc: 0.8906\n",
      "Epoch [1273], loss: 0.4527, acc: 0.8906\n",
      "Epoch [1274], loss: 0.4981, acc: 0.7969\n",
      "Epoch [1275], loss: 0.4475, acc: 0.8750\n",
      "Epoch [1276], loss: 0.3397, acc: 0.8438\n",
      "Epoch [1277], loss: 0.4148, acc: 0.8594\n",
      "Epoch [1278], loss: 0.3746, acc: 0.8906\n",
      "Epoch [1279], loss: 0.3625, acc: 0.8906\n",
      "Epoch [1280], loss: 0.3440, acc: 0.9219\n",
      "\n",
      "Checkpoints/1a500model.ckpt Model Saved...\n",
      "Epoch [1281], loss: 0.4077, acc: 0.8438\n",
      "Epoch [1282], loss: 0.5186, acc: 0.8594\n",
      "Epoch [1283], loss: 0.5158, acc: 0.8438\n",
      "Epoch [1284], loss: 0.2902, acc: 0.9219\n",
      "Epoch [1285], loss: 0.4032, acc: 0.8594\n",
      "Epoch [1286], loss: 0.2569, acc: 0.9062\n",
      "Epoch [1287], loss: 0.3938, acc: 0.8750\n",
      "Epoch [1288], loss: 0.1823, acc: 0.9531\n",
      "Epoch [1289], loss: 0.4144, acc: 0.8594\n",
      "Epoch [1290], loss: 0.2560, acc: 0.9844\n",
      "Epoch [1291], loss: 0.4222, acc: 0.8594\n",
      "Epoch [1292], loss: 0.3902, acc: 0.9062\n",
      "Epoch [1293], loss: 0.3112, acc: 0.9219\n",
      "Epoch [1294], loss: 0.4730, acc: 0.8594\n",
      "Epoch [1295], loss: 0.3755, acc: 0.9062\n",
      "Epoch [1296], loss: 0.2901, acc: 0.9219\n",
      "Epoch [1297], loss: 0.3618, acc: 0.9062\n",
      "Epoch [1298], loss: 0.3901, acc: 0.8594\n",
      "Epoch [1299], loss: 0.3404, acc: 0.9062\n",
      "Epoch [1300], loss: 0.4440, acc: 0.9062\n",
      "Epoch [1301], loss: 0.4972, acc: 0.9062\n",
      "Epoch [1302], loss: 0.4545, acc: 0.7812\n",
      "Epoch [1303], loss: 0.3422, acc: 0.8438\n",
      "Epoch [1304], loss: 0.3460, acc: 0.8906\n",
      "Epoch [1305], loss: 0.3021, acc: 0.8906\n",
      "Epoch [1306], loss: 0.2111, acc: 0.9375\n",
      "Epoch [1307], loss: 0.4170, acc: 0.8438\n",
      "Epoch [1308], loss: 0.4340, acc: 0.8281\n",
      "Epoch [1309], loss: 0.3387, acc: 0.9219\n",
      "Epoch [1310], loss: 0.3442, acc: 0.8906\n",
      "Epoch [1311], loss: 0.3952, acc: 0.8594\n",
      "Epoch [1312], loss: 0.3461, acc: 0.8750\n",
      "Epoch [1313], loss: 0.3713, acc: 0.8750\n",
      "Epoch [1314], loss: 0.3623, acc: 0.9062\n",
      "Epoch [1315], loss: 0.3422, acc: 0.9219\n",
      "Epoch [1316], loss: 0.3952, acc: 0.8594\n",
      "Epoch [1317], loss: 0.3533, acc: 0.9375\n",
      "Epoch [1318], loss: 0.4342, acc: 0.8594\n",
      "Epoch [1319], loss: 0.4191, acc: 0.8594\n",
      "Epoch [1320], loss: 0.5472, acc: 0.7812\n",
      "Epoch [1321], loss: 0.2834, acc: 0.9062\n",
      "Epoch [1322], loss: 0.2901, acc: 0.9062\n",
      "Epoch [1323], loss: 0.3745, acc: 0.9062\n",
      "Epoch [1324], loss: 0.3188, acc: 0.9375\n",
      "Epoch [1325], loss: 0.3838, acc: 0.8906\n",
      "Epoch [1326], loss: 0.3166, acc: 0.9219\n",
      "Epoch [1327], loss: 0.2879, acc: 0.9375\n",
      "Epoch [1328], loss: 0.3825, acc: 0.8438\n",
      "Epoch [1329], loss: 0.2365, acc: 0.8906\n",
      "Epoch [1330], loss: 0.2988, acc: 0.9219\n",
      "Epoch [1331], loss: 0.5124, acc: 0.8438\n",
      "Epoch [1332], loss: 0.3719, acc: 0.8750\n",
      "Epoch [1333], loss: 0.2578, acc: 0.9375\n",
      "Epoch [1334], loss: 0.3150, acc: 0.9062\n",
      "Epoch [1335], loss: 0.3999, acc: 0.8750\n",
      "Epoch [1336], loss: 0.4331, acc: 0.8594\n",
      "Epoch [1337], loss: 0.3488, acc: 0.9219\n",
      "Epoch [1338], loss: 0.5339, acc: 0.8125\n",
      "Epoch [1339], loss: 0.4210, acc: 0.8750\n",
      "Epoch [1340], loss: 0.4378, acc: 0.9062\n",
      "Epoch [1341], loss: 0.4058, acc: 0.8906\n",
      "Epoch [1342], loss: 0.3364, acc: 0.9219\n",
      "Epoch [1343], loss: 0.3439, acc: 0.8750\n",
      "Epoch [1344], loss: 0.3745, acc: 0.9062\n",
      "Epoch [1345], loss: 0.3196, acc: 0.9375\n",
      "Epoch [1346], loss: 0.4100, acc: 0.8594\n",
      "Epoch [1347], loss: 0.2510, acc: 0.9375\n",
      "Epoch [1348], loss: 0.3471, acc: 0.8750\n",
      "Epoch [1349], loss: 0.4620, acc: 0.8594\n",
      "Epoch [1350], loss: 0.6133, acc: 0.7969\n",
      "Epoch [1351], loss: 0.2674, acc: 0.9375\n",
      "Epoch [1352], loss: 0.2678, acc: 0.9375\n",
      "Epoch [1353], loss: 0.3077, acc: 0.9375\n",
      "Epoch [1354], loss: 0.4301, acc: 0.8594\n",
      "Epoch [1355], loss: 0.3191, acc: 0.9219\n",
      "Epoch [1356], loss: 0.5281, acc: 0.8750\n",
      "Epoch [1357], loss: 0.4091, acc: 0.8594\n",
      "Epoch [1358], loss: 0.3250, acc: 0.9688\n",
      "Epoch [1359], loss: 0.3432, acc: 0.8594\n",
      "Epoch [1360], loss: 0.4009, acc: 0.8750\n",
      "Epoch [1361], loss: 0.4963, acc: 0.8125\n",
      "Epoch [1362], loss: 0.1925, acc: 0.9688\n",
      "Epoch [1363], loss: 0.2984, acc: 0.9219\n",
      "Epoch [1364], loss: 0.3618, acc: 0.9062\n",
      "Epoch [1365], loss: 0.3981, acc: 0.8594\n",
      "Epoch [1366], loss: 0.3556, acc: 0.8906\n",
      "Epoch [1367], loss: 0.3519, acc: 0.8750\n",
      "Epoch [1368], loss: 0.3854, acc: 0.8750\n",
      "Epoch [1369], loss: 0.3601, acc: 0.9219\n",
      "Epoch [1370], loss: 0.2956, acc: 0.8750\n",
      "Epoch [1371], loss: 0.4588, acc: 0.8906\n",
      "Epoch [1372], loss: 0.3989, acc: 0.8750\n",
      "Epoch [1373], loss: 0.4013, acc: 0.8750\n",
      "Epoch [1374], loss: 0.3255, acc: 0.9062\n",
      "Epoch [1375], loss: 0.4638, acc: 0.8594\n",
      "Epoch [1376], loss: 0.3315, acc: 0.8594\n",
      "Epoch [1377], loss: 0.4134, acc: 0.8594\n",
      "Epoch [1378], loss: 0.2665, acc: 0.9062\n",
      "Epoch [1379], loss: 0.3144, acc: 0.9375\n",
      "Epoch [1380], loss: 0.3834, acc: 0.8750\n",
      "\n",
      "Checkpoints/1a600model.ckpt Model Saved...\n",
      "Epoch [1381], loss: 0.5114, acc: 0.8438\n",
      "Epoch [1382], loss: 0.3530, acc: 0.9062\n",
      "Epoch [1383], loss: 0.2901, acc: 0.8906\n",
      "Epoch [1384], loss: 0.3137, acc: 0.9062\n",
      "Epoch [1385], loss: 0.4169, acc: 0.9062\n",
      "Epoch [1386], loss: 0.2908, acc: 0.9062\n",
      "Epoch [1387], loss: 0.4380, acc: 0.8750\n",
      "Epoch [1388], loss: 0.3691, acc: 0.9219\n",
      "Epoch [1389], loss: 0.2604, acc: 0.9531\n",
      "Epoch [1390], loss: 0.2407, acc: 0.9688\n",
      "Epoch [1391], loss: 0.2293, acc: 0.9531\n",
      "Epoch [1392], loss: 0.2770, acc: 0.9062\n",
      "Epoch [1393], loss: 0.4681, acc: 0.8750\n",
      "Epoch [1394], loss: 0.2849, acc: 0.9375\n",
      "Epoch [1395], loss: 0.3778, acc: 0.8594\n",
      "Epoch [1396], loss: 0.2789, acc: 0.9219\n",
      "Epoch [1397], loss: 0.6010, acc: 0.7656\n",
      "Epoch [1398], loss: 0.4784, acc: 0.8281\n",
      "Epoch [1399], loss: 0.3126, acc: 0.9219\n",
      "Epoch [1400], loss: 0.3236, acc: 0.9062\n",
      "Epoch [1401], loss: 0.4226, acc: 0.8438\n",
      "Epoch [1402], loss: 0.3198, acc: 0.9375\n",
      "Epoch [1403], loss: 0.4364, acc: 0.7969\n",
      "Epoch [1404], loss: 0.3055, acc: 0.9375\n",
      "Epoch [1405], loss: 0.4095, acc: 0.9062\n",
      "Epoch [1406], loss: 0.2821, acc: 0.9531\n",
      "Epoch [1407], loss: 0.4454, acc: 0.8125\n",
      "Epoch [1408], loss: 0.3264, acc: 0.8594\n",
      "Epoch [1409], loss: 0.4250, acc: 0.8906\n",
      "Epoch [1410], loss: 0.3220, acc: 0.9062\n",
      "Epoch [1411], loss: 0.2569, acc: 0.9375\n",
      "Epoch [1412], loss: 0.4659, acc: 0.7812\n",
      "Epoch [1413], loss: 0.3189, acc: 0.8906\n",
      "Epoch [1414], loss: 0.3368, acc: 0.9219\n",
      "Epoch [1415], loss: 0.3201, acc: 0.8906\n",
      "Epoch [1416], loss: 0.3108, acc: 0.9375\n",
      "Epoch [1417], loss: 0.4111, acc: 0.8750\n",
      "Epoch [1418], loss: 0.4302, acc: 0.8594\n",
      "Epoch [1419], loss: 0.4142, acc: 0.8594\n",
      "Epoch [1420], loss: 0.2401, acc: 0.9375\n",
      "Epoch [1421], loss: 0.3453, acc: 0.9062\n",
      "Epoch [1422], loss: 0.3635, acc: 0.8594\n",
      "Epoch [1423], loss: 0.3049, acc: 0.9219\n",
      "Epoch [1424], loss: 0.3256, acc: 0.8750\n",
      "Epoch [1425], loss: 0.3062, acc: 0.8906\n",
      "Epoch [1426], loss: 0.4857, acc: 0.9062\n",
      "Epoch [1427], loss: 0.3592, acc: 0.8906\n",
      "Epoch [1428], loss: 0.2979, acc: 0.8906\n",
      "Epoch [1429], loss: 0.2939, acc: 0.9375\n",
      "Epoch [1430], loss: 0.2891, acc: 0.8906\n",
      "Epoch [1431], loss: 0.4647, acc: 0.8438\n",
      "Epoch [1432], loss: 0.4301, acc: 0.8750\n",
      "Epoch [1433], loss: 0.2731, acc: 0.9062\n",
      "Epoch [1434], loss: 0.5336, acc: 0.8594\n",
      "Epoch [1435], loss: 0.2519, acc: 0.9375\n",
      "Epoch [1436], loss: 0.4104, acc: 0.8750\n",
      "Epoch [1437], loss: 0.3911, acc: 0.9062\n",
      "Epoch [1438], loss: 0.2391, acc: 0.9062\n",
      "Epoch [1439], loss: 0.3417, acc: 0.8906\n",
      "Epoch [1440], loss: 0.3678, acc: 0.8906\n",
      "Epoch [1441], loss: 0.3855, acc: 0.8750\n",
      "Epoch [1442], loss: 0.4643, acc: 0.9062\n",
      "Epoch [1443], loss: 0.5380, acc: 0.8281\n",
      "Epoch [1444], loss: 0.5186, acc: 0.8125\n",
      "Epoch [1445], loss: 0.4364, acc: 0.8750\n",
      "Epoch [1446], loss: 0.3828, acc: 0.8594\n",
      "Epoch [1447], loss: 0.4289, acc: 0.8594\n",
      "Epoch [1448], loss: 0.4028, acc: 0.8750\n",
      "Epoch [1449], loss: 0.3647, acc: 0.8594\n",
      "Epoch [1450], loss: 0.3872, acc: 0.9062\n",
      "Epoch [1451], loss: 0.3332, acc: 0.8750\n",
      "Epoch [1452], loss: 0.3046, acc: 0.8906\n",
      "Epoch [1453], loss: 0.2613, acc: 0.9375\n",
      "Epoch [1454], loss: 0.4811, acc: 0.8906\n",
      "Epoch [1455], loss: 0.4741, acc: 0.8438\n",
      "Epoch [1456], loss: 0.4173, acc: 0.8906\n",
      "Epoch [1457], loss: 0.3305, acc: 0.9062\n",
      "Epoch [1458], loss: 0.3028, acc: 0.8906\n",
      "Epoch [1459], loss: 0.3799, acc: 0.8750\n",
      "Epoch [1460], loss: 0.4078, acc: 0.8438\n",
      "Epoch [1461], loss: 0.3183, acc: 0.8906\n",
      "Epoch [1462], loss: 0.4527, acc: 0.8438\n",
      "Epoch [1463], loss: 0.4759, acc: 0.7969\n",
      "Epoch [1464], loss: 0.4559, acc: 0.8281\n",
      "Epoch [1465], loss: 0.3410, acc: 0.8750\n",
      "Epoch [1466], loss: 0.2424, acc: 0.9531\n",
      "Epoch [1467], loss: 0.3532, acc: 0.8438\n",
      "Epoch [1468], loss: 0.4825, acc: 0.8438\n",
      "Epoch [1469], loss: 0.2573, acc: 0.9375\n",
      "Epoch [1470], loss: 0.5404, acc: 0.8906\n",
      "Epoch [1471], loss: 0.3505, acc: 0.8906\n",
      "Epoch [1472], loss: 0.2777, acc: 0.9375\n",
      "Epoch [1473], loss: 0.4666, acc: 0.8594\n",
      "Epoch [1474], loss: 0.3559, acc: 0.9062\n",
      "Epoch [1475], loss: 0.3171, acc: 0.9062\n",
      "Epoch [1476], loss: 0.3839, acc: 0.8750\n",
      "Epoch [1477], loss: 0.2449, acc: 0.9531\n",
      "Epoch [1478], loss: 0.3933, acc: 0.8906\n",
      "Epoch [1479], loss: 0.3913, acc: 0.8750\n",
      "Epoch [1480], loss: 0.3827, acc: 0.8438\n",
      "\n",
      "Checkpoints/1a700model.ckpt Model Saved...\n",
      "Epoch [1481], loss: 0.4636, acc: 0.8438\n",
      "Epoch [1482], loss: 0.4689, acc: 0.8281\n",
      "Epoch [1483], loss: 0.4584, acc: 0.8750\n",
      "Epoch [1484], loss: 0.2789, acc: 0.9062\n",
      "Epoch [1485], loss: 0.3642, acc: 0.8906\n",
      "Epoch [1486], loss: 0.3794, acc: 0.8906\n",
      "Epoch [1487], loss: 0.2902, acc: 0.9219\n",
      "Epoch [1488], loss: 0.2508, acc: 0.9375\n",
      "Epoch [1489], loss: 0.3399, acc: 0.8750\n",
      "Epoch [1490], loss: 0.3162, acc: 0.9219\n",
      "Epoch [1491], loss: 0.3477, acc: 0.8906\n",
      "Epoch [1492], loss: 0.3897, acc: 0.8906\n",
      "Epoch [1493], loss: 0.4929, acc: 0.8281\n",
      "Epoch [1494], loss: 0.3170, acc: 0.9062\n",
      "Epoch [1495], loss: 0.4276, acc: 0.8594\n",
      "Epoch [1496], loss: 0.4894, acc: 0.8438\n",
      "Epoch [1497], loss: 0.3478, acc: 0.9062\n",
      "Epoch [1498], loss: 0.4939, acc: 0.8438\n",
      "Epoch [1499], loss: 0.3580, acc: 0.8906\n",
      "Epoch [1500], loss: 0.3813, acc: 0.8750\n",
      "Epoch [1501], loss: 0.4105, acc: 0.8594\n",
      "Epoch [1502], loss: 0.3163, acc: 0.9062\n",
      "Epoch [1503], loss: 0.3097, acc: 0.9062\n",
      "Epoch [1504], loss: 0.3235, acc: 0.8438\n",
      "Epoch [1505], loss: 0.4390, acc: 0.8438\n",
      "Epoch [1506], loss: 0.3984, acc: 0.8750\n",
      "Epoch [1507], loss: 0.4115, acc: 0.8906\n",
      "Epoch [1508], loss: 0.3925, acc: 0.8750\n",
      "Epoch [1509], loss: 0.3440, acc: 0.8750\n",
      "Epoch [1510], loss: 0.2209, acc: 0.9531\n",
      "Epoch [1511], loss: 0.2818, acc: 0.9375\n",
      "Epoch [1512], loss: 0.4561, acc: 0.8594\n",
      "Epoch [1513], loss: 0.2586, acc: 0.9531\n",
      "Epoch [1514], loss: 0.4510, acc: 0.8281\n",
      "Epoch [1515], loss: 0.4372, acc: 0.8438\n",
      "Epoch [1516], loss: 0.2905, acc: 0.8906\n",
      "Epoch [1517], loss: 0.3802, acc: 0.8438\n",
      "Epoch [1518], loss: 0.3475, acc: 0.8906\n",
      "Epoch [1519], loss: 0.4500, acc: 0.8750\n",
      "Epoch [1520], loss: 0.4273, acc: 0.8594\n",
      "Epoch [1521], loss: 0.3012, acc: 0.9375\n",
      "Epoch [1522], loss: 0.3176, acc: 0.8906\n",
      "Epoch [1523], loss: 0.3814, acc: 0.8750\n",
      "Epoch [1524], loss: 0.2982, acc: 0.9688\n",
      "Epoch [1525], loss: 0.4688, acc: 0.8281\n",
      "Epoch [1526], loss: 0.3368, acc: 0.9531\n",
      "Epoch [1527], loss: 0.3909, acc: 0.9062\n",
      "Epoch [1528], loss: 0.4145, acc: 0.8594\n",
      "Epoch [1529], loss: 0.3631, acc: 0.8906\n",
      "Epoch [1530], loss: 0.4127, acc: 0.8906\n",
      "Epoch [1531], loss: 0.5014, acc: 0.8750\n",
      "Epoch [1532], loss: 0.3645, acc: 0.9062\n",
      "Epoch [1533], loss: 0.4007, acc: 0.8750\n",
      "Epoch [1534], loss: 0.5197, acc: 0.7969\n",
      "Epoch [1535], loss: 0.2432, acc: 0.9375\n",
      "Epoch [1536], loss: 0.3396, acc: 0.8906\n",
      "Epoch [1537], loss: 0.3353, acc: 0.9219\n",
      "Epoch [1538], loss: 0.3556, acc: 0.8750\n",
      "Epoch [1539], loss: 0.4303, acc: 0.8438\n",
      "Epoch [1540], loss: 0.3189, acc: 0.8906\n",
      "Epoch [1541], loss: 0.3550, acc: 0.8594\n",
      "Epoch [1542], loss: 0.3739, acc: 0.8906\n",
      "Epoch [1543], loss: 0.2455, acc: 0.9531\n",
      "Epoch [1544], loss: 0.4195, acc: 0.8750\n",
      "Epoch [1545], loss: 0.2802, acc: 0.9062\n",
      "Epoch [1546], loss: 0.4863, acc: 0.8281\n",
      "Epoch [1547], loss: 0.3998, acc: 0.8750\n",
      "Epoch [1548], loss: 0.5053, acc: 0.8438\n",
      "Epoch [1549], loss: 0.3756, acc: 0.8281\n",
      "Epoch [1550], loss: 0.3004, acc: 0.9219\n",
      "Epoch [1551], loss: 0.4833, acc: 0.8594\n",
      "Epoch [1552], loss: 0.6394, acc: 0.8281\n",
      "Epoch [1553], loss: 0.2657, acc: 0.9219\n",
      "Epoch [1554], loss: 0.3608, acc: 0.9062\n",
      "Epoch [1555], loss: 0.2940, acc: 0.9062\n",
      "Epoch [1556], loss: 0.4078, acc: 0.8438\n",
      "Epoch [1557], loss: 0.2653, acc: 0.9219\n",
      "Epoch [1558], loss: 0.4776, acc: 0.8594\n",
      "Epoch [1559], loss: 0.3070, acc: 0.9062\n",
      "Epoch [1560], loss: 0.2474, acc: 0.9688\n",
      "Epoch [1561], loss: 0.2024, acc: 0.9688\n",
      "\n",
      "Checkpoints/1model.ckpt Model Saved...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b684dafbfe6646829165606ac7f2707f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checkpoints/2a0model.ckpt Model Saved...\n",
      "Epoch [1562], loss: 0.3657, acc: 0.9062\n",
      "Epoch [1563], loss: 0.2837, acc: 0.9688\n",
      "Epoch [1564], loss: 0.3612, acc: 0.9062\n",
      "Epoch [1565], loss: 0.4273, acc: 0.8750\n",
      "Epoch [1566], loss: 0.2628, acc: 0.9375\n",
      "Epoch [1567], loss: 0.2334, acc: 0.9688\n",
      "Epoch [1568], loss: 0.4840, acc: 0.8125\n",
      "Epoch [1569], loss: 0.2034, acc: 0.9531\n",
      "Epoch [1570], loss: 0.3533, acc: 0.8750\n",
      "Epoch [1571], loss: 0.2750, acc: 0.9375\n",
      "Epoch [1572], loss: 0.3864, acc: 0.9062\n",
      "Epoch [1573], loss: 0.3002, acc: 0.8750\n",
      "Epoch [1574], loss: 0.5473, acc: 0.8125\n",
      "Epoch [1575], loss: 0.2693, acc: 0.9219\n",
      "Epoch [1576], loss: 0.2961, acc: 0.9062\n",
      "Epoch [1577], loss: 0.3955, acc: 0.8750\n",
      "Epoch [1578], loss: 0.4612, acc: 0.8438\n",
      "Epoch [1579], loss: 0.4234, acc: 0.8594\n",
      "Epoch [1580], loss: 0.4424, acc: 0.8438\n",
      "Epoch [1581], loss: 0.4048, acc: 0.8594\n",
      "Epoch [1582], loss: 0.2521, acc: 0.9531\n",
      "Epoch [1583], loss: 0.2860, acc: 0.9219\n",
      "Epoch [1584], loss: 0.3213, acc: 0.8906\n",
      "Epoch [1585], loss: 0.3991, acc: 0.8906\n",
      "Epoch [1586], loss: 0.4799, acc: 0.8594\n",
      "Epoch [1587], loss: 0.2833, acc: 0.9375\n",
      "Epoch [1588], loss: 0.3445, acc: 0.8438\n",
      "Epoch [1589], loss: 0.2684, acc: 0.9375\n",
      "Epoch [1590], loss: 0.3818, acc: 0.8906\n",
      "Epoch [1591], loss: 0.4202, acc: 0.8906\n",
      "Epoch [1592], loss: 0.3386, acc: 0.8906\n",
      "Epoch [1593], loss: 0.4425, acc: 0.9062\n",
      "Epoch [1594], loss: 0.2147, acc: 0.9375\n",
      "Epoch [1595], loss: 0.3481, acc: 0.8906\n",
      "Epoch [1596], loss: 0.2840, acc: 0.9062\n",
      "Epoch [1597], loss: 0.3328, acc: 0.8906\n",
      "Epoch [1598], loss: 0.4211, acc: 0.9062\n",
      "Epoch [1599], loss: 0.3243, acc: 0.9062\n",
      "Epoch [1600], loss: 0.4526, acc: 0.8594\n",
      "Epoch [1601], loss: 0.4873, acc: 0.8594\n",
      "Epoch [1602], loss: 0.2407, acc: 0.9062\n",
      "Epoch [1603], loss: 0.2963, acc: 0.9688\n",
      "Epoch [1604], loss: 0.2881, acc: 0.9219\n",
      "Epoch [1605], loss: 0.3271, acc: 0.8906\n",
      "Epoch [1606], loss: 0.3771, acc: 0.9219\n",
      "Epoch [1607], loss: 0.2628, acc: 0.9219\n",
      "Epoch [1608], loss: 0.2459, acc: 0.9062\n",
      "Epoch [1609], loss: 0.2521, acc: 0.9375\n",
      "Epoch [1610], loss: 0.3229, acc: 0.8906\n",
      "Epoch [1611], loss: 0.4306, acc: 0.8281\n",
      "Epoch [1612], loss: 0.1916, acc: 0.9219\n",
      "Epoch [1613], loss: 0.2629, acc: 0.9375\n",
      "Epoch [1614], loss: 0.2006, acc: 0.9688\n",
      "Epoch [1615], loss: 0.3691, acc: 0.8906\n",
      "Epoch [1616], loss: 0.2845, acc: 0.9531\n",
      "Epoch [1617], loss: 0.3572, acc: 0.9219\n",
      "Epoch [1618], loss: 0.2108, acc: 0.9219\n",
      "Epoch [1619], loss: 0.3453, acc: 0.8906\n",
      "Epoch [1620], loss: 0.2490, acc: 0.9375\n",
      "Epoch [1621], loss: 0.2774, acc: 0.9375\n",
      "Epoch [1622], loss: 0.3222, acc: 0.8906\n",
      "Epoch [1623], loss: 0.4392, acc: 0.9062\n",
      "Epoch [1624], loss: 0.2170, acc: 0.9219\n",
      "Epoch [1625], loss: 0.3145, acc: 0.8750\n",
      "Epoch [1626], loss: 0.3910, acc: 0.8750\n",
      "Epoch [1627], loss: 0.3650, acc: 0.8750\n",
      "Epoch [1628], loss: 0.1893, acc: 0.9531\n",
      "Epoch [1629], loss: 0.4222, acc: 0.8906\n",
      "Epoch [1630], loss: 0.3917, acc: 0.8594\n",
      "Epoch [1631], loss: 0.2788, acc: 0.9219\n",
      "Epoch [1632], loss: 0.3359, acc: 0.8906\n",
      "Epoch [1633], loss: 0.3433, acc: 0.8750\n",
      "Epoch [1634], loss: 0.2640, acc: 0.9062\n",
      "Epoch [1635], loss: 0.3777, acc: 0.8281\n",
      "Epoch [1636], loss: 0.4031, acc: 0.8125\n",
      "Epoch [1637], loss: 0.3985, acc: 0.8750\n",
      "Epoch [1638], loss: 0.1579, acc: 0.9531\n",
      "Epoch [1639], loss: 0.2041, acc: 0.9219\n",
      "Epoch [1640], loss: 0.3494, acc: 0.8750\n",
      "Epoch [1641], loss: 0.3407, acc: 0.8750\n",
      "Epoch [1642], loss: 0.2683, acc: 0.9062\n",
      "Epoch [1643], loss: 0.3108, acc: 0.9062\n",
      "Epoch [1644], loss: 0.2292, acc: 0.9375\n",
      "Epoch [1645], loss: 0.2095, acc: 0.9375\n",
      "Epoch [1646], loss: 0.2331, acc: 0.9375\n",
      "Epoch [1647], loss: 0.1779, acc: 0.9531\n",
      "Epoch [1648], loss: 0.2945, acc: 0.9219\n",
      "Epoch [1649], loss: 0.3527, acc: 0.8750\n",
      "Epoch [1650], loss: 0.4113, acc: 0.9062\n",
      "Epoch [1651], loss: 0.3286, acc: 0.8594\n",
      "Epoch [1652], loss: 0.3638, acc: 0.9062\n",
      "Epoch [1653], loss: 0.3244, acc: 0.8594\n",
      "Epoch [1654], loss: 0.2955, acc: 0.8906\n",
      "Epoch [1655], loss: 0.3940, acc: 0.9062\n",
      "Epoch [1656], loss: 0.3149, acc: 0.8906\n",
      "Epoch [1657], loss: 0.3084, acc: 0.8750\n",
      "Epoch [1658], loss: 0.3633, acc: 0.9219\n",
      "Epoch [1659], loss: 0.2932, acc: 0.8750\n",
      "Epoch [1660], loss: 0.3322, acc: 0.8906\n",
      "Epoch [1661], loss: 0.5524, acc: 0.8281\n",
      "\n",
      "Checkpoints/2a100model.ckpt Model Saved...\n",
      "Epoch [1662], loss: 0.2978, acc: 0.8750\n",
      "Epoch [1663], loss: 0.2637, acc: 0.9219\n",
      "Epoch [1664], loss: 0.2734, acc: 0.9062\n",
      "Epoch [1665], loss: 0.5428, acc: 0.8281\n",
      "Epoch [1666], loss: 0.1421, acc: 0.9688\n",
      "Epoch [1667], loss: 0.3544, acc: 0.9219\n",
      "Epoch [1668], loss: 0.3913, acc: 0.8906\n",
      "Epoch [1669], loss: 0.3078, acc: 0.9219\n",
      "Epoch [1670], loss: 0.3808, acc: 0.8750\n",
      "Epoch [1671], loss: 0.4136, acc: 0.8750\n",
      "Epoch [1672], loss: 0.2759, acc: 0.9375\n",
      "Epoch [1673], loss: 0.2428, acc: 0.9375\n",
      "Epoch [1674], loss: 0.2895, acc: 0.8750\n",
      "Epoch [1675], loss: 0.2745, acc: 0.9375\n",
      "Epoch [1676], loss: 0.4143, acc: 0.8750\n",
      "Epoch [1677], loss: 0.1948, acc: 0.9531\n",
      "Epoch [1678], loss: 0.4097, acc: 0.8750\n",
      "Epoch [1679], loss: 0.4379, acc: 0.8281\n",
      "Epoch [1680], loss: 0.3462, acc: 0.9062\n",
      "Epoch [1681], loss: 0.3158, acc: 0.9219\n",
      "Epoch [1682], loss: 0.2712, acc: 0.9531\n",
      "Epoch [1683], loss: 0.3417, acc: 0.9219\n",
      "Epoch [1684], loss: 0.3841, acc: 0.8438\n",
      "Epoch [1685], loss: 0.3266, acc: 0.9062\n",
      "Epoch [1686], loss: 0.2783, acc: 0.9531\n",
      "Epoch [1687], loss: 0.2456, acc: 0.9375\n",
      "Epoch [1688], loss: 0.1895, acc: 0.9375\n",
      "Epoch [1689], loss: 0.4257, acc: 0.8438\n",
      "Epoch [1690], loss: 0.2633, acc: 0.9062\n",
      "Epoch [1691], loss: 0.2931, acc: 0.9219\n",
      "Epoch [1692], loss: 0.4033, acc: 0.9062\n",
      "Epoch [1693], loss: 0.2512, acc: 0.9375\n",
      "Epoch [1694], loss: 0.3128, acc: 0.8750\n",
      "Epoch [1695], loss: 0.3325, acc: 0.8594\n",
      "Epoch [1696], loss: 0.4009, acc: 0.9219\n",
      "Epoch [1697], loss: 0.3442, acc: 0.8438\n",
      "Epoch [1698], loss: 0.3501, acc: 0.9219\n",
      "Epoch [1699], loss: 0.3647, acc: 0.9062\n",
      "Epoch [1700], loss: 0.2854, acc: 0.9531\n",
      "Epoch [1701], loss: 0.4028, acc: 0.8438\n",
      "Epoch [1702], loss: 0.3214, acc: 0.9219\n",
      "Epoch [1703], loss: 0.3440, acc: 0.9375\n",
      "Epoch [1704], loss: 0.3005, acc: 0.9062\n",
      "Epoch [1705], loss: 0.2654, acc: 0.9219\n",
      "Epoch [1706], loss: 0.3835, acc: 0.9219\n",
      "Epoch [1707], loss: 0.3486, acc: 0.8906\n",
      "Epoch [1708], loss: 0.2616, acc: 0.9219\n",
      "Epoch [1709], loss: 0.2314, acc: 0.9219\n",
      "Epoch [1710], loss: 0.3449, acc: 0.8750\n",
      "Epoch [1711], loss: 0.3555, acc: 0.9219\n",
      "Epoch [1712], loss: 0.3011, acc: 0.8906\n",
      "Epoch [1713], loss: 0.4370, acc: 0.9219\n",
      "Epoch [1714], loss: 0.3733, acc: 0.9062\n",
      "Epoch [1715], loss: 0.4368, acc: 0.8438\n",
      "Epoch [1716], loss: 0.2985, acc: 0.9062\n",
      "Epoch [1717], loss: 0.4101, acc: 0.8906\n",
      "Epoch [1718], loss: 0.3817, acc: 0.8281\n",
      "Epoch [1719], loss: 0.2841, acc: 0.9375\n",
      "Epoch [1720], loss: 0.2344, acc: 0.9375\n",
      "Epoch [1721], loss: 0.2393, acc: 0.9375\n",
      "Epoch [1722], loss: 0.3691, acc: 0.9062\n",
      "Epoch [1723], loss: 0.2421, acc: 0.9531\n",
      "Epoch [1724], loss: 0.3663, acc: 0.8438\n",
      "Epoch [1725], loss: 0.2984, acc: 0.9219\n",
      "Epoch [1726], loss: 0.3343, acc: 0.9062\n",
      "Epoch [1727], loss: 0.2586, acc: 0.9062\n",
      "Epoch [1728], loss: 0.4527, acc: 0.8750\n",
      "Epoch [1729], loss: 0.3019, acc: 0.9219\n",
      "Epoch [1730], loss: 0.2621, acc: 0.9062\n",
      "Epoch [1731], loss: 0.2707, acc: 0.9375\n",
      "Epoch [1732], loss: 0.2137, acc: 0.9375\n",
      "Epoch [1733], loss: 0.2766, acc: 0.9219\n",
      "Epoch [1734], loss: 0.2421, acc: 0.9219\n",
      "Epoch [1735], loss: 0.2676, acc: 0.9531\n",
      "Epoch [1736], loss: 0.2586, acc: 0.9062\n",
      "Epoch [1737], loss: 0.5315, acc: 0.7969\n",
      "Epoch [1738], loss: 0.2228, acc: 0.9375\n",
      "Epoch [1739], loss: 0.2581, acc: 0.9375\n",
      "Epoch [1740], loss: 0.3333, acc: 0.9219\n",
      "Epoch [1741], loss: 0.3890, acc: 0.8281\n",
      "Epoch [1742], loss: 0.2457, acc: 0.9531\n",
      "Epoch [1743], loss: 0.2793, acc: 0.9062\n",
      "Epoch [1744], loss: 0.2680, acc: 0.9062\n",
      "Epoch [1745], loss: 0.3051, acc: 0.9062\n",
      "Epoch [1746], loss: 0.3216, acc: 0.9375\n",
      "Epoch [1747], loss: 0.3793, acc: 0.8438\n",
      "Epoch [1748], loss: 0.4240, acc: 0.8750\n",
      "Epoch [1749], loss: 0.3448, acc: 0.8906\n",
      "Epoch [1750], loss: 0.2426, acc: 0.9375\n",
      "Epoch [1751], loss: 0.1899, acc: 0.9688\n",
      "Epoch [1752], loss: 0.2800, acc: 0.9375\n",
      "Epoch [1753], loss: 0.2701, acc: 0.9375\n",
      "Epoch [1754], loss: 0.3235, acc: 0.9062\n",
      "Epoch [1755], loss: 0.4864, acc: 0.7969\n",
      "Epoch [1756], loss: 0.3607, acc: 0.8438\n",
      "Epoch [1757], loss: 0.4243, acc: 0.8906\n",
      "Epoch [1758], loss: 0.2677, acc: 0.9062\n",
      "Epoch [1759], loss: 0.2421, acc: 0.9375\n",
      "Epoch [1760], loss: 0.3101, acc: 0.9375\n",
      "Epoch [1761], loss: 0.2537, acc: 0.9531\n",
      "\n",
      "Checkpoints/2a200model.ckpt Model Saved...\n",
      "Epoch [1762], loss: 0.3796, acc: 0.8594\n",
      "Epoch [1763], loss: 0.3374, acc: 0.8750\n",
      "Epoch [1764], loss: 0.3297, acc: 0.8906\n",
      "Epoch [1765], loss: 0.2600, acc: 0.9062\n",
      "Epoch [1766], loss: 0.2923, acc: 0.9219\n",
      "Epoch [1767], loss: 0.2077, acc: 0.9531\n",
      "Epoch [1768], loss: 0.2517, acc: 0.9062\n",
      "Epoch [1769], loss: 0.3110, acc: 0.9375\n",
      "Epoch [1770], loss: 0.4606, acc: 0.8750\n",
      "Epoch [1771], loss: 0.3113, acc: 0.8906\n",
      "Epoch [1772], loss: 0.2659, acc: 0.9062\n",
      "Epoch [1773], loss: 0.2038, acc: 0.9531\n",
      "Epoch [1774], loss: 0.2898, acc: 0.9219\n",
      "Epoch [1775], loss: 0.3598, acc: 0.9062\n",
      "Epoch [1776], loss: 0.3420, acc: 0.9219\n",
      "Epoch [1777], loss: 0.2185, acc: 0.9219\n",
      "Epoch [1778], loss: 0.4190, acc: 0.8750\n",
      "Epoch [1779], loss: 0.4245, acc: 0.8594\n",
      "Epoch [1780], loss: 0.3242, acc: 0.8750\n",
      "Epoch [1781], loss: 0.3205, acc: 0.9062\n",
      "Epoch [1782], loss: 0.3891, acc: 0.8750\n",
      "Epoch [1783], loss: 0.2043, acc: 0.9531\n",
      "Epoch [1784], loss: 0.2541, acc: 0.8906\n",
      "Epoch [1785], loss: 0.5133, acc: 0.8281\n",
      "Epoch [1786], loss: 0.3791, acc: 0.8438\n",
      "Epoch [1787], loss: 0.1858, acc: 0.9688\n",
      "Epoch [1788], loss: 0.3625, acc: 0.9219\n",
      "Epoch [1789], loss: 0.2603, acc: 0.9375\n",
      "Epoch [1790], loss: 0.2888, acc: 0.9062\n",
      "Epoch [1791], loss: 0.4590, acc: 0.8281\n",
      "Epoch [1792], loss: 0.2089, acc: 0.9531\n",
      "Epoch [1793], loss: 0.3381, acc: 0.9375\n",
      "Epoch [1794], loss: 0.2420, acc: 0.9062\n",
      "Epoch [1795], loss: 0.2227, acc: 0.9531\n",
      "Epoch [1796], loss: 0.2957, acc: 0.9531\n",
      "Epoch [1797], loss: 0.1808, acc: 0.9375\n",
      "Epoch [1798], loss: 0.2986, acc: 0.9375\n",
      "Epoch [1799], loss: 0.2378, acc: 0.9375\n",
      "Epoch [1800], loss: 0.2953, acc: 0.9219\n",
      "Epoch [1801], loss: 0.2194, acc: 0.9531\n",
      "Epoch [1802], loss: 0.3253, acc: 0.9375\n",
      "Epoch [1803], loss: 0.3539, acc: 0.9375\n",
      "Epoch [1804], loss: 0.4743, acc: 0.8438\n",
      "Epoch [1805], loss: 0.3571, acc: 0.8750\n",
      "Epoch [1806], loss: 0.2200, acc: 0.9219\n",
      "Epoch [1807], loss: 0.2704, acc: 0.9375\n",
      "Epoch [1808], loss: 0.2768, acc: 0.9531\n",
      "Epoch [1809], loss: 0.2665, acc: 0.8906\n",
      "Epoch [1810], loss: 0.3635, acc: 0.9062\n",
      "Epoch [1811], loss: 0.4628, acc: 0.8281\n",
      "Epoch [1812], loss: 0.3296, acc: 0.9219\n",
      "Epoch [1813], loss: 0.3323, acc: 0.9219\n",
      "Epoch [1814], loss: 0.3488, acc: 0.9219\n",
      "Epoch [1815], loss: 0.4193, acc: 0.8906\n",
      "Epoch [1816], loss: 0.3590, acc: 0.8750\n",
      "Epoch [1817], loss: 0.4244, acc: 0.8906\n",
      "Epoch [1818], loss: 0.2841, acc: 0.9375\n",
      "Epoch [1819], loss: 0.3240, acc: 0.9219\n",
      "Epoch [1820], loss: 0.2453, acc: 0.9219\n",
      "Epoch [1821], loss: 0.3356, acc: 0.8906\n",
      "Epoch [1822], loss: 0.3205, acc: 0.8906\n",
      "Epoch [1823], loss: 0.2228, acc: 0.9844\n",
      "Epoch [1824], loss: 0.2285, acc: 0.9375\n",
      "Epoch [1825], loss: 0.2452, acc: 0.9531\n",
      "Epoch [1826], loss: 0.2490, acc: 0.8906\n",
      "Epoch [1827], loss: 0.3110, acc: 0.9062\n",
      "Epoch [1828], loss: 0.2392, acc: 0.9531\n",
      "Epoch [1829], loss: 0.2409, acc: 0.9062\n",
      "Epoch [1830], loss: 0.4186, acc: 0.8750\n",
      "Epoch [1831], loss: 0.3263, acc: 0.9062\n",
      "Epoch [1832], loss: 0.3139, acc: 0.8906\n",
      "Epoch [1833], loss: 0.2170, acc: 0.9531\n",
      "Epoch [1834], loss: 0.1984, acc: 0.9375\n",
      "Epoch [1835], loss: 0.2964, acc: 0.8906\n",
      "Epoch [1836], loss: 0.2754, acc: 0.9375\n",
      "Epoch [1837], loss: 0.2010, acc: 0.9688\n",
      "Epoch [1838], loss: 0.1350, acc: 0.9844\n",
      "Epoch [1839], loss: 0.2015, acc: 0.9375\n",
      "Epoch [1840], loss: 0.2976, acc: 0.9375\n",
      "Epoch [1841], loss: 0.3133, acc: 0.9375\n",
      "Epoch [1842], loss: 0.2886, acc: 0.9375\n",
      "Epoch [1843], loss: 0.1844, acc: 0.9219\n",
      "Epoch [1844], loss: 0.2399, acc: 0.9375\n",
      "Epoch [1845], loss: 0.4648, acc: 0.8906\n",
      "Epoch [1846], loss: 0.2184, acc: 0.9219\n",
      "Epoch [1847], loss: 0.3021, acc: 0.9062\n",
      "Epoch [1848], loss: 0.2859, acc: 0.9219\n",
      "Epoch [1849], loss: 0.2469, acc: 0.9219\n",
      "Epoch [1850], loss: 0.2605, acc: 0.9219\n",
      "Epoch [1851], loss: 0.4966, acc: 0.8594\n",
      "Epoch [1852], loss: 0.2187, acc: 0.9219\n",
      "Epoch [1853], loss: 0.2703, acc: 0.9219\n",
      "Epoch [1854], loss: 0.2459, acc: 0.9688\n",
      "Epoch [1855], loss: 0.4268, acc: 0.8594\n",
      "Epoch [1856], loss: 0.3023, acc: 0.9219\n",
      "Epoch [1857], loss: 0.2109, acc: 0.9531\n",
      "Epoch [1858], loss: 0.2723, acc: 0.9062\n",
      "Epoch [1859], loss: 0.3244, acc: 0.8750\n",
      "Epoch [1860], loss: 0.3044, acc: 0.9375\n",
      "Epoch [1861], loss: 0.2507, acc: 0.9219\n",
      "\n",
      "Checkpoints/2a300model.ckpt Model Saved...\n",
      "Epoch [1862], loss: 0.1998, acc: 0.9375\n",
      "Epoch [1863], loss: 0.2223, acc: 0.9219\n",
      "Epoch [1864], loss: 0.4263, acc: 0.8594\n",
      "Epoch [1865], loss: 0.2961, acc: 0.9375\n",
      "Epoch [1866], loss: 0.2952, acc: 0.9375\n",
      "Epoch [1867], loss: 0.1925, acc: 0.9531\n",
      "Epoch [1868], loss: 0.2712, acc: 0.9688\n",
      "Epoch [1869], loss: 0.5061, acc: 0.8750\n",
      "Epoch [1870], loss: 0.1795, acc: 0.9375\n",
      "Epoch [1871], loss: 0.3870, acc: 0.8906\n",
      "Epoch [1872], loss: 0.2139, acc: 0.9375\n",
      "Epoch [1873], loss: 0.2510, acc: 0.9375\n",
      "Epoch [1874], loss: 0.2937, acc: 0.9062\n",
      "Epoch [1875], loss: 0.5630, acc: 0.8281\n",
      "Epoch [1876], loss: 0.2716, acc: 0.9062\n",
      "Epoch [1877], loss: 0.2724, acc: 0.9219\n",
      "Epoch [1878], loss: 0.2964, acc: 0.8906\n",
      "Epoch [1879], loss: 0.2214, acc: 0.9375\n",
      "Epoch [1880], loss: 0.4487, acc: 0.9375\n",
      "Epoch [1881], loss: 0.3306, acc: 0.8906\n",
      "Epoch [1882], loss: 0.2313, acc: 0.9531\n",
      "Epoch [1883], loss: 0.4029, acc: 0.8750\n",
      "Epoch [1884], loss: 0.2309, acc: 0.9531\n",
      "Epoch [1885], loss: 0.3179, acc: 0.9219\n",
      "Epoch [1886], loss: 0.3999, acc: 0.8594\n",
      "Epoch [1887], loss: 0.3163, acc: 0.9375\n",
      "Epoch [1888], loss: 0.2388, acc: 0.9219\n",
      "Epoch [1889], loss: 0.3973, acc: 0.9062\n",
      "Epoch [1890], loss: 0.2334, acc: 0.9375\n",
      "Epoch [1891], loss: 0.3722, acc: 0.8906\n",
      "Epoch [1892], loss: 0.2273, acc: 0.9531\n",
      "Epoch [1893], loss: 0.3310, acc: 0.9062\n",
      "Epoch [1894], loss: 0.2023, acc: 0.9688\n",
      "Epoch [1895], loss: 0.2605, acc: 0.9062\n",
      "Epoch [1896], loss: 0.3844, acc: 0.8594\n",
      "Epoch [1897], loss: 0.2293, acc: 0.9375\n",
      "Epoch [1898], loss: 0.3128, acc: 0.8906\n",
      "Epoch [1899], loss: 0.2703, acc: 0.9375\n",
      "Epoch [1900], loss: 0.4083, acc: 0.9062\n",
      "Epoch [1901], loss: 0.2652, acc: 0.9062\n",
      "Epoch [1902], loss: 0.3129, acc: 0.8594\n",
      "Epoch [1903], loss: 0.2655, acc: 0.9219\n",
      "Epoch [1904], loss: 0.3713, acc: 0.9062\n",
      "Epoch [1905], loss: 0.2340, acc: 0.9531\n",
      "Epoch [1906], loss: 0.3391, acc: 0.8906\n",
      "Epoch [1907], loss: 0.2866, acc: 0.9219\n",
      "Epoch [1908], loss: 0.3047, acc: 0.9062\n",
      "Epoch [1909], loss: 0.2517, acc: 0.9062\n",
      "Epoch [1910], loss: 0.3022, acc: 0.9219\n",
      "Epoch [1911], loss: 0.3368, acc: 0.9375\n",
      "Epoch [1912], loss: 0.3479, acc: 0.8594\n",
      "Epoch [1913], loss: 0.4117, acc: 0.8594\n",
      "Epoch [1914], loss: 0.2954, acc: 0.9219\n",
      "Epoch [1915], loss: 0.2154, acc: 0.9219\n",
      "Epoch [1916], loss: 0.2192, acc: 0.9531\n",
      "Epoch [1917], loss: 0.3266, acc: 0.9375\n",
      "Epoch [1918], loss: 0.4035, acc: 0.8594\n",
      "Epoch [1919], loss: 0.2539, acc: 0.9375\n",
      "Epoch [1920], loss: 0.2915, acc: 0.9062\n",
      "Epoch [1921], loss: 0.2090, acc: 0.9219\n",
      "Epoch [1922], loss: 0.2916, acc: 0.8750\n",
      "Epoch [1923], loss: 0.3230, acc: 0.9219\n",
      "Epoch [1924], loss: 0.3102, acc: 0.9062\n",
      "Epoch [1925], loss: 0.2140, acc: 0.9375\n",
      "Epoch [1926], loss: 0.3985, acc: 0.8750\n",
      "Epoch [1927], loss: 0.2433, acc: 0.9062\n",
      "Epoch [1928], loss: 0.2651, acc: 0.8906\n",
      "Epoch [1929], loss: 0.3390, acc: 0.8906\n",
      "Epoch [1930], loss: 0.2369, acc: 0.9219\n",
      "Epoch [1931], loss: 0.3293, acc: 0.9062\n",
      "Epoch [1932], loss: 0.2147, acc: 0.9688\n",
      "Epoch [1933], loss: 0.2290, acc: 0.9531\n",
      "Epoch [1934], loss: 0.3311, acc: 0.8906\n",
      "Epoch [1935], loss: 0.2614, acc: 0.9219\n",
      "Epoch [1936], loss: 0.3576, acc: 0.8906\n",
      "Epoch [1937], loss: 0.4171, acc: 0.8594\n",
      "Epoch [1938], loss: 0.2933, acc: 0.9219\n",
      "Epoch [1939], loss: 0.3871, acc: 0.8594\n",
      "Epoch [1940], loss: 0.2458, acc: 0.9531\n",
      "Epoch [1941], loss: 0.2489, acc: 0.9219\n",
      "Epoch [1942], loss: 0.2712, acc: 0.9062\n",
      "Epoch [1943], loss: 0.2281, acc: 0.9219\n",
      "Epoch [1944], loss: 0.2748, acc: 0.8906\n",
      "Epoch [1945], loss: 0.2060, acc: 0.9531\n",
      "Epoch [1946], loss: 0.2994, acc: 0.9062\n",
      "Epoch [1947], loss: 0.2659, acc: 0.9219\n",
      "Epoch [1948], loss: 0.2728, acc: 0.9062\n",
      "Epoch [1949], loss: 0.4527, acc: 0.8906\n",
      "Epoch [1950], loss: 0.3346, acc: 0.8906\n",
      "Epoch [1951], loss: 0.3014, acc: 0.9219\n",
      "Epoch [1952], loss: 0.2751, acc: 0.9062\n",
      "Epoch [1953], loss: 0.2473, acc: 0.9375\n",
      "Epoch [1954], loss: 0.2673, acc: 0.8906\n",
      "Epoch [1955], loss: 0.1748, acc: 0.9844\n",
      "Epoch [1956], loss: 0.3074, acc: 0.8906\n",
      "Epoch [1957], loss: 0.4263, acc: 0.8281\n",
      "Epoch [1958], loss: 0.3508, acc: 0.9219\n",
      "Epoch [1959], loss: 0.2816, acc: 0.8906\n",
      "Epoch [1960], loss: 0.2979, acc: 0.9375\n",
      "Epoch [1961], loss: 0.3121, acc: 0.9062\n",
      "\n",
      "Checkpoints/2a400model.ckpt Model Saved...\n",
      "Epoch [1962], loss: 0.2791, acc: 0.9062\n",
      "Epoch [1963], loss: 0.2914, acc: 0.9062\n",
      "Epoch [1964], loss: 0.2973, acc: 0.8906\n",
      "Epoch [1965], loss: 0.2823, acc: 0.9062\n",
      "Epoch [1966], loss: 0.3481, acc: 0.9219\n",
      "Epoch [1967], loss: 0.1809, acc: 0.9531\n",
      "Epoch [1968], loss: 0.3039, acc: 0.9062\n",
      "Epoch [1969], loss: 0.3242, acc: 0.9375\n",
      "Epoch [1970], loss: 0.2825, acc: 0.9062\n",
      "Epoch [1971], loss: 0.3275, acc: 0.9062\n",
      "Epoch [1972], loss: 0.2628, acc: 0.9375\n",
      "Epoch [1973], loss: 0.1564, acc: 0.9688\n",
      "Epoch [1974], loss: 0.2554, acc: 0.9219\n",
      "Epoch [1975], loss: 0.2333, acc: 0.9531\n",
      "Epoch [1976], loss: 0.3774, acc: 0.8906\n",
      "Epoch [1977], loss: 0.2002, acc: 0.9531\n",
      "Epoch [1978], loss: 0.1318, acc: 1.0000\n",
      "Epoch [1979], loss: 0.2811, acc: 0.9062\n",
      "Epoch [1980], loss: 0.2776, acc: 0.8906\n",
      "Epoch [1981], loss: 0.5175, acc: 0.8438\n",
      "Epoch [1982], loss: 0.4298, acc: 0.8594\n",
      "Epoch [1983], loss: 0.3020, acc: 0.9375\n",
      "Epoch [1984], loss: 0.2157, acc: 0.9531\n",
      "Epoch [1985], loss: 0.4316, acc: 0.8438\n",
      "Epoch [1986], loss: 0.3634, acc: 0.9219\n",
      "Epoch [1987], loss: 0.3348, acc: 0.9219\n",
      "Epoch [1988], loss: 0.2470, acc: 0.9219\n",
      "Epoch [1989], loss: 0.4659, acc: 0.8594\n",
      "Epoch [1990], loss: 0.2563, acc: 0.9219\n",
      "Epoch [1991], loss: 0.1989, acc: 0.9688\n",
      "Epoch [1992], loss: 0.2260, acc: 0.9531\n",
      "Epoch [1993], loss: 0.3001, acc: 0.9062\n",
      "Epoch [1994], loss: 0.3478, acc: 0.8594\n",
      "Epoch [1995], loss: 0.3947, acc: 0.9219\n",
      "Epoch [1996], loss: 0.4257, acc: 0.8594\n",
      "Epoch [1997], loss: 0.2836, acc: 0.8906\n",
      "Epoch [1998], loss: 0.2410, acc: 0.9375\n",
      "Epoch [1999], loss: 0.3046, acc: 0.9062\n",
      "Epoch [2000], loss: 0.4653, acc: 0.8750\n",
      "Epoch [2001], loss: 0.3074, acc: 0.8281\n",
      "Epoch [2002], loss: 0.3558, acc: 0.8750\n",
      "Epoch [2003], loss: 0.3097, acc: 0.9219\n",
      "Epoch [2004], loss: 0.2299, acc: 0.9375\n",
      "Epoch [2005], loss: 0.3275, acc: 0.9062\n",
      "Epoch [2006], loss: 0.3309, acc: 0.8594\n",
      "Epoch [2007], loss: 0.3324, acc: 0.8906\n",
      "Epoch [2008], loss: 0.2884, acc: 0.9531\n",
      "Epoch [2009], loss: 0.4566, acc: 0.8750\n",
      "Epoch [2010], loss: 0.2864, acc: 0.9219\n",
      "Epoch [2011], loss: 0.3034, acc: 0.8906\n",
      "Epoch [2012], loss: 0.4924, acc: 0.8750\n",
      "Epoch [2013], loss: 0.6257, acc: 0.7344\n",
      "Epoch [2014], loss: 0.3938, acc: 0.8750\n",
      "Epoch [2015], loss: 0.2032, acc: 0.9375\n",
      "Epoch [2016], loss: 0.3516, acc: 0.8906\n",
      "Epoch [2017], loss: 0.5448, acc: 0.8281\n",
      "Epoch [2018], loss: 0.2700, acc: 0.9219\n",
      "Epoch [2019], loss: 0.3298, acc: 0.9062\n",
      "Epoch [2020], loss: 0.2655, acc: 0.9219\n",
      "Epoch [2021], loss: 0.3799, acc: 0.8750\n",
      "Epoch [2022], loss: 0.2692, acc: 0.9531\n",
      "Epoch [2023], loss: 0.3164, acc: 0.9219\n",
      "Epoch [2024], loss: 0.1875, acc: 0.9531\n",
      "Epoch [2025], loss: 0.4040, acc: 0.8750\n",
      "Epoch [2026], loss: 0.3920, acc: 0.8906\n",
      "Epoch [2027], loss: 0.4766, acc: 0.8438\n",
      "Epoch [2028], loss: 0.3284, acc: 0.9062\n",
      "Epoch [2029], loss: 0.2559, acc: 0.9375\n",
      "Epoch [2030], loss: 0.2113, acc: 0.9531\n",
      "Epoch [2031], loss: 0.3330, acc: 0.8906\n",
      "Epoch [2032], loss: 0.2567, acc: 0.9062\n",
      "Epoch [2033], loss: 0.2624, acc: 0.9375\n",
      "Epoch [2034], loss: 0.3459, acc: 0.9062\n",
      "Epoch [2035], loss: 0.2761, acc: 0.9219\n",
      "Epoch [2036], loss: 0.2623, acc: 0.9375\n",
      "Epoch [2037], loss: 0.3984, acc: 0.8906\n",
      "Epoch [2038], loss: 0.2801, acc: 0.9375\n",
      "Epoch [2039], loss: 0.3115, acc: 0.9219\n",
      "Epoch [2040], loss: 0.2864, acc: 0.9531\n",
      "Epoch [2041], loss: 0.2240, acc: 0.9531\n",
      "Epoch [2042], loss: 0.2983, acc: 0.9219\n",
      "Epoch [2043], loss: 0.3781, acc: 0.8438\n",
      "Epoch [2044], loss: 0.3246, acc: 0.8750\n",
      "Epoch [2045], loss: 0.2783, acc: 0.9531\n",
      "Epoch [2046], loss: 0.2838, acc: 0.9062\n",
      "Epoch [2047], loss: 0.2325, acc: 0.9375\n",
      "Epoch [2048], loss: 0.1893, acc: 0.9688\n",
      "Epoch [2049], loss: 0.3055, acc: 0.8906\n",
      "Epoch [2050], loss: 0.2890, acc: 0.8906\n",
      "Epoch [2051], loss: 0.2499, acc: 0.9375\n",
      "Epoch [2052], loss: 0.3394, acc: 0.9219\n",
      "Epoch [2053], loss: 0.3355, acc: 0.8750\n",
      "Epoch [2054], loss: 0.3556, acc: 0.9219\n",
      "Epoch [2055], loss: 0.2456, acc: 0.9531\n",
      "Epoch [2056], loss: 0.2867, acc: 0.9219\n",
      "Epoch [2057], loss: 0.3330, acc: 0.9062\n",
      "Epoch [2058], loss: 0.3537, acc: 0.8906\n",
      "Epoch [2059], loss: 0.3775, acc: 0.8438\n",
      "Epoch [2060], loss: 0.2905, acc: 0.9219\n",
      "Epoch [2061], loss: 0.2358, acc: 0.9219\n",
      "\n",
      "Checkpoints/2a500model.ckpt Model Saved...\n",
      "Epoch [2062], loss: 0.1697, acc: 0.9531\n",
      "Epoch [2063], loss: 0.3531, acc: 0.8906\n",
      "Epoch [2064], loss: 0.2688, acc: 0.9531\n",
      "Epoch [2065], loss: 0.2191, acc: 0.9375\n",
      "Epoch [2066], loss: 0.4050, acc: 0.9375\n",
      "Epoch [2067], loss: 0.3598, acc: 0.8906\n",
      "Epoch [2068], loss: 0.3332, acc: 0.8750\n",
      "Epoch [2069], loss: 0.3470, acc: 0.8906\n",
      "Epoch [2070], loss: 0.2771, acc: 0.9531\n",
      "Epoch [2071], loss: 0.2858, acc: 0.9219\n",
      "Epoch [2072], loss: 0.2774, acc: 0.9062\n",
      "Epoch [2073], loss: 0.2526, acc: 0.9062\n",
      "Epoch [2074], loss: 0.2904, acc: 0.8750\n",
      "Epoch [2075], loss: 0.2559, acc: 0.9688\n",
      "Epoch [2076], loss: 0.1821, acc: 0.9688\n",
      "Epoch [2077], loss: 0.3478, acc: 0.8906\n",
      "Epoch [2078], loss: 0.2966, acc: 0.9062\n",
      "Epoch [2079], loss: 0.3372, acc: 0.8750\n",
      "Epoch [2080], loss: 0.2646, acc: 0.9062\n",
      "Epoch [2081], loss: 0.4070, acc: 0.8906\n",
      "Epoch [2082], loss: 0.3510, acc: 0.8750\n",
      "Epoch [2083], loss: 0.1633, acc: 0.9844\n",
      "Epoch [2084], loss: 0.2650, acc: 0.9688\n",
      "Epoch [2085], loss: 0.4311, acc: 0.9062\n",
      "Epoch [2086], loss: 0.3670, acc: 0.8906\n",
      "Epoch [2087], loss: 0.1786, acc: 0.9688\n",
      "Epoch [2088], loss: 0.2884, acc: 0.9062\n",
      "Epoch [2089], loss: 0.2121, acc: 0.9219\n",
      "Epoch [2090], loss: 0.2489, acc: 0.9375\n",
      "Epoch [2091], loss: 0.4492, acc: 0.8750\n",
      "Epoch [2092], loss: 0.2945, acc: 0.9062\n",
      "Epoch [2093], loss: 0.3452, acc: 0.9062\n",
      "Epoch [2094], loss: 0.3195, acc: 0.9219\n",
      "Epoch [2095], loss: 0.2329, acc: 0.9375\n",
      "Epoch [2096], loss: 0.3700, acc: 0.8750\n",
      "Epoch [2097], loss: 0.2194, acc: 0.9531\n",
      "Epoch [2098], loss: 0.3072, acc: 0.9531\n",
      "Epoch [2099], loss: 0.3070, acc: 0.9219\n",
      "Epoch [2100], loss: 0.4396, acc: 0.9062\n",
      "Epoch [2101], loss: 0.2676, acc: 0.9219\n",
      "Epoch [2102], loss: 0.3391, acc: 0.9062\n",
      "Epoch [2103], loss: 0.3733, acc: 0.8750\n",
      "Epoch [2104], loss: 0.2470, acc: 0.9375\n",
      "Epoch [2105], loss: 0.2909, acc: 0.8906\n",
      "Epoch [2106], loss: 0.2371, acc: 0.9375\n",
      "Epoch [2107], loss: 0.2848, acc: 0.9219\n",
      "Epoch [2108], loss: 0.2974, acc: 0.9062\n",
      "Epoch [2109], loss: 0.2009, acc: 0.9688\n",
      "Epoch [2110], loss: 0.3291, acc: 0.8906\n",
      "Epoch [2111], loss: 0.2259, acc: 0.9375\n",
      "Epoch [2112], loss: 0.3745, acc: 0.8594\n",
      "Epoch [2113], loss: 0.2439, acc: 0.9375\n",
      "Epoch [2114], loss: 0.3483, acc: 0.9219\n",
      "Epoch [2115], loss: 0.3119, acc: 0.8906\n",
      "Epoch [2116], loss: 0.2293, acc: 0.9688\n",
      "Epoch [2117], loss: 0.3149, acc: 0.8750\n",
      "Epoch [2118], loss: 0.4486, acc: 0.8438\n",
      "Epoch [2119], loss: 0.3446, acc: 0.8906\n",
      "Epoch [2120], loss: 0.2764, acc: 0.9219\n",
      "Epoch [2121], loss: 0.3673, acc: 0.9062\n",
      "Epoch [2122], loss: 0.2802, acc: 0.9219\n",
      "Epoch [2123], loss: 0.3212, acc: 0.8594\n",
      "Epoch [2124], loss: 0.1886, acc: 0.9688\n",
      "Epoch [2125], loss: 0.2057, acc: 0.9375\n",
      "Epoch [2126], loss: 0.2429, acc: 0.9531\n",
      "Epoch [2127], loss: 0.3622, acc: 0.8750\n",
      "Epoch [2128], loss: 0.4495, acc: 0.8281\n",
      "Epoch [2129], loss: 0.2609, acc: 0.9531\n",
      "Epoch [2130], loss: 0.3394, acc: 0.8906\n",
      "Epoch [2131], loss: 0.3143, acc: 0.8906\n",
      "Epoch [2132], loss: 0.3073, acc: 0.8750\n",
      "Epoch [2133], loss: 0.2731, acc: 0.9062\n",
      "Epoch [2134], loss: 0.2126, acc: 0.9531\n",
      "Epoch [2135], loss: 0.1998, acc: 0.9531\n",
      "Epoch [2136], loss: 0.1786, acc: 0.9531\n",
      "Epoch [2137], loss: 0.2925, acc: 0.9219\n",
      "Epoch [2138], loss: 0.2518, acc: 0.9531\n",
      "Epoch [2139], loss: 0.2218, acc: 0.9531\n",
      "Epoch [2140], loss: 0.2883, acc: 0.9219\n",
      "Epoch [2141], loss: 0.2791, acc: 0.9375\n",
      "Epoch [2142], loss: 0.1809, acc: 0.9688\n",
      "Epoch [2143], loss: 0.3356, acc: 0.9062\n",
      "Epoch [2144], loss: 0.1968, acc: 0.9844\n",
      "Epoch [2145], loss: 0.2965, acc: 0.9531\n",
      "Epoch [2146], loss: 0.2085, acc: 0.9531\n",
      "Epoch [2147], loss: 0.2028, acc: 0.9531\n",
      "Epoch [2148], loss: 0.2252, acc: 0.9531\n",
      "Epoch [2149], loss: 0.1877, acc: 0.9531\n",
      "Epoch [2150], loss: 0.2162, acc: 0.9375\n",
      "Epoch [2151], loss: 0.2401, acc: 0.9062\n",
      "Epoch [2152], loss: 0.2953, acc: 0.9219\n",
      "Epoch [2153], loss: 0.3609, acc: 0.8906\n",
      "Epoch [2154], loss: 0.2103, acc: 0.9531\n",
      "Epoch [2155], loss: 0.2550, acc: 0.9375\n",
      "Epoch [2156], loss: 0.1736, acc: 0.9531\n",
      "Epoch [2157], loss: 0.1641, acc: 0.9375\n",
      "Epoch [2158], loss: 0.1743, acc: 0.9531\n",
      "Epoch [2159], loss: 0.2530, acc: 0.9375\n",
      "Epoch [2160], loss: 0.2251, acc: 0.9219\n",
      "Epoch [2161], loss: 0.1671, acc: 0.9688\n",
      "\n",
      "Checkpoints/2a600model.ckpt Model Saved...\n",
      "Epoch [2162], loss: 0.2464, acc: 0.9062\n",
      "Epoch [2163], loss: 0.3548, acc: 0.8750\n",
      "Epoch [2164], loss: 0.2220, acc: 0.9375\n",
      "Epoch [2165], loss: 0.2419, acc: 0.9375\n",
      "Epoch [2166], loss: 0.3148, acc: 0.8906\n",
      "Epoch [2167], loss: 0.1533, acc: 0.9844\n",
      "Epoch [2168], loss: 0.2743, acc: 0.9375\n",
      "Epoch [2169], loss: 0.1890, acc: 0.9375\n",
      "Epoch [2170], loss: 0.3425, acc: 0.8906\n",
      "Epoch [2171], loss: 0.1980, acc: 0.9219\n",
      "Epoch [2172], loss: 0.2121, acc: 0.9375\n",
      "Epoch [2173], loss: 0.2258, acc: 0.9375\n",
      "Epoch [2174], loss: 0.1264, acc: 0.9844\n",
      "Epoch [2175], loss: 0.3014, acc: 0.9062\n",
      "Epoch [2176], loss: 0.2030, acc: 0.9688\n",
      "Epoch [2177], loss: 0.1635, acc: 0.9688\n",
      "Epoch [2178], loss: 0.2541, acc: 0.9375\n",
      "Epoch [2179], loss: 0.1668, acc: 0.9844\n",
      "Epoch [2180], loss: 0.1950, acc: 0.9375\n",
      "Epoch [2181], loss: 0.1492, acc: 0.9531\n",
      "Epoch [2182], loss: 0.2280, acc: 0.9375\n",
      "Epoch [2183], loss: 0.2466, acc: 0.9375\n",
      "Epoch [2184], loss: 0.2512, acc: 0.9219\n",
      "Epoch [2185], loss: 0.2128, acc: 0.9219\n",
      "Epoch [2186], loss: 0.1925, acc: 0.9531\n",
      "Epoch [2187], loss: 0.2497, acc: 0.9219\n",
      "Epoch [2188], loss: 0.3091, acc: 0.9062\n",
      "Epoch [2189], loss: 0.2210, acc: 0.9531\n",
      "Epoch [2190], loss: 0.2023, acc: 0.9531\n",
      "Epoch [2191], loss: 0.2084, acc: 0.9688\n",
      "Epoch [2192], loss: 0.2508, acc: 0.9375\n",
      "Epoch [2193], loss: 0.2073, acc: 0.9062\n",
      "Epoch [2194], loss: 0.2326, acc: 0.9375\n",
      "Epoch [2195], loss: 0.3372, acc: 0.9062\n",
      "Epoch [2196], loss: 0.2214, acc: 0.9375\n",
      "Epoch [2197], loss: 0.2169, acc: 0.9531\n",
      "Epoch [2198], loss: 0.2269, acc: 0.9375\n",
      "Epoch [2199], loss: 0.1969, acc: 0.9375\n",
      "Epoch [2200], loss: 0.3933, acc: 0.8750\n",
      "Epoch [2201], loss: 0.3123, acc: 0.9062\n",
      "Epoch [2202], loss: 0.3499, acc: 0.8906\n",
      "Epoch [2203], loss: 0.2141, acc: 0.9219\n",
      "Epoch [2204], loss: 0.2883, acc: 0.9062\n",
      "Epoch [2205], loss: 0.3449, acc: 0.9375\n",
      "Epoch [2206], loss: 0.2040, acc: 0.9062\n",
      "Epoch [2207], loss: 0.2694, acc: 0.9375\n",
      "Epoch [2208], loss: 0.3499, acc: 0.8594\n",
      "Epoch [2209], loss: 0.3061, acc: 0.9375\n",
      "Epoch [2210], loss: 0.2226, acc: 0.9375\n",
      "Epoch [2211], loss: 0.2628, acc: 0.9219\n",
      "Epoch [2212], loss: 0.3267, acc: 0.9375\n",
      "Epoch [2213], loss: 0.3778, acc: 0.9062\n",
      "Epoch [2214], loss: 0.1909, acc: 0.9531\n",
      "Epoch [2215], loss: 0.2908, acc: 0.9375\n",
      "Epoch [2216], loss: 0.2373, acc: 0.9219\n",
      "Epoch [2217], loss: 0.2972, acc: 0.9375\n",
      "Epoch [2218], loss: 0.2529, acc: 0.9219\n",
      "Epoch [2219], loss: 0.2103, acc: 0.9688\n",
      "Epoch [2220], loss: 0.1985, acc: 0.9375\n",
      "Epoch [2221], loss: 0.2691, acc: 0.9219\n",
      "Epoch [2222], loss: 0.1713, acc: 0.9688\n",
      "Epoch [2223], loss: 0.1283, acc: 1.0000\n",
      "Epoch [2224], loss: 0.2904, acc: 0.9375\n",
      "Epoch [2225], loss: 0.1710, acc: 0.9688\n",
      "Epoch [2226], loss: 0.2058, acc: 0.9531\n",
      "Epoch [2227], loss: 0.3007, acc: 0.9219\n",
      "Epoch [2228], loss: 0.3058, acc: 0.9062\n",
      "Epoch [2229], loss: 0.2075, acc: 0.9531\n",
      "Epoch [2230], loss: 0.1830, acc: 0.9688\n",
      "Epoch [2231], loss: 0.2101, acc: 0.9219\n",
      "Epoch [2232], loss: 0.1857, acc: 0.9531\n",
      "Epoch [2233], loss: 0.3023, acc: 0.9219\n",
      "Epoch [2234], loss: 0.2325, acc: 0.9219\n",
      "Epoch [2235], loss: 0.1886, acc: 0.9375\n",
      "Epoch [2236], loss: 0.2513, acc: 0.9375\n",
      "Epoch [2237], loss: 0.2155, acc: 0.9375\n",
      "Epoch [2238], loss: 0.1532, acc: 0.9688\n",
      "Epoch [2239], loss: 0.1575, acc: 0.9688\n",
      "Epoch [2240], loss: 0.2562, acc: 0.9375\n",
      "Epoch [2241], loss: 0.1837, acc: 0.9844\n",
      "Epoch [2242], loss: 0.2933, acc: 0.9219\n",
      "Epoch [2243], loss: 0.2332, acc: 0.9375\n",
      "Epoch [2244], loss: 0.2111, acc: 0.9531\n",
      "Epoch [2245], loss: 0.2871, acc: 0.9219\n",
      "Epoch [2246], loss: 0.2143, acc: 0.9688\n",
      "Epoch [2247], loss: 0.1752, acc: 0.9844\n",
      "Epoch [2248], loss: 0.2919, acc: 0.9219\n",
      "Epoch [2249], loss: 0.1724, acc: 0.9844\n",
      "Epoch [2250], loss: 0.2803, acc: 0.9219\n",
      "Epoch [2251], loss: 0.3838, acc: 0.9062\n",
      "Epoch [2252], loss: 0.1637, acc: 0.9688\n",
      "Epoch [2253], loss: 0.1792, acc: 0.9531\n",
      "Epoch [2254], loss: 0.2503, acc: 0.9219\n",
      "Epoch [2255], loss: 0.1845, acc: 0.9688\n",
      "Epoch [2256], loss: 0.2182, acc: 0.9531\n",
      "Epoch [2257], loss: 0.1983, acc: 0.9375\n",
      "Epoch [2258], loss: 0.1267, acc: 0.9688\n",
      "Epoch [2259], loss: 0.2711, acc: 0.9219\n",
      "Epoch [2260], loss: 0.1801, acc: 0.9688\n",
      "Epoch [2261], loss: 0.2754, acc: 0.9062\n",
      "\n",
      "Checkpoints/2a700model.ckpt Model Saved...\n",
      "Epoch [2262], loss: 0.3051, acc: 0.9062\n",
      "Epoch [2263], loss: 0.1882, acc: 0.9531\n",
      "Epoch [2264], loss: 0.3391, acc: 0.8906\n",
      "Epoch [2265], loss: 0.3496, acc: 0.8750\n",
      "Epoch [2266], loss: 0.1414, acc: 0.9844\n",
      "Epoch [2267], loss: 0.3674, acc: 0.8906\n",
      "Epoch [2268], loss: 0.0867, acc: 1.0000\n",
      "Epoch [2269], loss: 0.1799, acc: 0.9375\n",
      "Epoch [2270], loss: 0.2919, acc: 0.8906\n",
      "Epoch [2271], loss: 0.3475, acc: 0.9375\n",
      "Epoch [2272], loss: 0.1515, acc: 0.9531\n",
      "Epoch [2273], loss: 0.2120, acc: 0.9219\n",
      "Epoch [2274], loss: 0.2516, acc: 0.9219\n",
      "Epoch [2275], loss: 0.2688, acc: 0.9219\n",
      "Epoch [2276], loss: 0.1755, acc: 0.9219\n",
      "Epoch [2277], loss: 0.4002, acc: 0.8594\n",
      "Epoch [2278], loss: 0.1500, acc: 0.9531\n",
      "Epoch [2279], loss: 0.2676, acc: 0.9375\n",
      "Epoch [2280], loss: 0.3253, acc: 0.9062\n",
      "Epoch [2281], loss: 0.1154, acc: 0.9844\n",
      "Epoch [2282], loss: 0.1671, acc: 0.9531\n",
      "Epoch [2283], loss: 0.2530, acc: 0.9375\n",
      "Epoch [2284], loss: 0.1949, acc: 0.9531\n",
      "Epoch [2285], loss: 0.1726, acc: 0.9531\n",
      "Epoch [2286], loss: 0.2177, acc: 0.9375\n",
      "Epoch [2287], loss: 0.1732, acc: 0.9531\n",
      "Epoch [2288], loss: 0.2282, acc: 0.9375\n",
      "Epoch [2289], loss: 0.1704, acc: 0.9531\n",
      "Epoch [2290], loss: 0.2581, acc: 0.9375\n",
      "Epoch [2291], loss: 0.2665, acc: 0.9531\n",
      "Epoch [2292], loss: 0.3178, acc: 0.9062\n",
      "Epoch [2293], loss: 0.2605, acc: 0.9062\n",
      "Epoch [2294], loss: 0.3193, acc: 0.8750\n",
      "Epoch [2295], loss: 0.4411, acc: 0.8906\n",
      "Epoch [2296], loss: 0.2509, acc: 0.8906\n",
      "Epoch [2297], loss: 0.2138, acc: 0.9219\n",
      "Epoch [2298], loss: 0.3186, acc: 0.9219\n",
      "Epoch [2299], loss: 0.2055, acc: 0.9219\n",
      "Epoch [2300], loss: 0.2139, acc: 0.9531\n",
      "Epoch [2301], loss: 0.3212, acc: 0.9062\n",
      "Epoch [2302], loss: 0.1612, acc: 0.9531\n",
      "Epoch [2303], loss: 0.2540, acc: 0.9219\n",
      "Epoch [2304], loss: 0.1173, acc: 1.0000\n",
      "Epoch [2305], loss: 0.2414, acc: 0.9219\n",
      "Epoch [2306], loss: 0.1981, acc: 0.9844\n",
      "Epoch [2307], loss: 0.1983, acc: 0.9531\n",
      "Epoch [2308], loss: 0.2879, acc: 0.9062\n",
      "Epoch [2309], loss: 0.4633, acc: 0.9375\n",
      "Epoch [2310], loss: 0.2474, acc: 0.9375\n",
      "Epoch [2311], loss: 0.3804, acc: 0.8438\n",
      "Epoch [2312], loss: 0.2335, acc: 0.9375\n",
      "Epoch [2313], loss: 0.1866, acc: 0.9531\n",
      "Epoch [2314], loss: 0.1827, acc: 0.9688\n",
      "Epoch [2315], loss: 0.2349, acc: 0.9375\n",
      "Epoch [2316], loss: 0.2313, acc: 0.9688\n",
      "Epoch [2317], loss: 0.2895, acc: 0.8906\n",
      "Epoch [2318], loss: 0.2923, acc: 0.9531\n",
      "Epoch [2319], loss: 0.1708, acc: 0.9375\n",
      "Epoch [2320], loss: 0.3598, acc: 0.8750\n",
      "Epoch [2321], loss: 0.2190, acc: 0.9375\n",
      "Epoch [2322], loss: 0.3751, acc: 0.8594\n",
      "Epoch [2323], loss: 0.1003, acc: 0.9844\n",
      "Epoch [2324], loss: 0.2200, acc: 0.9219\n",
      "Epoch [2325], loss: 0.2826, acc: 0.9062\n",
      "Epoch [2326], loss: 0.2041, acc: 0.9531\n",
      "Epoch [2327], loss: 0.1487, acc: 0.9844\n",
      "Epoch [2328], loss: 0.3138, acc: 0.8750\n",
      "Epoch [2329], loss: 0.5259, acc: 0.8281\n",
      "Epoch [2330], loss: 0.2146, acc: 0.9219\n",
      "Epoch [2331], loss: 0.1319, acc: 0.9844\n",
      "Epoch [2332], loss: 0.2841, acc: 0.9219\n",
      "Epoch [2333], loss: 0.2434, acc: 0.9531\n",
      "Epoch [2334], loss: 0.2065, acc: 0.9531\n",
      "Epoch [2335], loss: 0.1972, acc: 0.9531\n",
      "Epoch [2336], loss: 0.4103, acc: 0.8750\n",
      "Epoch [2337], loss: 0.2152, acc: 0.9219\n",
      "Epoch [2338], loss: 0.1607, acc: 0.9688\n",
      "Epoch [2339], loss: 0.1863, acc: 0.9219\n",
      "Epoch [2340], loss: 0.1792, acc: 0.9688\n",
      "Epoch [2341], loss: 0.1873, acc: 0.9844\n",
      "Epoch [2342], loss: 0.3112, acc: 0.9219\n",
      "\n",
      "Checkpoints/2model.ckpt Model Saved...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77447f78cd8c410fb2323d3391078c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checkpoints/3a0model.ckpt Model Saved...\n",
      "Epoch [2343], loss: 0.1931, acc: 0.9688\n",
      "Epoch [2344], loss: 0.4026, acc: 0.8750\n",
      "Epoch [2345], loss: 0.2665, acc: 0.9375\n",
      "Epoch [2346], loss: 0.1074, acc: 0.9844\n",
      "Epoch [2347], loss: 0.2107, acc: 0.9219\n",
      "Epoch [2348], loss: 0.2597, acc: 0.9531\n",
      "Epoch [2349], loss: 0.2769, acc: 0.9219\n",
      "Epoch [2350], loss: 0.2036, acc: 0.9844\n",
      "Epoch [2351], loss: 0.2237, acc: 0.9375\n",
      "Epoch [2352], loss: 0.2629, acc: 0.9375\n",
      "Epoch [2353], loss: 0.2792, acc: 0.9219\n",
      "Epoch [2354], loss: 0.2909, acc: 0.8906\n",
      "Epoch [2355], loss: 0.2641, acc: 0.9062\n",
      "Epoch [2356], loss: 0.3216, acc: 0.9219\n",
      "Epoch [2357], loss: 0.4014, acc: 0.8438\n",
      "Epoch [2358], loss: 0.2035, acc: 0.9688\n",
      "Epoch [2359], loss: 0.3107, acc: 0.9219\n",
      "Epoch [2360], loss: 0.2629, acc: 0.9531\n",
      "Epoch [2361], loss: 0.2821, acc: 0.8906\n",
      "Epoch [2362], loss: 0.2138, acc: 0.9375\n",
      "Epoch [2363], loss: 0.2423, acc: 0.9062\n",
      "Epoch [2364], loss: 0.2476, acc: 0.9062\n",
      "Epoch [2365], loss: 0.1723, acc: 0.9375\n",
      "Epoch [2366], loss: 0.2118, acc: 0.9688\n",
      "Epoch [2367], loss: 0.2149, acc: 0.9219\n",
      "Epoch [2368], loss: 0.2284, acc: 0.9375\n",
      "Epoch [2369], loss: 0.2608, acc: 0.9531\n",
      "Epoch [2370], loss: 0.2878, acc: 0.9062\n",
      "Epoch [2371], loss: 0.2187, acc: 0.9688\n",
      "Epoch [2372], loss: 0.1714, acc: 0.9375\n",
      "Epoch [2373], loss: 0.3247, acc: 0.8594\n",
      "Epoch [2374], loss: 0.2941, acc: 0.9219\n",
      "Epoch [2375], loss: 0.2269, acc: 0.9062\n",
      "Epoch [2376], loss: 0.3771, acc: 0.8906\n",
      "Epoch [2377], loss: 0.2775, acc: 0.9688\n",
      "Epoch [2378], loss: 0.2114, acc: 0.9375\n",
      "Epoch [2379], loss: 0.1630, acc: 0.9688\n",
      "Epoch [2380], loss: 0.1070, acc: 0.9844\n",
      "Epoch [2381], loss: 0.2624, acc: 0.9062\n",
      "Epoch [2382], loss: 0.2905, acc: 0.9219\n",
      "Epoch [2383], loss: 0.2001, acc: 0.9531\n",
      "Epoch [2384], loss: 0.3108, acc: 0.9062\n",
      "Epoch [2385], loss: 0.2287, acc: 0.9688\n",
      "Epoch [2386], loss: 0.2809, acc: 0.9219\n",
      "Epoch [2387], loss: 0.3133, acc: 0.9062\n",
      "Epoch [2388], loss: 0.2669, acc: 0.8906\n",
      "Epoch [2389], loss: 0.1318, acc: 0.9688\n",
      "Epoch [2390], loss: 0.2760, acc: 0.9062\n",
      "Epoch [2391], loss: 0.1991, acc: 0.9688\n",
      "Epoch [2392], loss: 0.3002, acc: 0.9219\n",
      "Epoch [2393], loss: 0.2665, acc: 0.9062\n",
      "Epoch [2394], loss: 0.3132, acc: 0.9375\n",
      "Epoch [2395], loss: 0.4375, acc: 0.8594\n",
      "Epoch [2396], loss: 0.2445, acc: 0.9062\n",
      "Epoch [2397], loss: 0.2039, acc: 0.9375\n",
      "Epoch [2398], loss: 0.2899, acc: 0.8750\n",
      "Epoch [2399], loss: 0.1771, acc: 0.9531\n",
      "Epoch [2400], loss: 0.2135, acc: 0.9688\n",
      "Epoch [2401], loss: 0.3399, acc: 0.9219\n",
      "Epoch [2402], loss: 0.1306, acc: 0.9844\n",
      "Epoch [2403], loss: 0.2244, acc: 0.9219\n",
      "Epoch [2404], loss: 0.2919, acc: 0.9062\n",
      "Epoch [2405], loss: 0.2230, acc: 0.9375\n",
      "Epoch [2406], loss: 0.1942, acc: 0.9375\n",
      "Epoch [2407], loss: 0.1964, acc: 0.9531\n",
      "Epoch [2408], loss: 0.1841, acc: 0.9375\n",
      "Epoch [2409], loss: 0.2585, acc: 0.8906\n",
      "Epoch [2410], loss: 0.2071, acc: 0.9219\n",
      "Epoch [2411], loss: 0.1692, acc: 0.9688\n",
      "Epoch [2412], loss: 0.1309, acc: 0.9844\n",
      "Epoch [2413], loss: 0.1646, acc: 0.9844\n",
      "Epoch [2414], loss: 0.1948, acc: 0.9219\n",
      "Epoch [2415], loss: 0.1971, acc: 0.9375\n",
      "Epoch [2416], loss: 0.4461, acc: 0.8750\n",
      "Epoch [2417], loss: 0.2802, acc: 0.9375\n",
      "Epoch [2418], loss: 0.1952, acc: 0.9531\n",
      "Epoch [2419], loss: 0.2409, acc: 0.9062\n",
      "Epoch [2420], loss: 0.2353, acc: 0.9219\n",
      "Epoch [2421], loss: 0.1977, acc: 0.9688\n",
      "Epoch [2422], loss: 0.2358, acc: 0.9062\n",
      "Epoch [2423], loss: 0.1629, acc: 0.9531\n",
      "Epoch [2424], loss: 0.1941, acc: 0.9688\n",
      "Epoch [2425], loss: 0.2314, acc: 0.9375\n",
      "Epoch [2426], loss: 0.2010, acc: 0.9688\n",
      "Epoch [2427], loss: 0.3490, acc: 0.9062\n",
      "Epoch [2428], loss: 0.1109, acc: 0.9844\n",
      "Epoch [2429], loss: 0.2296, acc: 0.9219\n",
      "Epoch [2430], loss: 0.1806, acc: 0.9531\n",
      "Epoch [2431], loss: 0.1749, acc: 0.9531\n",
      "Epoch [2432], loss: 0.2745, acc: 0.9375\n",
      "Epoch [2433], loss: 0.2064, acc: 0.9219\n",
      "Epoch [2434], loss: 0.2145, acc: 0.9531\n",
      "Epoch [2435], loss: 0.3889, acc: 0.8594\n",
      "Epoch [2436], loss: 0.1715, acc: 0.9375\n",
      "Epoch [2437], loss: 0.1532, acc: 0.9688\n",
      "Epoch [2438], loss: 0.2759, acc: 0.8750\n",
      "Epoch [2439], loss: 0.2291, acc: 0.9375\n",
      "Epoch [2440], loss: 0.2370, acc: 0.9219\n",
      "Epoch [2441], loss: 0.3025, acc: 0.8906\n",
      "Epoch [2442], loss: 0.1948, acc: 0.9531\n",
      "\n",
      "Checkpoints/3a100model.ckpt Model Saved...\n",
      "Epoch [2443], loss: 0.2280, acc: 0.8906\n",
      "Epoch [2444], loss: 0.1112, acc: 0.9844\n",
      "Epoch [2445], loss: 0.1504, acc: 0.9844\n",
      "Epoch [2446], loss: 0.2339, acc: 0.9062\n",
      "Epoch [2447], loss: 0.2036, acc: 0.9688\n",
      "Epoch [2448], loss: 0.2797, acc: 0.8594\n",
      "Epoch [2449], loss: 0.1914, acc: 0.9219\n",
      "Epoch [2450], loss: 0.4228, acc: 0.8594\n",
      "Epoch [2451], loss: 0.1162, acc: 1.0000\n",
      "Epoch [2452], loss: 0.2981, acc: 0.8906\n",
      "Epoch [2453], loss: 0.2460, acc: 0.9219\n",
      "Epoch [2454], loss: 0.2604, acc: 0.9219\n",
      "Epoch [2455], loss: 0.2372, acc: 0.9375\n",
      "Epoch [2456], loss: 0.2520, acc: 0.9375\n",
      "Epoch [2457], loss: 0.2999, acc: 0.9219\n",
      "Epoch [2458], loss: 0.2248, acc: 0.9531\n",
      "Epoch [2459], loss: 0.1532, acc: 0.9531\n",
      "Epoch [2460], loss: 0.2228, acc: 0.9531\n",
      "Epoch [2461], loss: 0.2235, acc: 0.9531\n",
      "Epoch [2462], loss: 0.1352, acc: 0.9844\n",
      "Epoch [2463], loss: 0.1553, acc: 0.9688\n",
      "Epoch [2464], loss: 0.1865, acc: 0.9688\n",
      "Epoch [2465], loss: 0.2460, acc: 0.9219\n",
      "Epoch [2466], loss: 0.1674, acc: 0.9219\n",
      "Epoch [2467], loss: 0.1595, acc: 0.9844\n",
      "Epoch [2468], loss: 0.2809, acc: 0.8906\n",
      "Epoch [2469], loss: 0.2102, acc: 0.9375\n",
      "Epoch [2470], loss: 0.0753, acc: 0.9844\n",
      "Epoch [2471], loss: 0.2232, acc: 0.9375\n",
      "Epoch [2472], loss: 0.2577, acc: 0.9531\n",
      "Epoch [2473], loss: 0.1935, acc: 0.9531\n",
      "Epoch [2474], loss: 0.2503, acc: 0.9062\n",
      "Epoch [2475], loss: 0.2983, acc: 0.9375\n",
      "Epoch [2476], loss: 0.2087, acc: 0.9375\n",
      "Epoch [2477], loss: 0.1899, acc: 0.9375\n",
      "Epoch [2478], loss: 0.3476, acc: 0.9062\n",
      "Epoch [2479], loss: 0.2848, acc: 0.9531\n",
      "Epoch [2480], loss: 0.2123, acc: 0.9375\n",
      "Epoch [2481], loss: 0.2450, acc: 0.9375\n",
      "Epoch [2482], loss: 0.2648, acc: 0.9062\n",
      "Epoch [2483], loss: 0.2235, acc: 0.9375\n",
      "Epoch [2484], loss: 0.2190, acc: 0.9531\n",
      "Epoch [2485], loss: 0.2326, acc: 0.9375\n",
      "Epoch [2486], loss: 0.2129, acc: 0.9062\n",
      "Epoch [2487], loss: 0.2509, acc: 0.9062\n",
      "Epoch [2488], loss: 0.2499, acc: 0.9375\n",
      "Epoch [2489], loss: 0.1825, acc: 0.9531\n",
      "Epoch [2490], loss: 0.3312, acc: 0.9062\n",
      "Epoch [2491], loss: 0.2168, acc: 0.9531\n",
      "Epoch [2492], loss: 0.2000, acc: 0.9531\n",
      "Epoch [2493], loss: 0.1852, acc: 0.9688\n",
      "Epoch [2494], loss: 0.3077, acc: 0.8906\n",
      "Epoch [2495], loss: 0.1373, acc: 0.9844\n",
      "Epoch [2496], loss: 0.1846, acc: 0.9688\n",
      "Epoch [2497], loss: 0.2867, acc: 0.9062\n",
      "Epoch [2498], loss: 0.1584, acc: 0.9688\n",
      "Epoch [2499], loss: 0.1544, acc: 0.9844\n",
      "Epoch [2500], loss: 0.2551, acc: 0.9531\n",
      "Epoch [2501], loss: 0.2504, acc: 0.9375\n",
      "Epoch [2502], loss: 0.2842, acc: 0.9219\n",
      "Epoch [2503], loss: 0.3434, acc: 0.8906\n",
      "Epoch [2504], loss: 0.2914, acc: 0.9375\n",
      "Epoch [2505], loss: 0.3515, acc: 0.9062\n",
      "Epoch [2506], loss: 0.2616, acc: 0.9375\n",
      "Epoch [2507], loss: 0.2372, acc: 0.9375\n",
      "Epoch [2508], loss: 0.3906, acc: 0.8906\n",
      "Epoch [2509], loss: 0.2192, acc: 0.9062\n",
      "Epoch [2510], loss: 0.2800, acc: 0.9219\n",
      "Epoch [2511], loss: 0.2509, acc: 0.9531\n",
      "Epoch [2512], loss: 0.2396, acc: 0.9219\n",
      "Epoch [2513], loss: 0.2580, acc: 0.9375\n",
      "Epoch [2514], loss: 0.2805, acc: 0.9062\n",
      "Epoch [2515], loss: 0.2550, acc: 0.9219\n",
      "Epoch [2516], loss: 0.2189, acc: 0.9531\n",
      "Epoch [2517], loss: 0.3129, acc: 0.8906\n",
      "Epoch [2518], loss: 0.2142, acc: 0.9688\n",
      "Epoch [2519], loss: 0.1834, acc: 0.9531\n",
      "Epoch [2520], loss: 0.2348, acc: 0.9375\n",
      "Epoch [2521], loss: 0.2641, acc: 0.9531\n",
      "Epoch [2522], loss: 0.2801, acc: 0.9219\n",
      "Epoch [2523], loss: 0.1808, acc: 0.9688\n",
      "Epoch [2524], loss: 0.1474, acc: 0.9688\n",
      "Epoch [2525], loss: 0.2171, acc: 0.9688\n",
      "Epoch [2526], loss: 0.2137, acc: 0.9688\n",
      "Epoch [2527], loss: 0.2180, acc: 0.9531\n",
      "Epoch [2528], loss: 0.2952, acc: 0.9219\n",
      "Epoch [2529], loss: 0.2257, acc: 0.9062\n",
      "Epoch [2530], loss: 0.1860, acc: 0.9375\n",
      "Epoch [2531], loss: 0.1950, acc: 0.9688\n",
      "Epoch [2532], loss: 0.2129, acc: 0.9531\n",
      "Epoch [2533], loss: 0.1147, acc: 0.9844\n",
      "Epoch [2534], loss: 0.2843, acc: 0.9219\n",
      "Epoch [2535], loss: 0.2743, acc: 0.9219\n",
      "Epoch [2536], loss: 0.1404, acc: 0.9844\n",
      "Epoch [2537], loss: 0.2303, acc: 0.9375\n",
      "Epoch [2538], loss: 0.1768, acc: 0.9531\n",
      "Epoch [2539], loss: 0.2309, acc: 0.9375\n",
      "Epoch [2540], loss: 0.1807, acc: 0.9688\n",
      "Epoch [2541], loss: 0.2101, acc: 0.9375\n",
      "Epoch [2542], loss: 0.1718, acc: 0.9375\n",
      "\n",
      "Checkpoints/3a200model.ckpt Model Saved...\n",
      "Epoch [2543], loss: 0.2402, acc: 0.9219\n",
      "Epoch [2544], loss: 0.2239, acc: 0.9531\n",
      "Epoch [2545], loss: 0.3031, acc: 0.8594\n",
      "Epoch [2546], loss: 0.2015, acc: 0.9531\n",
      "Epoch [2547], loss: 0.2164, acc: 0.9531\n",
      "Epoch [2548], loss: 0.3039, acc: 0.8750\n",
      "Epoch [2549], loss: 0.2590, acc: 0.9531\n",
      "Epoch [2550], loss: 0.1928, acc: 0.9531\n",
      "Epoch [2551], loss: 0.1875, acc: 0.9844\n",
      "Epoch [2552], loss: 0.1649, acc: 0.9688\n",
      "Epoch [2553], loss: 0.1812, acc: 0.9531\n",
      "Epoch [2554], loss: 0.2553, acc: 0.9219\n",
      "Epoch [2555], loss: 0.2277, acc: 0.9375\n",
      "Epoch [2556], loss: 0.2736, acc: 0.8906\n",
      "Epoch [2557], loss: 0.1700, acc: 0.9688\n",
      "Epoch [2558], loss: 0.2955, acc: 0.9219\n",
      "Epoch [2559], loss: 0.2890, acc: 0.9062\n",
      "Epoch [2560], loss: 0.2250, acc: 0.9219\n",
      "Epoch [2561], loss: 0.1988, acc: 0.9688\n",
      "Epoch [2562], loss: 0.2116, acc: 0.9219\n",
      "Epoch [2563], loss: 0.3615, acc: 0.9219\n",
      "Epoch [2564], loss: 0.2426, acc: 0.9375\n",
      "Epoch [2565], loss: 0.2260, acc: 0.9375\n",
      "Epoch [2566], loss: 0.1036, acc: 0.9844\n",
      "Epoch [2567], loss: 0.3058, acc: 0.8906\n",
      "Epoch [2568], loss: 0.2769, acc: 0.9375\n",
      "Epoch [2569], loss: 0.1992, acc: 0.9062\n",
      "Epoch [2570], loss: 0.2161, acc: 0.9531\n",
      "Epoch [2571], loss: 0.2584, acc: 0.9219\n",
      "Epoch [2572], loss: 0.1934, acc: 0.9688\n",
      "Epoch [2573], loss: 0.2020, acc: 0.9688\n",
      "Epoch [2574], loss: 0.1512, acc: 1.0000\n",
      "Epoch [2575], loss: 0.1522, acc: 0.9688\n",
      "Epoch [2576], loss: 0.2802, acc: 0.9062\n",
      "Epoch [2577], loss: 0.1489, acc: 0.9688\n",
      "Epoch [2578], loss: 0.2585, acc: 0.9062\n",
      "Epoch [2579], loss: 0.2778, acc: 0.8906\n",
      "Epoch [2580], loss: 0.2075, acc: 0.9531\n",
      "Epoch [2581], loss: 0.1551, acc: 0.9688\n",
      "Epoch [2582], loss: 0.1892, acc: 0.9688\n",
      "Epoch [2583], loss: 0.2155, acc: 0.9219\n",
      "Epoch [2584], loss: 0.1557, acc: 0.9688\n",
      "Epoch [2585], loss: 0.1621, acc: 0.9375\n",
      "Epoch [2586], loss: 0.3077, acc: 0.8906\n",
      "Epoch [2587], loss: 0.1610, acc: 0.9688\n",
      "Epoch [2588], loss: 0.2865, acc: 0.8906\n",
      "Epoch [2589], loss: 0.1888, acc: 0.9688\n",
      "Epoch [2590], loss: 0.0925, acc: 0.9844\n",
      "Epoch [2591], loss: 0.1903, acc: 0.9531\n",
      "Epoch [2592], loss: 0.2812, acc: 0.9062\n",
      "Epoch [2593], loss: 0.2349, acc: 0.9219\n",
      "Epoch [2594], loss: 0.1647, acc: 0.9844\n",
      "Epoch [2595], loss: 0.3294, acc: 0.9219\n",
      "Epoch [2596], loss: 0.2024, acc: 0.9531\n",
      "Epoch [2597], loss: 0.2090, acc: 0.9531\n",
      "Epoch [2598], loss: 0.1819, acc: 0.9688\n",
      "Epoch [2599], loss: 0.3190, acc: 0.9062\n",
      "Epoch [2600], loss: 0.1233, acc: 0.9844\n",
      "Epoch [2601], loss: 0.1655, acc: 0.9531\n",
      "Epoch [2602], loss: 0.3116, acc: 0.9219\n",
      "Epoch [2603], loss: 0.2766, acc: 0.9062\n",
      "Epoch [2604], loss: 0.1970, acc: 0.9531\n",
      "Epoch [2605], loss: 0.2325, acc: 0.9375\n",
      "Epoch [2606], loss: 0.2297, acc: 0.9062\n",
      "Epoch [2607], loss: 0.2466, acc: 0.9375\n",
      "Epoch [2608], loss: 0.1149, acc: 1.0000\n",
      "Epoch [2609], loss: 0.3013, acc: 0.9219\n",
      "Epoch [2610], loss: 0.2564, acc: 0.9219\n",
      "Epoch [2611], loss: 0.2727, acc: 0.9375\n",
      "Epoch [2612], loss: 0.1223, acc: 0.9688\n",
      "Epoch [2613], loss: 0.3882, acc: 0.8750\n",
      "Epoch [2614], loss: 0.2086, acc: 0.9219\n",
      "Epoch [2615], loss: 0.1385, acc: 0.9688\n",
      "Epoch [2616], loss: 0.1841, acc: 0.9531\n",
      "Epoch [2617], loss: 0.3085, acc: 0.9062\n",
      "Epoch [2618], loss: 0.1953, acc: 0.9531\n",
      "Epoch [2619], loss: 0.4036, acc: 0.8594\n",
      "Epoch [2620], loss: 0.3363, acc: 0.8594\n",
      "Epoch [2621], loss: 0.2853, acc: 0.8906\n",
      "Epoch [2622], loss: 0.1531, acc: 0.9688\n",
      "Epoch [2623], loss: 0.1859, acc: 0.9531\n",
      "Epoch [2624], loss: 0.3096, acc: 0.9375\n",
      "Epoch [2625], loss: 0.2462, acc: 0.9375\n",
      "Epoch [2626], loss: 0.1800, acc: 0.9531\n",
      "Epoch [2627], loss: 0.1904, acc: 0.9688\n",
      "Epoch [2628], loss: 0.2864, acc: 0.9375\n",
      "Epoch [2629], loss: 0.2085, acc: 0.9219\n",
      "Epoch [2630], loss: 0.2742, acc: 0.9219\n",
      "Epoch [2631], loss: 0.2002, acc: 0.9688\n",
      "Epoch [2632], loss: 0.2160, acc: 0.9531\n",
      "Epoch [2633], loss: 0.1905, acc: 0.9844\n",
      "Epoch [2634], loss: 0.2520, acc: 0.9375\n",
      "Epoch [2635], loss: 0.2684, acc: 0.9062\n",
      "Epoch [2636], loss: 0.1960, acc: 0.9844\n",
      "Epoch [2637], loss: 0.1530, acc: 0.9688\n",
      "Epoch [2638], loss: 0.2245, acc: 0.9062\n",
      "Epoch [2639], loss: 0.3460, acc: 0.9062\n",
      "Epoch [2640], loss: 0.4651, acc: 0.8281\n",
      "Epoch [2641], loss: 0.2195, acc: 0.9062\n",
      "Epoch [2642], loss: 0.2232, acc: 0.9531\n",
      "\n",
      "Checkpoints/3a300model.ckpt Model Saved...\n",
      "Epoch [2643], loss: 0.1665, acc: 0.9531\n",
      "Epoch [2644], loss: 0.2430, acc: 0.9531\n",
      "Epoch [2645], loss: 0.2108, acc: 0.9531\n",
      "Epoch [2646], loss: 0.3522, acc: 0.8906\n",
      "Epoch [2647], loss: 0.1728, acc: 0.9688\n",
      "Epoch [2648], loss: 0.1895, acc: 0.9844\n",
      "Epoch [2649], loss: 0.4932, acc: 0.8125\n",
      "Epoch [2650], loss: 0.1554, acc: 0.9844\n",
      "Epoch [2651], loss: 0.1678, acc: 0.9688\n",
      "Epoch [2652], loss: 0.2517, acc: 0.9688\n",
      "Epoch [2653], loss: 0.2019, acc: 0.9531\n",
      "Epoch [2654], loss: 0.1737, acc: 0.9688\n",
      "Epoch [2655], loss: 0.2016, acc: 0.9531\n",
      "Epoch [2656], loss: 0.2909, acc: 0.9062\n",
      "Epoch [2657], loss: 0.2520, acc: 0.9219\n",
      "Epoch [2658], loss: 0.1807, acc: 0.9844\n",
      "Epoch [2659], loss: 0.1640, acc: 0.9531\n",
      "Epoch [2660], loss: 0.2607, acc: 0.9219\n",
      "Epoch [2661], loss: 0.2076, acc: 0.9531\n",
      "Epoch [2662], loss: 0.1780, acc: 0.9531\n",
      "Epoch [2663], loss: 0.1858, acc: 0.9531\n",
      "Epoch [2664], loss: 0.2634, acc: 0.9219\n",
      "Epoch [2665], loss: 0.2624, acc: 0.9062\n",
      "Epoch [2666], loss: 0.2054, acc: 0.9531\n",
      "Epoch [2667], loss: 0.2008, acc: 0.9688\n",
      "Epoch [2668], loss: 0.1495, acc: 0.9688\n",
      "Epoch [2669], loss: 0.2816, acc: 0.9062\n",
      "Epoch [2670], loss: 0.1930, acc: 0.9844\n",
      "Epoch [2671], loss: 0.1867, acc: 0.9375\n",
      "Epoch [2672], loss: 0.2664, acc: 0.9531\n",
      "Epoch [2673], loss: 0.1713, acc: 0.9688\n",
      "Epoch [2674], loss: 0.2393, acc: 0.9219\n",
      "Epoch [2675], loss: 0.2334, acc: 0.9375\n",
      "Epoch [2676], loss: 0.1641, acc: 0.9688\n",
      "Epoch [2677], loss: 0.2782, acc: 0.8906\n",
      "Epoch [2678], loss: 0.1323, acc: 0.9688\n",
      "Epoch [2679], loss: 0.1880, acc: 0.9531\n",
      "Epoch [2680], loss: 0.2505, acc: 0.9062\n",
      "Epoch [2681], loss: 0.1496, acc: 0.9688\n",
      "Epoch [2682], loss: 0.2365, acc: 0.8750\n",
      "Epoch [2683], loss: 0.3018, acc: 0.8594\n",
      "Epoch [2684], loss: 0.1987, acc: 0.9531\n",
      "Epoch [2685], loss: 0.1552, acc: 0.9531\n",
      "Epoch [2686], loss: 0.4015, acc: 0.8750\n",
      "Epoch [2687], loss: 0.2520, acc: 0.9062\n",
      "Epoch [2688], loss: 0.2429, acc: 0.9062\n",
      "Epoch [2689], loss: 0.1842, acc: 0.9688\n",
      "Epoch [2690], loss: 0.1742, acc: 0.9375\n",
      "Epoch [2691], loss: 0.1755, acc: 0.9688\n",
      "Epoch [2692], loss: 0.2257, acc: 0.9375\n",
      "Epoch [2693], loss: 0.3589, acc: 0.9219\n",
      "Epoch [2694], loss: 0.1580, acc: 0.9844\n",
      "Epoch [2695], loss: 0.2083, acc: 0.9688\n",
      "Epoch [2696], loss: 0.3031, acc: 0.8750\n",
      "Epoch [2697], loss: 0.2863, acc: 0.9219\n",
      "Epoch [2698], loss: 0.2513, acc: 0.9531\n",
      "Epoch [2699], loss: 0.1401, acc: 0.9531\n",
      "Epoch [2700], loss: 0.1433, acc: 0.9688\n",
      "Epoch [2701], loss: 0.1999, acc: 0.9375\n",
      "Epoch [2702], loss: 0.2652, acc: 0.9219\n",
      "Epoch [2703], loss: 0.2233, acc: 0.9375\n",
      "Epoch [2704], loss: 0.2256, acc: 0.9375\n",
      "Epoch [2705], loss: 0.2401, acc: 0.9219\n",
      "Epoch [2706], loss: 0.1457, acc: 1.0000\n",
      "Epoch [2707], loss: 0.2511, acc: 0.9219\n",
      "Epoch [2708], loss: 0.2328, acc: 0.9219\n",
      "Epoch [2709], loss: 0.1606, acc: 0.9688\n",
      "Epoch [2710], loss: 0.2412, acc: 0.9219\n",
      "Epoch [2711], loss: 0.2325, acc: 0.9219\n",
      "Epoch [2712], loss: 0.1790, acc: 0.9844\n",
      "Epoch [2713], loss: 0.2240, acc: 0.9688\n",
      "Epoch [2714], loss: 0.2686, acc: 0.8906\n",
      "Epoch [2715], loss: 0.2722, acc: 0.9375\n",
      "Epoch [2716], loss: 0.2382, acc: 0.9062\n",
      "Epoch [2717], loss: 0.1990, acc: 0.9219\n",
      "Epoch [2718], loss: 0.2334, acc: 0.9375\n",
      "Epoch [2719], loss: 0.2210, acc: 0.9531\n",
      "Epoch [2720], loss: 0.2622, acc: 0.9062\n",
      "Epoch [2721], loss: 0.1957, acc: 0.9219\n",
      "Epoch [2722], loss: 0.2000, acc: 0.9375\n",
      "Epoch [2723], loss: 0.1908, acc: 0.9531\n",
      "Epoch [2724], loss: 0.2461, acc: 0.9375\n",
      "Epoch [2725], loss: 0.1595, acc: 0.9688\n",
      "Epoch [2726], loss: 0.3408, acc: 0.8906\n",
      "Epoch [2727], loss: 0.2404, acc: 0.9375\n",
      "Epoch [2728], loss: 0.4175, acc: 0.8906\n",
      "Epoch [2729], loss: 0.2236, acc: 0.9062\n",
      "Epoch [2730], loss: 0.2767, acc: 0.8906\n",
      "Epoch [2731], loss: 0.2840, acc: 0.8906\n",
      "Epoch [2732], loss: 0.1757, acc: 0.9688\n",
      "Epoch [2733], loss: 0.2436, acc: 0.8906\n",
      "Epoch [2734], loss: 0.2300, acc: 0.9219\n",
      "Epoch [2735], loss: 0.2458, acc: 0.9219\n",
      "Epoch [2736], loss: 0.2258, acc: 0.9375\n",
      "Epoch [2737], loss: 0.2511, acc: 0.9219\n",
      "Epoch [2738], loss: 0.1326, acc: 0.9844\n",
      "Epoch [2739], loss: 0.2252, acc: 0.9531\n",
      "Epoch [2740], loss: 0.3248, acc: 0.8906\n",
      "Epoch [2741], loss: 0.1848, acc: 0.9688\n",
      "Epoch [2742], loss: 0.1850, acc: 0.9375\n",
      "\n",
      "Checkpoints/3a400model.ckpt Model Saved...\n",
      "Epoch [2743], loss: 0.3321, acc: 0.9219\n",
      "Epoch [2744], loss: 0.1776, acc: 0.9844\n",
      "Epoch [2745], loss: 0.2188, acc: 0.9062\n",
      "Epoch [2746], loss: 0.2268, acc: 0.9375\n",
      "Epoch [2747], loss: 0.2775, acc: 0.9219\n",
      "Epoch [2748], loss: 0.3938, acc: 0.8438\n",
      "Epoch [2749], loss: 0.2132, acc: 0.9219\n",
      "Epoch [2750], loss: 0.1810, acc: 0.9375\n",
      "Epoch [2751], loss: 0.2131, acc: 0.9531\n",
      "Epoch [2752], loss: 0.1891, acc: 0.9375\n",
      "Epoch [2753], loss: 0.1526, acc: 0.9688\n",
      "Epoch [2754], loss: 0.3099, acc: 0.9062\n",
      "Epoch [2755], loss: 0.1888, acc: 0.9531\n",
      "Epoch [2756], loss: 0.1889, acc: 0.9531\n",
      "Epoch [2757], loss: 0.1564, acc: 0.9688\n",
      "Epoch [2758], loss: 0.4547, acc: 0.9062\n",
      "Epoch [2759], loss: 0.2318, acc: 0.9688\n",
      "Epoch [2760], loss: 0.2789, acc: 0.8906\n",
      "Epoch [2761], loss: 0.3166, acc: 0.9219\n",
      "Epoch [2762], loss: 0.2254, acc: 0.9531\n",
      "Epoch [2763], loss: 0.1343, acc: 0.9844\n",
      "Epoch [2764], loss: 0.2003, acc: 0.9688\n",
      "Epoch [2765], loss: 0.2311, acc: 0.9375\n",
      "Epoch [2766], loss: 0.2279, acc: 0.9375\n",
      "Epoch [2767], loss: 0.1866, acc: 0.9531\n",
      "Epoch [2768], loss: 0.1891, acc: 0.9688\n",
      "Epoch [2769], loss: 0.1106, acc: 1.0000\n",
      "Epoch [2770], loss: 0.2362, acc: 0.9375\n",
      "Epoch [2771], loss: 0.1919, acc: 0.9531\n",
      "Epoch [2772], loss: 0.3121, acc: 0.9219\n",
      "Epoch [2773], loss: 0.2124, acc: 0.9531\n",
      "Epoch [2774], loss: 0.2305, acc: 0.9375\n",
      "Epoch [2775], loss: 0.1886, acc: 0.9844\n",
      "Epoch [2776], loss: 0.2617, acc: 0.9219\n",
      "Epoch [2777], loss: 0.1331, acc: 0.9688\n",
      "Epoch [2778], loss: 0.4131, acc: 0.8750\n",
      "Epoch [2779], loss: 0.3051, acc: 0.9531\n",
      "Epoch [2780], loss: 0.2018, acc: 0.9531\n",
      "Epoch [2781], loss: 0.1448, acc: 0.9844\n",
      "Epoch [2782], loss: 0.2149, acc: 0.9375\n",
      "Epoch [2783], loss: 0.1182, acc: 0.9844\n",
      "Epoch [2784], loss: 0.1500, acc: 0.9688\n",
      "Epoch [2785], loss: 0.2574, acc: 0.9531\n",
      "Epoch [2786], loss: 0.1497, acc: 0.9688\n",
      "Epoch [2787], loss: 0.3617, acc: 0.8594\n",
      "Epoch [2788], loss: 0.2540, acc: 0.9531\n",
      "Epoch [2789], loss: 0.1788, acc: 0.9375\n",
      "Epoch [2790], loss: 0.2431, acc: 0.9688\n",
      "Epoch [2791], loss: 0.2455, acc: 0.9531\n",
      "Epoch [2792], loss: 0.2089, acc: 0.9531\n",
      "Epoch [2793], loss: 0.1955, acc: 0.9375\n",
      "Epoch [2794], loss: 0.1577, acc: 0.9531\n",
      "Epoch [2795], loss: 0.2622, acc: 0.9062\n",
      "Epoch [2796], loss: 0.2698, acc: 0.9531\n",
      "Epoch [2797], loss: 0.2299, acc: 0.9219\n",
      "Epoch [2798], loss: 0.2851, acc: 0.9219\n",
      "Epoch [2799], loss: 0.1497, acc: 0.9531\n",
      "Epoch [2800], loss: 0.1286, acc: 0.9844\n",
      "Epoch [2801], loss: 0.2219, acc: 0.9219\n",
      "Epoch [2802], loss: 0.2515, acc: 0.9531\n",
      "Epoch [2803], loss: 0.2077, acc: 0.9375\n",
      "Epoch [2804], loss: 0.1781, acc: 0.9531\n",
      "Epoch [2805], loss: 0.2082, acc: 0.9531\n",
      "Epoch [2806], loss: 0.2320, acc: 0.8906\n",
      "Epoch [2807], loss: 0.1987, acc: 0.9531\n",
      "Epoch [2808], loss: 0.1511, acc: 0.9375\n",
      "Epoch [2809], loss: 0.2306, acc: 0.9219\n",
      "Epoch [2810], loss: 0.2514, acc: 0.9375\n",
      "Epoch [2811], loss: 0.1255, acc: 0.9688\n",
      "Epoch [2812], loss: 0.2249, acc: 0.9375\n",
      "Epoch [2813], loss: 0.2024, acc: 0.9531\n",
      "Epoch [2814], loss: 0.2350, acc: 0.9375\n",
      "Epoch [2815], loss: 0.2336, acc: 0.9219\n",
      "Epoch [2816], loss: 0.2969, acc: 0.9062\n",
      "Epoch [2817], loss: 0.3996, acc: 0.8906\n",
      "Epoch [2818], loss: 0.1995, acc: 0.9688\n",
      "Epoch [2819], loss: 0.2541, acc: 0.9375\n",
      "Epoch [2820], loss: 0.4199, acc: 0.8906\n",
      "Epoch [2821], loss: 0.2657, acc: 0.9062\n",
      "Epoch [2822], loss: 0.1721, acc: 0.9688\n",
      "Epoch [2823], loss: 0.1750, acc: 0.9531\n",
      "Epoch [2824], loss: 0.1685, acc: 0.9375\n",
      "Epoch [2825], loss: 0.2689, acc: 0.8906\n",
      "Epoch [2826], loss: 0.1277, acc: 0.9844\n",
      "Epoch [2827], loss: 0.2894, acc: 0.8750\n",
      "Epoch [2828], loss: 0.1939, acc: 0.9531\n",
      "Epoch [2829], loss: 0.3259, acc: 0.9062\n",
      "Epoch [2830], loss: 0.2695, acc: 0.9062\n",
      "Epoch [2831], loss: 0.2272, acc: 0.9531\n",
      "Epoch [2832], loss: 0.3444, acc: 0.9062\n",
      "Epoch [2833], loss: 0.2923, acc: 0.9531\n",
      "Epoch [2834], loss: 0.1906, acc: 0.9531\n",
      "Epoch [2835], loss: 0.2202, acc: 0.9219\n",
      "Epoch [2836], loss: 0.2833, acc: 0.9375\n",
      "Epoch [2837], loss: 0.2194, acc: 0.9531\n",
      "Epoch [2838], loss: 0.2789, acc: 0.9062\n",
      "Epoch [2839], loss: 0.3263, acc: 0.8750\n",
      "Epoch [2840], loss: 0.2155, acc: 0.9375\n",
      "Epoch [2841], loss: 0.2459, acc: 0.9375\n",
      "Epoch [2842], loss: 0.2602, acc: 0.9219\n",
      "\n",
      "Checkpoints/3a500model.ckpt Model Saved...\n",
      "Epoch [2843], loss: 0.2839, acc: 0.9062\n",
      "Epoch [2844], loss: 0.1914, acc: 0.9375\n",
      "Epoch [2845], loss: 0.1975, acc: 0.9375\n",
      "Epoch [2846], loss: 0.2873, acc: 0.9219\n",
      "Epoch [2847], loss: 0.2100, acc: 0.9531\n",
      "Epoch [2848], loss: 0.3714, acc: 0.8750\n",
      "Epoch [2849], loss: 0.1146, acc: 0.9844\n",
      "Epoch [2850], loss: 0.2000, acc: 0.9375\n",
      "Epoch [2851], loss: 0.2137, acc: 0.9219\n",
      "Epoch [2852], loss: 0.2563, acc: 0.9062\n",
      "Epoch [2853], loss: 0.2199, acc: 0.9062\n",
      "Epoch [2854], loss: 0.1747, acc: 1.0000\n",
      "Epoch [2855], loss: 0.1967, acc: 0.9531\n",
      "Epoch [2856], loss: 0.3019, acc: 0.9062\n",
      "Epoch [2857], loss: 0.1198, acc: 0.9688\n",
      "Epoch [2858], loss: 0.1431, acc: 0.9688\n",
      "Epoch [2859], loss: 0.3626, acc: 0.9219\n",
      "Epoch [2860], loss: 0.2380, acc: 0.9219\n",
      "Epoch [2861], loss: 0.2887, acc: 0.8750\n",
      "Epoch [2862], loss: 0.1976, acc: 0.9375\n",
      "Epoch [2863], loss: 0.2053, acc: 0.9375\n",
      "Epoch [2864], loss: 0.1299, acc: 0.9844\n",
      "Epoch [2865], loss: 0.2135, acc: 0.9531\n",
      "Epoch [2866], loss: 0.1717, acc: 0.9688\n",
      "Epoch [2867], loss: 0.2518, acc: 0.9531\n",
      "Epoch [2868], loss: 0.2724, acc: 0.9375\n",
      "Epoch [2869], loss: 0.1911, acc: 0.9375\n",
      "Epoch [2870], loss: 0.1787, acc: 0.9844\n",
      "Epoch [2871], loss: 0.1811, acc: 0.9688\n",
      "Epoch [2872], loss: 0.2088, acc: 0.9375\n",
      "Epoch [2873], loss: 0.2023, acc: 0.9531\n",
      "Epoch [2874], loss: 0.3087, acc: 0.9219\n",
      "Epoch [2875], loss: 0.2009, acc: 0.9062\n",
      "Epoch [2876], loss: 0.2128, acc: 0.9375\n",
      "Epoch [2877], loss: 0.1850, acc: 0.9531\n",
      "Epoch [2878], loss: 0.2479, acc: 0.9375\n",
      "Epoch [2879], loss: 0.2938, acc: 0.8906\n",
      "Epoch [2880], loss: 0.1986, acc: 0.9531\n",
      "Epoch [2881], loss: 0.1884, acc: 0.9844\n",
      "Epoch [2882], loss: 0.2079, acc: 0.9688\n",
      "Epoch [2883], loss: 0.1765, acc: 0.9688\n",
      "Epoch [2884], loss: 0.0872, acc: 1.0000\n",
      "Epoch [2885], loss: 0.1417, acc: 0.9844\n",
      "Epoch [2886], loss: 0.2006, acc: 0.9375\n",
      "Epoch [2887], loss: 0.2831, acc: 0.9062\n",
      "Epoch [2888], loss: 0.2202, acc: 0.9375\n",
      "Epoch [2889], loss: 0.2414, acc: 0.9531\n",
      "Epoch [2890], loss: 0.2437, acc: 0.9531\n",
      "Epoch [2891], loss: 0.2919, acc: 0.9062\n",
      "Epoch [2892], loss: 0.1703, acc: 0.9531\n",
      "Epoch [2893], loss: 0.2185, acc: 0.9375\n",
      "Epoch [2894], loss: 0.2650, acc: 0.8906\n",
      "Epoch [2895], loss: 0.1945, acc: 0.9688\n",
      "Epoch [2896], loss: 0.2698, acc: 0.9531\n",
      "Epoch [2897], loss: 0.2091, acc: 0.9219\n",
      "Epoch [2898], loss: 0.2729, acc: 0.9219\n",
      "Epoch [2899], loss: 0.1420, acc: 0.9688\n",
      "Epoch [2900], loss: 0.3166, acc: 0.9375\n",
      "Epoch [2901], loss: 0.1496, acc: 0.9844\n",
      "Epoch [2902], loss: 0.2099, acc: 0.9375\n",
      "Epoch [2903], loss: 0.2760, acc: 0.9062\n",
      "Epoch [2904], loss: 0.1705, acc: 0.9375\n",
      "Epoch [2905], loss: 0.2217, acc: 0.9531\n",
      "Epoch [2906], loss: 0.1699, acc: 0.9375\n",
      "Epoch [2907], loss: 0.2284, acc: 0.9375\n",
      "Epoch [2908], loss: 0.2214, acc: 0.9062\n",
      "Epoch [2909], loss: 0.2436, acc: 0.9531\n",
      "Epoch [2910], loss: 0.2214, acc: 0.9375\n",
      "Epoch [2911], loss: 0.1752, acc: 0.9531\n",
      "Epoch [2912], loss: 0.3108, acc: 0.9375\n",
      "Epoch [2913], loss: 0.1571, acc: 0.9375\n",
      "Epoch [2914], loss: 0.1677, acc: 0.9688\n",
      "Epoch [2915], loss: 0.1534, acc: 0.9688\n",
      "Epoch [2916], loss: 0.0964, acc: 1.0000\n",
      "Epoch [2917], loss: 0.2306, acc: 0.9375\n",
      "Epoch [2918], loss: 0.1580, acc: 0.9688\n",
      "Epoch [2919], loss: 0.2215, acc: 0.9219\n",
      "Epoch [2920], loss: 0.2553, acc: 0.9531\n",
      "Epoch [2921], loss: 0.2752, acc: 0.9219\n",
      "Epoch [2922], loss: 0.1630, acc: 0.9688\n",
      "Epoch [2923], loss: 0.2163, acc: 0.9531\n",
      "Epoch [2924], loss: 0.1808, acc: 0.9531\n",
      "Epoch [2925], loss: 0.1939, acc: 0.9688\n",
      "Epoch [2926], loss: 0.1642, acc: 0.9531\n",
      "Epoch [2927], loss: 0.2547, acc: 0.9531\n",
      "Epoch [2928], loss: 0.3164, acc: 0.9062\n",
      "Epoch [2929], loss: 0.1179, acc: 0.9844\n",
      "Epoch [2930], loss: 0.1702, acc: 0.9531\n",
      "Epoch [2931], loss: 0.2640, acc: 0.9062\n",
      "Epoch [2932], loss: 0.1322, acc: 0.9688\n",
      "Epoch [2933], loss: 0.1665, acc: 0.9844\n",
      "Epoch [2934], loss: 0.2234, acc: 0.9531\n",
      "Epoch [2935], loss: 0.2405, acc: 0.9219\n",
      "Epoch [2936], loss: 0.2064, acc: 0.9688\n",
      "Epoch [2937], loss: 0.2149, acc: 0.9219\n",
      "Epoch [2938], loss: 0.1273, acc: 0.9688\n",
      "Epoch [2939], loss: 0.2649, acc: 0.9219\n",
      "Epoch [2940], loss: 0.1653, acc: 0.9531\n",
      "Epoch [2941], loss: 0.1249, acc: 0.9844\n",
      "Epoch [2942], loss: 0.1648, acc: 0.9531\n",
      "\n",
      "Checkpoints/3a600model.ckpt Model Saved...\n",
      "Epoch [2943], loss: 0.2139, acc: 0.9375\n",
      "Epoch [2944], loss: 0.2111, acc: 0.9688\n",
      "Epoch [2945], loss: 0.2940, acc: 0.9531\n",
      "Epoch [2946], loss: 0.2125, acc: 0.9531\n",
      "Epoch [2947], loss: 0.2537, acc: 0.9062\n",
      "Epoch [2948], loss: 0.3176, acc: 0.9062\n",
      "Epoch [2949], loss: 0.1389, acc: 0.9531\n",
      "Epoch [2950], loss: 0.1698, acc: 0.9688\n",
      "Epoch [2951], loss: 0.2756, acc: 0.9219\n",
      "Epoch [2952], loss: 0.1093, acc: 1.0000\n",
      "Epoch [2953], loss: 0.1555, acc: 0.9844\n",
      "Epoch [2954], loss: 0.0703, acc: 1.0000\n",
      "Epoch [2955], loss: 0.1362, acc: 1.0000\n",
      "Epoch [2956], loss: 0.1868, acc: 0.9531\n",
      "Epoch [2957], loss: 0.3434, acc: 0.8906\n",
      "Epoch [2958], loss: 0.1063, acc: 0.9844\n",
      "Epoch [2959], loss: 0.2458, acc: 0.9062\n",
      "Epoch [2960], loss: 0.2251, acc: 0.9375\n",
      "Epoch [2961], loss: 0.1759, acc: 0.9531\n",
      "Epoch [2962], loss: 0.1246, acc: 0.9688\n",
      "Epoch [2963], loss: 0.1418, acc: 0.9688\n",
      "Epoch [2964], loss: 0.1695, acc: 0.9844\n",
      "Epoch [2965], loss: 0.1912, acc: 0.9375\n",
      "Epoch [2966], loss: 0.1869, acc: 0.9219\n",
      "Epoch [2967], loss: 0.1945, acc: 0.9531\n",
      "Epoch [2968], loss: 0.1720, acc: 0.9375\n",
      "Epoch [2969], loss: 0.1141, acc: 1.0000\n",
      "Epoch [2970], loss: 0.2185, acc: 0.9219\n",
      "Epoch [2971], loss: 0.1570, acc: 0.9844\n",
      "Epoch [2972], loss: 0.1722, acc: 0.9531\n",
      "Epoch [2973], loss: 0.3650, acc: 0.8906\n",
      "Epoch [2974], loss: 0.1764, acc: 0.9688\n",
      "Epoch [2975], loss: 0.1958, acc: 0.9531\n",
      "Epoch [2976], loss: 0.1643, acc: 0.9688\n",
      "Epoch [2977], loss: 0.2291, acc: 0.9375\n",
      "Epoch [2978], loss: 0.2718, acc: 0.9219\n",
      "Epoch [2979], loss: 0.2093, acc: 0.9688\n",
      "Epoch [2980], loss: 0.2112, acc: 0.9531\n",
      "Epoch [2981], loss: 0.2054, acc: 0.9531\n",
      "Epoch [2982], loss: 0.1850, acc: 0.9062\n",
      "Epoch [2983], loss: 0.0991, acc: 0.9844\n",
      "Epoch [2984], loss: 0.1172, acc: 1.0000\n",
      "Epoch [2985], loss: 0.2034, acc: 0.9531\n",
      "Epoch [2986], loss: 0.1448, acc: 0.9844\n",
      "Epoch [2987], loss: 0.2199, acc: 0.9375\n",
      "Epoch [2988], loss: 0.1846, acc: 0.9688\n",
      "Epoch [2989], loss: 0.1211, acc: 1.0000\n",
      "Epoch [2990], loss: 0.1193, acc: 1.0000\n",
      "Epoch [2991], loss: 0.2291, acc: 0.8906\n",
      "Epoch [2992], loss: 0.1461, acc: 0.9688\n",
      "Epoch [2993], loss: 0.1209, acc: 1.0000\n",
      "Epoch [2994], loss: 0.1622, acc: 0.9531\n",
      "Epoch [2995], loss: 0.1819, acc: 0.9219\n",
      "Epoch [2996], loss: 0.1847, acc: 0.9531\n",
      "Epoch [2997], loss: 0.2289, acc: 0.9219\n",
      "Epoch [2998], loss: 0.2263, acc: 0.9375\n",
      "Epoch [2999], loss: 0.2424, acc: 0.8906\n",
      "Epoch [3000], loss: 0.2630, acc: 0.9062\n",
      "Epoch [3001], loss: 0.2513, acc: 0.9531\n",
      "Epoch [3002], loss: 0.1889, acc: 0.9531\n",
      "Epoch [3003], loss: 0.1618, acc: 0.9844\n",
      "Epoch [3004], loss: 0.2835, acc: 0.9062\n",
      "Epoch [3005], loss: 0.3099, acc: 0.9062\n",
      "Epoch [3006], loss: 0.1275, acc: 0.9531\n",
      "Epoch [3007], loss: 0.1647, acc: 0.9531\n",
      "Epoch [3008], loss: 0.1816, acc: 0.9688\n",
      "Epoch [3009], loss: 0.2331, acc: 0.9062\n",
      "Epoch [3010], loss: 0.1361, acc: 0.9688\n",
      "Epoch [3011], loss: 0.2133, acc: 0.9688\n",
      "Epoch [3012], loss: 0.2124, acc: 0.9375\n",
      "Epoch [3013], loss: 0.2119, acc: 0.9375\n",
      "Epoch [3014], loss: 0.2976, acc: 0.9219\n",
      "Epoch [3015], loss: 0.2917, acc: 0.8906\n",
      "Epoch [3016], loss: 0.2077, acc: 0.9688\n",
      "Epoch [3017], loss: 0.2428, acc: 0.9375\n",
      "Epoch [3018], loss: 0.1936, acc: 0.9688\n",
      "Epoch [3019], loss: 0.2133, acc: 0.9531\n",
      "Epoch [3020], loss: 0.2734, acc: 0.9219\n",
      "Epoch [3021], loss: 0.2537, acc: 0.9375\n",
      "Epoch [3022], loss: 0.2866, acc: 0.9219\n",
      "Epoch [3023], loss: 0.1416, acc: 0.9688\n",
      "Epoch [3024], loss: 0.2260, acc: 0.9219\n",
      "Epoch [3025], loss: 0.1772, acc: 0.9531\n",
      "Epoch [3026], loss: 0.2029, acc: 0.9219\n",
      "Epoch [3027], loss: 0.1609, acc: 0.9844\n",
      "Epoch [3028], loss: 0.1645, acc: 0.9531\n",
      "Epoch [3029], loss: 0.2529, acc: 0.9531\n",
      "Epoch [3030], loss: 0.2315, acc: 0.9688\n",
      "Epoch [3031], loss: 0.1670, acc: 0.9531\n",
      "Epoch [3032], loss: 0.1074, acc: 0.9844\n",
      "Epoch [3033], loss: 0.2345, acc: 0.9375\n",
      "Epoch [3034], loss: 0.3075, acc: 0.8906\n",
      "Epoch [3035], loss: 0.2733, acc: 0.9375\n",
      "Epoch [3036], loss: 0.1584, acc: 0.9688\n",
      "Epoch [3037], loss: 0.2438, acc: 0.9219\n",
      "Epoch [3038], loss: 0.1452, acc: 0.9688\n",
      "Epoch [3039], loss: 0.2381, acc: 0.9531\n",
      "Epoch [3040], loss: 0.1323, acc: 0.9844\n",
      "Epoch [3041], loss: 0.1811, acc: 0.9688\n",
      "Epoch [3042], loss: 0.1215, acc: 1.0000\n",
      "\n",
      "Checkpoints/3a700model.ckpt Model Saved...\n",
      "Epoch [3043], loss: 0.2648, acc: 0.9062\n",
      "Epoch [3044], loss: 0.1680, acc: 0.9844\n",
      "Epoch [3045], loss: 0.1868, acc: 0.9844\n",
      "Epoch [3046], loss: 0.1336, acc: 0.9531\n",
      "Epoch [3047], loss: 0.1511, acc: 0.9688\n",
      "Epoch [3048], loss: 0.1567, acc: 0.9688\n",
      "Epoch [3049], loss: 0.1993, acc: 0.9531\n",
      "Epoch [3050], loss: 0.1557, acc: 0.9844\n",
      "Epoch [3051], loss: 0.1287, acc: 0.9688\n",
      "Epoch [3052], loss: 0.1545, acc: 0.9688\n",
      "Epoch [3053], loss: 0.1411, acc: 0.9688\n",
      "Epoch [3054], loss: 0.0918, acc: 0.9844\n",
      "Epoch [3055], loss: 0.2176, acc: 0.9219\n",
      "Epoch [3056], loss: 0.1753, acc: 0.9531\n",
      "Epoch [3057], loss: 0.2004, acc: 0.9375\n",
      "Epoch [3058], loss: 0.1340, acc: 0.9531\n",
      "Epoch [3059], loss: 0.1607, acc: 0.9844\n",
      "Epoch [3060], loss: 0.0850, acc: 1.0000\n",
      "Epoch [3061], loss: 0.2249, acc: 0.9375\n",
      "Epoch [3062], loss: 0.2779, acc: 0.8906\n",
      "Epoch [3063], loss: 0.2207, acc: 0.9219\n",
      "Epoch [3064], loss: 0.1821, acc: 1.0000\n",
      "Epoch [3065], loss: 0.2417, acc: 0.9375\n",
      "Epoch [3066], loss: 0.2188, acc: 0.9375\n",
      "Epoch [3067], loss: 0.2001, acc: 0.9531\n",
      "Epoch [3068], loss: 0.2031, acc: 0.9531\n",
      "Epoch [3069], loss: 0.1897, acc: 0.9219\n",
      "Epoch [3070], loss: 0.2881, acc: 0.9531\n",
      "Epoch [3071], loss: 0.1187, acc: 0.9844\n",
      "Epoch [3072], loss: 0.1854, acc: 0.9375\n",
      "Epoch [3073], loss: 0.1814, acc: 0.9688\n",
      "Epoch [3074], loss: 0.4167, acc: 0.8750\n",
      "Epoch [3075], loss: 0.1297, acc: 0.9688\n",
      "Epoch [3076], loss: 0.0909, acc: 0.9844\n",
      "Epoch [3077], loss: 0.1369, acc: 0.9844\n",
      "Epoch [3078], loss: 0.3021, acc: 0.9219\n",
      "Epoch [3079], loss: 0.3176, acc: 0.9219\n",
      "Epoch [3080], loss: 0.3244, acc: 0.9375\n",
      "Epoch [3081], loss: 0.2288, acc: 0.9219\n",
      "Epoch [3082], loss: 0.2037, acc: 0.9219\n",
      "Epoch [3083], loss: 0.3144, acc: 0.9062\n",
      "Epoch [3084], loss: 0.3222, acc: 0.9531\n",
      "Epoch [3085], loss: 0.1688, acc: 0.9531\n",
      "Epoch [3086], loss: 0.1210, acc: 0.9844\n",
      "Epoch [3087], loss: 0.3204, acc: 0.9062\n",
      "Epoch [3088], loss: 0.1762, acc: 0.9375\n",
      "Epoch [3089], loss: 0.1766, acc: 0.9375\n",
      "Epoch [3090], loss: 0.2529, acc: 0.9062\n",
      "Epoch [3091], loss: 0.1827, acc: 0.9531\n",
      "Epoch [3092], loss: 0.0936, acc: 0.9844\n",
      "Epoch [3093], loss: 0.1359, acc: 0.9688\n",
      "Epoch [3094], loss: 0.1436, acc: 0.9844\n",
      "Epoch [3095], loss: 0.1255, acc: 1.0000\n",
      "Epoch [3096], loss: 0.1279, acc: 0.9844\n",
      "Epoch [3097], loss: 0.1607, acc: 0.9531\n",
      "Epoch [3098], loss: 0.1576, acc: 0.9844\n",
      "Epoch [3099], loss: 0.1888, acc: 0.9531\n",
      "Epoch [3100], loss: 0.1664, acc: 0.9688\n",
      "Epoch [3101], loss: 0.1588, acc: 0.9688\n",
      "Epoch [3102], loss: 0.1953, acc: 0.9375\n",
      "Epoch [3103], loss: 0.1849, acc: 0.9375\n",
      "Epoch [3104], loss: 0.1547, acc: 0.9531\n",
      "Epoch [3105], loss: 0.1377, acc: 0.9688\n",
      "Epoch [3106], loss: 0.2757, acc: 0.9219\n",
      "Epoch [3107], loss: 0.2885, acc: 0.9062\n",
      "Epoch [3108], loss: 0.3564, acc: 0.9219\n",
      "Epoch [3109], loss: 0.2116, acc: 0.9531\n",
      "Epoch [3110], loss: 0.1445, acc: 0.9844\n",
      "Epoch [3111], loss: 0.1374, acc: 0.9688\n",
      "Epoch [3112], loss: 0.2352, acc: 0.9375\n",
      "Epoch [3113], loss: 0.1408, acc: 0.9688\n",
      "Epoch [3114], loss: 0.1033, acc: 0.9844\n",
      "Epoch [3115], loss: 0.2650, acc: 0.8906\n",
      "Epoch [3116], loss: 0.1978, acc: 0.9688\n",
      "Epoch [3117], loss: 0.2024, acc: 0.9688\n",
      "Epoch [3118], loss: 0.1543, acc: 0.9531\n",
      "Epoch [3119], loss: 0.1391, acc: 0.9688\n",
      "Epoch [3120], loss: 0.1363, acc: 0.9844\n",
      "Epoch [3121], loss: 0.1424, acc: 0.9844\n",
      "Epoch [3122], loss: 0.1914, acc: 0.9688\n",
      "Epoch [3123], loss: 0.1068, acc: 1.0000\n",
      "\n",
      "Checkpoints/3model.ckpt Model Saved...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed74ca415f3b49a39b13c3ba6a30cd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checkpoints/4a0model.ckpt Model Saved...\n",
      "Epoch [3124], loss: 0.1023, acc: 0.9844\n",
      "Epoch [3125], loss: 0.2857, acc: 0.9375\n",
      "Epoch [3126], loss: 0.2409, acc: 0.9375\n",
      "Epoch [3127], loss: 0.1065, acc: 0.9688\n",
      "Epoch [3128], loss: 0.1900, acc: 0.9531\n",
      "Epoch [3129], loss: 0.2053, acc: 0.9375\n",
      "Epoch [3130], loss: 0.1854, acc: 0.9375\n",
      "Epoch [3131], loss: 0.2235, acc: 0.9219\n",
      "Epoch [3132], loss: 0.1471, acc: 0.9688\n",
      "Epoch [3133], loss: 0.1192, acc: 0.9844\n",
      "Epoch [3134], loss: 0.1834, acc: 0.9688\n",
      "Epoch [3135], loss: 0.1964, acc: 0.9531\n",
      "Epoch [3136], loss: 0.1320, acc: 0.9844\n",
      "Epoch [3137], loss: 0.1794, acc: 0.9688\n",
      "Epoch [3138], loss: 0.2265, acc: 0.9531\n",
      "Epoch [3139], loss: 0.2681, acc: 0.9375\n",
      "Epoch [3140], loss: 0.1704, acc: 0.9844\n",
      "Epoch [3141], loss: 0.1667, acc: 0.9688\n",
      "Epoch [3142], loss: 0.1636, acc: 0.9688\n",
      "Epoch [3143], loss: 0.1088, acc: 0.9844\n",
      "Epoch [3144], loss: 0.1511, acc: 0.9531\n",
      "Epoch [3145], loss: 0.0866, acc: 1.0000\n",
      "Epoch [3146], loss: 0.2432, acc: 0.9219\n",
      "Epoch [3147], loss: 0.2425, acc: 0.9531\n",
      "Epoch [3148], loss: 0.2463, acc: 0.9375\n",
      "Epoch [3149], loss: 0.1320, acc: 0.9688\n",
      "Epoch [3150], loss: 0.2324, acc: 0.9375\n",
      "Epoch [3151], loss: 0.1673, acc: 0.9688\n",
      "Epoch [3152], loss: 0.2248, acc: 0.9688\n",
      "Epoch [3153], loss: 0.1550, acc: 0.9688\n",
      "Epoch [3154], loss: 0.1576, acc: 0.9531\n",
      "Epoch [3155], loss: 0.2743, acc: 0.9531\n",
      "Epoch [3156], loss: 0.1289, acc: 0.9844\n",
      "Epoch [3157], loss: 0.2232, acc: 0.9688\n",
      "Epoch [3158], loss: 0.2159, acc: 0.9531\n",
      "Epoch [3159], loss: 0.1141, acc: 0.9844\n",
      "Epoch [3160], loss: 0.1619, acc: 0.9688\n",
      "Epoch [3161], loss: 0.2342, acc: 0.9531\n",
      "Epoch [3162], loss: 0.1265, acc: 1.0000\n",
      "Epoch [3163], loss: 0.2236, acc: 0.9531\n",
      "Epoch [3164], loss: 0.1500, acc: 0.9531\n",
      "Epoch [3165], loss: 0.1936, acc: 0.9688\n",
      "Epoch [3166], loss: 0.1420, acc: 0.9688\n",
      "Epoch [3167], loss: 0.1706, acc: 0.9844\n",
      "Epoch [3168], loss: 0.2766, acc: 0.9219\n",
      "Epoch [3169], loss: 0.1733, acc: 0.9531\n",
      "Epoch [3170], loss: 0.1734, acc: 0.9688\n",
      "Epoch [3171], loss: 0.1452, acc: 0.9844\n",
      "Epoch [3172], loss: 0.0685, acc: 1.0000\n",
      "Epoch [3173], loss: 0.1900, acc: 0.9688\n",
      "Epoch [3174], loss: 0.1710, acc: 0.9531\n",
      "Epoch [3175], loss: 0.1870, acc: 0.9688\n",
      "Epoch [3176], loss: 0.1461, acc: 0.9531\n",
      "Epoch [3177], loss: 0.2296, acc: 0.9688\n",
      "Epoch [3178], loss: 0.1759, acc: 0.9531\n",
      "Epoch [3179], loss: 0.1225, acc: 0.9844\n",
      "Epoch [3180], loss: 0.3939, acc: 0.8906\n",
      "Epoch [3181], loss: 0.1528, acc: 0.9531\n",
      "Epoch [3182], loss: 0.1901, acc: 0.9531\n",
      "Epoch [3183], loss: 0.2615, acc: 0.9219\n",
      "Epoch [3184], loss: 0.1065, acc: 0.9844\n",
      "Epoch [3185], loss: 0.2867, acc: 0.9219\n",
      "Epoch [3186], loss: 0.1939, acc: 0.9375\n",
      "Epoch [3187], loss: 0.1743, acc: 0.9531\n",
      "Epoch [3188], loss: 0.1111, acc: 1.0000\n",
      "Epoch [3189], loss: 0.4145, acc: 0.8594\n",
      "Epoch [3190], loss: 0.1867, acc: 0.9531\n",
      "Epoch [3191], loss: 0.1883, acc: 0.9375\n",
      "Epoch [3192], loss: 0.2899, acc: 0.9219\n",
      "Epoch [3193], loss: 0.1876, acc: 0.9531\n",
      "Epoch [3194], loss: 0.2164, acc: 0.9375\n",
      "Epoch [3195], loss: 0.1480, acc: 0.9844\n",
      "Epoch [3196], loss: 0.1910, acc: 0.9375\n",
      "Epoch [3197], loss: 0.1712, acc: 0.9531\n",
      "Epoch [3198], loss: 0.2232, acc: 0.9375\n",
      "Epoch [3199], loss: 0.1793, acc: 0.9688\n",
      "Epoch [3200], loss: 0.0996, acc: 1.0000\n",
      "Epoch [3201], loss: 0.3169, acc: 0.8906\n",
      "Epoch [3202], loss: 0.1356, acc: 0.9688\n",
      "Epoch [3203], loss: 0.2378, acc: 0.9375\n",
      "Epoch [3204], loss: 0.0984, acc: 0.9844\n",
      "Epoch [3205], loss: 0.1840, acc: 0.9375\n",
      "Epoch [3206], loss: 0.1590, acc: 0.9688\n",
      "Epoch [3207], loss: 0.1266, acc: 0.9844\n",
      "Epoch [3208], loss: 0.2267, acc: 0.9375\n",
      "Epoch [3209], loss: 0.1683, acc: 0.9531\n",
      "Epoch [3210], loss: 0.1585, acc: 0.9375\n",
      "Epoch [3211], loss: 0.2579, acc: 0.9375\n",
      "Epoch [3212], loss: 0.1661, acc: 0.9688\n",
      "Epoch [3213], loss: 0.1141, acc: 0.9688\n",
      "Epoch [3214], loss: 0.0709, acc: 1.0000\n",
      "Epoch [3215], loss: 0.2967, acc: 0.9375\n",
      "Epoch [3216], loss: 0.1601, acc: 0.9375\n",
      "Epoch [3217], loss: 0.1762, acc: 0.9531\n",
      "Epoch [3218], loss: 0.1377, acc: 0.9688\n",
      "Epoch [3219], loss: 0.1503, acc: 0.9844\n",
      "Epoch [3220], loss: 0.1710, acc: 0.9531\n",
      "Epoch [3221], loss: 0.2331, acc: 0.9375\n",
      "Epoch [3222], loss: 0.1542, acc: 0.9531\n",
      "Epoch [3223], loss: 0.1623, acc: 1.0000\n",
      "\n",
      "Checkpoints/4a100model.ckpt Model Saved...\n",
      "Epoch [3224], loss: 0.1909, acc: 0.9531\n",
      "Epoch [3225], loss: 0.2232, acc: 0.9375\n",
      "Epoch [3226], loss: 0.1149, acc: 1.0000\n",
      "Epoch [3227], loss: 0.1758, acc: 0.9531\n",
      "Epoch [3228], loss: 0.1994, acc: 0.9688\n",
      "Epoch [3229], loss: 0.2401, acc: 0.9375\n",
      "Epoch [3230], loss: 0.2411, acc: 0.9062\n",
      "Epoch [3231], loss: 0.2723, acc: 0.9219\n",
      "Epoch [3232], loss: 0.3047, acc: 0.9219\n",
      "Epoch [3233], loss: 0.2040, acc: 0.9531\n",
      "Epoch [3234], loss: 0.1266, acc: 0.9688\n",
      "Epoch [3235], loss: 0.1809, acc: 0.9531\n",
      "Epoch [3236], loss: 0.2132, acc: 0.9688\n",
      "Epoch [3237], loss: 0.1692, acc: 0.9688\n",
      "Epoch [3238], loss: 0.1552, acc: 0.9688\n",
      "Epoch [3239], loss: 0.3851, acc: 0.9219\n",
      "Epoch [3240], loss: 0.1610, acc: 0.9219\n",
      "Epoch [3241], loss: 0.1461, acc: 0.9844\n",
      "Epoch [3242], loss: 0.1618, acc: 0.9375\n",
      "Epoch [3243], loss: 0.1962, acc: 0.9531\n",
      "Epoch [3244], loss: 0.2089, acc: 0.9688\n",
      "Epoch [3245], loss: 0.2021, acc: 0.9688\n",
      "Epoch [3246], loss: 0.2796, acc: 0.8906\n",
      "Epoch [3247], loss: 0.1946, acc: 0.9688\n",
      "Epoch [3248], loss: 0.1470, acc: 0.9844\n",
      "Epoch [3249], loss: 0.1386, acc: 0.9688\n",
      "Epoch [3250], loss: 0.1672, acc: 0.9375\n",
      "Epoch [3251], loss: 0.2036, acc: 0.9531\n",
      "Epoch [3252], loss: 0.1250, acc: 0.9844\n",
      "Epoch [3253], loss: 0.2128, acc: 0.9531\n",
      "Epoch [3254], loss: 0.2268, acc: 0.9531\n",
      "Epoch [3255], loss: 0.1564, acc: 0.9531\n",
      "Epoch [3256], loss: 0.1722, acc: 0.9219\n",
      "Epoch [3257], loss: 0.1845, acc: 0.9375\n",
      "Epoch [3258], loss: 0.2521, acc: 0.9062\n",
      "Epoch [3259], loss: 0.2316, acc: 0.9219\n",
      "Epoch [3260], loss: 0.1797, acc: 0.9219\n",
      "Epoch [3261], loss: 0.1027, acc: 0.9688\n",
      "Epoch [3262], loss: 0.1345, acc: 0.9844\n",
      "Epoch [3263], loss: 0.2331, acc: 0.9531\n",
      "Epoch [3264], loss: 0.3642, acc: 0.9375\n",
      "Epoch [3265], loss: 0.3859, acc: 0.8906\n",
      "Epoch [3266], loss: 0.1696, acc: 0.9531\n",
      "Epoch [3267], loss: 0.1352, acc: 0.9688\n",
      "Epoch [3268], loss: 0.1851, acc: 0.9844\n",
      "Epoch [3269], loss: 0.1409, acc: 0.9844\n",
      "Epoch [3270], loss: 0.0894, acc: 0.9844\n",
      "Epoch [3271], loss: 0.1637, acc: 0.9531\n",
      "Epoch [3272], loss: 0.1407, acc: 0.9844\n",
      "Epoch [3273], loss: 0.1317, acc: 0.9844\n",
      "Epoch [3274], loss: 0.2598, acc: 0.9375\n",
      "Epoch [3275], loss: 0.1945, acc: 0.9531\n",
      "Epoch [3276], loss: 0.1334, acc: 0.9844\n",
      "Epoch [3277], loss: 0.1755, acc: 0.9688\n",
      "Epoch [3278], loss: 0.1232, acc: 0.9844\n",
      "Epoch [3279], loss: 0.2148, acc: 0.9375\n",
      "Epoch [3280], loss: 0.1176, acc: 0.9844\n",
      "Epoch [3281], loss: 0.1795, acc: 0.9688\n",
      "Epoch [3282], loss: 0.1056, acc: 0.9844\n",
      "Epoch [3283], loss: 0.1086, acc: 0.9844\n",
      "Epoch [3284], loss: 0.1101, acc: 0.9844\n",
      "Epoch [3285], loss: 0.1139, acc: 0.9844\n",
      "Epoch [3286], loss: 0.2772, acc: 0.9062\n",
      "Epoch [3287], loss: 0.1275, acc: 0.9844\n",
      "Epoch [3288], loss: 0.1596, acc: 0.9531\n",
      "Epoch [3289], loss: 0.2471, acc: 0.9219\n",
      "Epoch [3290], loss: 0.1393, acc: 0.9844\n",
      "Epoch [3291], loss: 0.1699, acc: 0.9688\n",
      "Epoch [3292], loss: 0.1613, acc: 0.9531\n",
      "Epoch [3293], loss: 0.1182, acc: 0.9844\n",
      "Epoch [3294], loss: 0.1503, acc: 0.9688\n",
      "Epoch [3295], loss: 0.2419, acc: 0.9219\n",
      "Epoch [3296], loss: 0.2157, acc: 0.9219\n",
      "Epoch [3297], loss: 0.1627, acc: 0.9375\n",
      "Epoch [3298], loss: 0.2664, acc: 0.9375\n",
      "Epoch [3299], loss: 0.1484, acc: 0.9531\n",
      "Epoch [3300], loss: 0.1794, acc: 0.9531\n",
      "Epoch [3301], loss: 0.1529, acc: 0.9688\n",
      "Epoch [3302], loss: 0.1470, acc: 0.9688\n",
      "Epoch [3303], loss: 0.1187, acc: 0.9688\n",
      "Epoch [3304], loss: 0.1569, acc: 0.9844\n",
      "Epoch [3305], loss: 0.1567, acc: 0.9531\n",
      "Epoch [3306], loss: 0.1089, acc: 0.9844\n",
      "Epoch [3307], loss: 0.1983, acc: 0.9375\n",
      "Epoch [3308], loss: 0.1689, acc: 0.9844\n",
      "Epoch [3309], loss: 0.1989, acc: 0.9531\n",
      "Epoch [3310], loss: 0.2150, acc: 0.9219\n",
      "Epoch [3311], loss: 0.1787, acc: 0.9219\n",
      "Epoch [3312], loss: 0.1481, acc: 0.9688\n",
      "Epoch [3313], loss: 0.2176, acc: 0.9219\n",
      "Epoch [3314], loss: 0.0684, acc: 1.0000\n",
      "Epoch [3315], loss: 0.1749, acc: 0.9688\n",
      "Epoch [3316], loss: 0.3595, acc: 0.8906\n",
      "Epoch [3317], loss: 0.1946, acc: 0.9688\n",
      "Epoch [3318], loss: 0.2262, acc: 0.9375\n",
      "Epoch [3319], loss: 0.1514, acc: 0.9844\n",
      "Epoch [3320], loss: 0.1624, acc: 0.9531\n",
      "Epoch [3321], loss: 0.2383, acc: 0.9375\n",
      "Epoch [3322], loss: 0.2164, acc: 0.9531\n",
      "Epoch [3323], loss: 0.1753, acc: 0.9688\n",
      "\n",
      "Checkpoints/4a200model.ckpt Model Saved...\n",
      "Epoch [3324], loss: 0.0812, acc: 0.9844\n",
      "Epoch [3325], loss: 0.1991, acc: 0.9688\n",
      "Epoch [3326], loss: 0.2211, acc: 0.9219\n",
      "Epoch [3327], loss: 0.1333, acc: 0.9844\n",
      "Epoch [3328], loss: 0.1685, acc: 0.9531\n",
      "Epoch [3329], loss: 0.1918, acc: 0.9219\n",
      "Epoch [3330], loss: 0.1396, acc: 0.9688\n",
      "Epoch [3331], loss: 0.1731, acc: 0.9688\n",
      "Epoch [3332], loss: 0.2384, acc: 0.9219\n",
      "Epoch [3333], loss: 0.1904, acc: 0.9531\n",
      "Epoch [3334], loss: 0.2962, acc: 0.9375\n",
      "Epoch [3335], loss: 0.2849, acc: 0.9062\n",
      "Epoch [3336], loss: 0.2306, acc: 0.9062\n",
      "Epoch [3337], loss: 0.1108, acc: 0.9688\n",
      "Epoch [3338], loss: 0.1541, acc: 0.9688\n",
      "Epoch [3339], loss: 0.1670, acc: 0.9688\n",
      "Epoch [3340], loss: 0.1767, acc: 0.9531\n",
      "Epoch [3341], loss: 0.1417, acc: 0.9688\n",
      "Epoch [3342], loss: 0.2284, acc: 0.9688\n",
      "Epoch [3343], loss: 0.1355, acc: 0.9531\n",
      "Epoch [3344], loss: 0.1455, acc: 0.9844\n",
      "Epoch [3345], loss: 0.2113, acc: 0.9219\n",
      "Epoch [3346], loss: 0.1675, acc: 0.9688\n",
      "Epoch [3347], loss: 0.1586, acc: 0.9688\n",
      "Epoch [3348], loss: 0.1494, acc: 0.9688\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim import AdamW\n",
    "from torchvision.datasets import CIFAR10\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import skimage\n",
    "import PIL\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from skimage import data, exposure, img_as_float\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from torchvision.transforms import ToTensor\n",
    "import argparse\n",
    "import shutil\n",
    "import string\n",
    "from termcolor import colored, cprint\n",
    "import math as m\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def SetupAll(CheckPointPath):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    CheckPointPath - Path to save checkpoints/model\n",
    "    Outputs:\n",
    "    SaveCheckPoint - Save checkpoint every SaveCheckPoint iteration in every epoch, checkpoint saved automatically after every epoch\n",
    "    ImageSize - Size of the image\n",
    "    NumTrainSamples - length(Train)\n",
    "    TrainLabels - Labels corresponding to Train\n",
    "    NumClasses - Number of classes\n",
    "    \"\"\"\n",
    "    # Read and Setup Labels\n",
    "    LabelsPathTrain = 'TxtFiles/LabelsTrain.txt'\n",
    "    TrainLabels = ReadLabels(LabelsPathTrain)\n",
    "\n",
    "    # If CheckPointPath doesn't exist make the path\n",
    "    if(not (os.path.isdir(CheckPointPath))):\n",
    "        os.makedirs(CheckPointPath)\n",
    "        \n",
    "    # Save checkpoint every SaveCheckPoint iteration in every epoch, checkpoint saved automatically after every epoch\n",
    "    SaveCheckPoint = 100 \n",
    "    \n",
    "    # Image Input Shape\n",
    "    ImageSize = [32, 32, 3]\n",
    "    NumTrainSamples = len(TrainSet)\n",
    "\n",
    "    # Number of classes\n",
    "    NumClasses = 10\n",
    "\n",
    "    return SaveCheckPoint, ImageSize, NumTrainSamples, TrainLabels, NumClasses\n",
    "\n",
    "\n",
    "def ReadLabels(LabelsPathTrain):\n",
    "    if(not (os.path.isfile(LabelsPathTrain))):\n",
    "        print('ERROR: Train Labels do not exist in '+LabelsPathTrain)\n",
    "        sys.exit()\n",
    "    else:\n",
    "        TrainLabels = open(LabelsPathTrain, 'r')\n",
    "        TrainLabels = TrainLabels.read()\n",
    "        TrainLabels = map(float, TrainLabels.split())\n",
    "\n",
    "    return TrainLabels\n",
    "    \n",
    "\n",
    "def ReadDirNames(ReadPath):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    ReadPath is the path of the file you want to read\n",
    "    Outputs:\n",
    "    DirNames is the data loaded from TxtFiles/DirNames.txt which has full path to all image files without extension\n",
    "    \"\"\"\n",
    "    # Read text files\n",
    "    DirNames = open(ReadPath, 'r')\n",
    "    DirNames = DirNames.read()\n",
    "    DirNames = DirNames.split()\n",
    "    return DirNames\n",
    "\n",
    "    \n",
    "def GenerateBatch(TrainSet, TrainLabels, ImageSize, MiniBatchSize, Indices):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    TrainSet - Variable with Subfolder paths to train files\n",
    "    NOTE that Train can be replaced by Val/Test for generating batch corresponding to validation (held-out testing in this case)/testing\n",
    "    TrainLabels - Labels corresponding to Train\n",
    "    NOTE that TrainLabels can be replaced by Val/TestLabels for generating batch corresponding to validation (held-out testing in this case)/testing\n",
    "    ImageSize is the Size of the Image\n",
    "    MiniBatchSize is the size of the MiniBatch\n",
    "   \n",
    "    Outputs:\n",
    "    I1Batch - Batch of images\n",
    "    LabelBatch - Batch of one-hot encoded labels \n",
    "    \"\"\"\n",
    "    I1Batch = []\n",
    "    LabelBatch = []\n",
    "    \n",
    "    ImageNum = 0\n",
    "    while ImageNum < MiniBatchSize:\n",
    "        # Generate random image\n",
    "        RandIdx = random.randint(0, len(Indices)-1)\n",
    "        \n",
    "        ImageNum += 1\n",
    "\n",
    "        ##########################################################\n",
    "        # Add any standardization or data augmentation here!\n",
    "        ##########################################################\n",
    "\n",
    "        I1, Label = TrainSet[Indices[RandIdx]]\n",
    "\n",
    "        # Append All Images and Mask\n",
    "        I1Batch.append(I1)\n",
    "        LabelBatch.append(torch.tensor(Label))\n",
    "        \n",
    "    return torch.stack(I1Batch), torch.stack(LabelBatch)\n",
    "\n",
    "\n",
    "def PrettyPrint(NumEpochs, DivTrain, MiniBatchSize, NumTrainSamples, LatestFile):\n",
    "    \"\"\"\n",
    "    Prints all stats with all arguments\n",
    "    \"\"\"\n",
    "    print('Number of Epochs Training will run for ' + str(NumEpochs))\n",
    "    print('Factor of reduction in training data is ' + str(DivTrain))\n",
    "    print('Mini Batch Size ' + str(MiniBatchSize))\n",
    "    print('Number of Training Images ' + str(NumTrainSamples))\n",
    "    if LatestFile is not None:\n",
    "        print('Loading latest checkpoint with the name ' + LatestFile)              \n",
    "\n",
    "def TrainOperation(TrainLabels, NumTrainSamples, ImageSize,\n",
    "                   NumEpochs, MiniBatchSize, SaveCheckPoint, CheckPointPath,\n",
    "                   DivTrain, LatestFile, TrainSet, LogsPath, TrainIndices, ValIndices):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    TrainLabels - Labels corresponding to Train/Test\n",
    "    NumTrainSamples - length(Train)\n",
    "    ImageSize - Size of the image\n",
    "    NumEpochs - Number of passes through the Train data\n",
    "    MiniBatchSize is the size of the MiniBatch\n",
    "    SaveCheckPoint - Save checkpoint every SaveCheckPoint iteration in every epoch, checkpoint saved automatically after every epoch\n",
    "    CheckPointPath - Path to save checkpoints/model\n",
    "    DivTrain - Divide the data by this number for Epoch calculation, use if you have a lot of dataor for debugging code\n",
    "    LatestFile - Latest checkpointfile to continue training\n",
    "    TrainSet - The training dataset\n",
    "    LogsPath - Path to save Tensorboard Logs\n",
    "    Outputs:\n",
    "    Saves Trained network in CheckPointPath and Logs to LogsPath\n",
    "    \"\"\"\n",
    "    # Initialize the model\n",
    "    # model = ResNet([2, 2, 2, 2], [3]) \n",
    "    \n",
    "    # model = ResNet( [2, 2, 2, 2])\n",
    "    model = ResNet9(3, 10)\n",
    "    \n",
    "    ###############################################\n",
    "    # Fill your optimizer of choice here!\n",
    "    ###############################################\n",
    "    Optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.0005)\n",
    "\n",
    "    # Tensorboard\n",
    "    # Create a summary to monitor loss tensor\n",
    "    Writer = SummaryWriter(LogsPath)\n",
    "\n",
    "    if LatestFile is not None:\n",
    "        CheckPoint = torch.load(CheckPointPath + LatestFile + '.ckpt')\n",
    "        # Extract only numbers from the name\n",
    "        StartEpoch = int(''.join(c for c in LatestFile.split('a')[0] if c.isdigit()))\n",
    "        model.load_state_dict(CheckPoint['model_state_dict'])\n",
    "        print('Loaded latest checkpoint with the name ' + LatestFile + '....')\n",
    "    else:\n",
    "        StartEpoch = 0\n",
    "        print('New model initialized....')\n",
    "        \n",
    "    history = []\n",
    "    for Epochs in tqdm(range(StartEpoch, NumEpochs)):\n",
    "        TrainLosses = []\n",
    "        \n",
    "        NumIterationsPerEpoch = int(NumTrainSamples/MiniBatchSize/DivTrain)\n",
    "        for PerEpochCounter in tqdm(range(NumIterationsPerEpoch)):\n",
    "            TrainBatch = GenerateBatch(TrainSet, TrainLabels, ImageSize, MiniBatchSize, TrainIndices)\n",
    "            \n",
    "            # Predict output with forward pass\n",
    "            LossThisBatch = model.training_step(TrainBatch)\n",
    "            TrainLosses.append(LossThisBatch)\n",
    "            \n",
    "            Optimizer.zero_grad()\n",
    "            LossThisBatch.backward()\n",
    "            Optimizer.step()\n",
    "            \n",
    "            # Save checkpoint every some SaveCheckPoint's iterations\n",
    "            if PerEpochCounter % SaveCheckPoint == 0:\n",
    "                # Save the Model learnt in this epoch\n",
    "                SaveName =  CheckPointPath + str(Epochs) + 'a' + str(PerEpochCounter) + 'model.ckpt'\n",
    "                \n",
    "                torch.save({'epoch': Epochs,'model_state_dict': model.state_dict(),'optimizer_state_dict': Optimizer.state_dict(),'loss': LossThisBatch}, SaveName)\n",
    "                print('\\n' + SaveName + ' Model Saved...')\n",
    "\n",
    "            result = model.validation_step(TrainBatch)\n",
    "            result['TrainLoss'] = torch.stack(TrainLosses).mean().item()\n",
    "            model.epoch_end(Epochs*NumIterationsPerEpoch + PerEpochCounter, result)\n",
    "            history.append(result)\n",
    "            \n",
    "            # Tensorboard\n",
    "            Writer.add_scalar('LossEveryIter', result[\"loss\"], Epochs*NumIterationsPerEpoch + PerEpochCounter)\n",
    "            Writer.add_scalar('Accuracy', result[\"acc\"], Epochs*NumIterationsPerEpoch + PerEpochCounter)\n",
    "            # If you don't flush the tensorboard doesn't update until a lot of iterations!\n",
    "            Writer.flush()\n",
    "\n",
    "        ValBatch = GenerateBatch(TrainSet, TrainLabels, ImageSize, MiniBatchSize, ValIndices)\n",
    "        ValResult = model.validation_step(ValBatch)\n",
    "        Writer.add_scalar('ValidationLossEveryEpoch',ValResult['loss'],Epochs)\n",
    "        Writer.add_scalar('ValidationAccuracyEveryEpoch',ValResult['acc'],Epochs)\n",
    "        Writer.flush()\n",
    "        \n",
    "        # Save model every epoch\n",
    "        SaveName = CheckPointPath + str(Epochs) + 'model.ckpt'\n",
    "        torch.save({'epoch': Epochs,'model_state_dict': model.state_dict(),'optimizer_state_dict': Optimizer.state_dict(),'loss': LossThisBatch}, SaveName)\n",
    "        print('\\n' + SaveName + ' Model Saved...')\n",
    "        \n",
    "\n",
    "\n",
    "# Default Hyperparameters\n",
    "NumEpochs = 10\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                             std=[0.2470, 0.2435, 0.2616])\n",
    "\n",
    "# transforms_to_apply = transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor(),normalize])\n",
    "transformations = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "TrainSet = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transformations)\n",
    "ValSet = torchvision.datasets.CIFAR10(root='../../data', train=True,\n",
    "                                        download=True, transform=transformations)\n",
    "\n",
    "valid_size = 0.1\n",
    "num_train = len(TrainSet)\n",
    "indices = list (range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "TrainIndices, ValIndices = indices[split:], indices[:split]\n",
    "\n",
    "\n",
    "DivTrain = 1.0\n",
    "MiniBatchSize = 64\n",
    "LoadCheckPoint = 0\n",
    "CheckPointPath = \"Checkpoints/\"\n",
    "LogsPath = \"Logs\"\n",
    "\n",
    "# Setup all needed paraymeters including file reading\n",
    "SaveCheckPoint, ImageSize, NumTrainSamples, TrainLabels, NumClasses = SetupAll(CheckPointPath)\n",
    "\n",
    "# Find Latest Checkpoint File\n",
    "if LoadCheckPoint==1:\n",
    "    LatestFile = FindLatestModel(CheckPointPath)\n",
    "else:\n",
    "    LatestFile = None\n",
    "\n",
    "# Pretty print stats\n",
    "PrettyPrint(NumEpochs, DivTrain, MiniBatchSize, NumTrainSamples, LatestFile)\n",
    "\n",
    "TrainOperation(TrainLabels, NumTrainSamples, ImageSize,\n",
    "                NumEpochs, MiniBatchSize, SaveCheckPoint, CheckPointPath,\n",
    "                DivTrain, LatestFile, TrainSet, LogsPath, TrainIndices, ValIndices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKVVLygOJ1kd"
   },
   "source": [
    "### Test your neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lY-9nSVBJ282"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "from skimage import data, exposure, img_as_float\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from torchvision.transforms import ToTensor\n",
    "import argparse\n",
    "import shutil\n",
    "import string\n",
    "import math as m\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "def SetupAll():\n",
    "    \"\"\"\n",
    "    Outputs:\n",
    "    ImageSize - Size of the Image\n",
    "    \"\"\"   \n",
    "    # Image Input Shape\n",
    "    ImageSize = [32, 32, 3]\n",
    "\n",
    "    return ImageSize\n",
    "\n",
    "def StandardizeInputs(Img):\n",
    "    ##########################################################################\n",
    "    # Add any standardization or cropping/resizing if used in Training here!\n",
    "    ##########################################################################\n",
    "    return Img\n",
    "    \n",
    "def ReadImages(Img):\n",
    "    \"\"\"\n",
    "    Outputs:\n",
    "    I1Combined - I1 image after any standardization and/or cropping/resizing to ImageSize\n",
    "    I1 - Original I1 image for visualization purposes only\n",
    "    \"\"\"    \n",
    "    I1 = Img\n",
    "    \n",
    "    if(I1 is None):\n",
    "        # OpenCV returns empty list if image is not read! \n",
    "        print('ERROR: Image I1 cannot be read')\n",
    "        sys.exit()\n",
    "        \n",
    "    I1S = StandardizeInputs(np.float32(I1))\n",
    "\n",
    "    I1Combined = np.expand_dims(I1S, axis=0)\n",
    "\n",
    "    return I1Combined, I1\n",
    "                \n",
    "\n",
    "def TestOperation(ImageSize, ModelPath, TestSet, LabelsPathPred):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    ImageSize is the size of the image\n",
    "    ModelPath - Path to load trained model from\n",
    "    TestSet - The test dataset\n",
    "    LabelsPathPred - Path to save predictions\n",
    "    Outputs:\n",
    "    Predictions written to TxtFiles/PredOut.txt\n",
    "    \"\"\"\n",
    "    # Predict output with forward pass, MiniBatchSize for Test is 1\n",
    "    # model = ResNet(ResidualBlock, [2, 2, 2]) \n",
    "    model = ResNet9(3, 10)\n",
    "    \n",
    "    CheckPoint = torch.load(ModelPath)\n",
    "    model.load_state_dict(CheckPoint['model_state_dict'])\n",
    "    print('Number of parameters in this model are %d ' % len(model.state_dict().items()))\n",
    "    \n",
    "    OutSaveT = open(LabelsPathPred, 'w')\n",
    "\n",
    "    for count in tqdm(range(len(TestSet))): \n",
    "        Img, Label = TestSet[count]\n",
    "        Img, ImgOrg = ReadImages(Img)\n",
    "        PredT = torch.argmax(model(torch.tensor(Img))).item()\n",
    "\n",
    "        OutSaveT.write(str(PredT)+'\\n')\n",
    "    OutSaveT.close()\n",
    "\n",
    "def Accuracy(Pred, GT):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    Pred are the predicted labels\n",
    "    GT are the ground truth labels\n",
    "    Outputs:\n",
    "    Accuracy in percentage\n",
    "    \"\"\"\n",
    "    return (np.sum(np.array(Pred)==np.array(GT))*100.0/len(Pred))\n",
    "\n",
    "def ReadLabels(LabelsPathTest, LabelsPathPred):\n",
    "    if(not (os.path.isfile(LabelsPathTest))):\n",
    "        print('ERROR: Test Labels do not exist in '+LabelsPathTest)\n",
    "        sys.exit()\n",
    "    else:\n",
    "        LabelTest = open(LabelsPathTest, 'r')\n",
    "        LabelTest = LabelTest.read()\n",
    "        LabelTest = map(float, LabelTest.split())\n",
    "\n",
    "    if(not (os.path.isfile(LabelsPathPred))):\n",
    "        print('ERROR: Pred Labels do not exist in '+LabelsPathPred)\n",
    "        sys.exit()\n",
    "    else:\n",
    "        LabelPred = open(LabelsPathPred, 'r')\n",
    "        LabelPred = LabelPred.read()\n",
    "        LabelPred = map(float, LabelPred.split())\n",
    "        \n",
    "    return LabelTest, LabelPred\n",
    "\n",
    "def ConfusionMatrix(LabelsTrue, LabelsPred):\n",
    "    \"\"\"\n",
    "    LabelsTrue - True labels\n",
    "    LabelsPred - Predicted labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the confusion matrix using sklearn.\n",
    "    LabelsTrue, LabelsPred = list(LabelsTrue), list(LabelsPred)\n",
    "    cm = confusion_matrix(y_true=LabelsTrue,  # True class for test-set.\n",
    "                          y_pred=LabelsPred)  # Predicted class.\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    for i in range(10):\n",
    "        print(str(cm[i, :]) + ' ({0})'.format(i))\n",
    "\n",
    "    # Print the class-numbers for easy reference.\n",
    "    class_numbers = [\" ({0})\".format(i) for i in range(10)]\n",
    "    print(\"\".join(class_numbers))\n",
    "\n",
    "    print('Accuracy: '+ str(Accuracy(LabelsPred, LabelsTrue)), '%')\n",
    "\n",
    "\n",
    "ModelPath = \"Checkpoints/9model.ckpt\"\n",
    "LabelsPath = \"TxtFiles/LabelsTest.txt\"\n",
    "\n",
    "TestSet = CIFAR10(root='data/', train=False, transform=transformations)\n",
    "\n",
    "# Setup all needed parameters including file reading\n",
    "ImageSize = SetupAll()\n",
    "\n",
    "# Define PlaceHolder variables for Input and Predicted output\n",
    "LabelsPathPred = 'TxtFiles/PredOut.txt' # Path to save predicted labels\n",
    "\n",
    "TestOperation(ImageSize, ModelPath, TestSet, LabelsPathPred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "LabelsTrue, LabelsPred = ReadLabels(LabelsPath, LabelsPathPred)\n",
    "ConfusionMatrix(LabelsTrue, LabelsPred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw0_to_be_filled.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2762af0fb94193cc770e2dbb99b50503f4c838317f9fa63bb8a7461c3d6fd280"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
